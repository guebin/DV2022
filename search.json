[
  {
    "objectID": "posts/2022-10-30-9wk-1-mid.html",
    "href": "posts/2022-10-30-9wk-1-mid.html",
    "title": "midterm",
    "section": "",
    "text": "중간고사"
  },
  {
    "objectID": "posts/2022-10-30-9wk-1-mid.html#시각화의-해석---다음을-잘-읽고-물음에-답하라.-20점",
    "href": "posts/2022-10-30-9wk-1-mid.html#시각화의-해석---다음을-잘-읽고-물음에-답하라.-20점",
    "title": "midterm",
    "section": "1. 시각화의 해석 - 다음을 잘 읽고 물음에 답하라. (20점)",
    "text": "1. 시각화의 해석 - 다음을 잘 읽고 물음에 답하라. (20점)\n(1) 아래의 그림을 보고 올바르게 해석한 것을 고르라. (모두 맞출경우만 정답으로 인정)\n\n#hide_input\nx = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\ny1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\ny2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\ny3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\nx4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\ny4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\nfig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\nax1.plot(x,y1,'.') \nax1.set_title(\"(a)\")\nax2.plot(x,y2,'.') \nax2.set_title(\"(b)\")\nax3.plot(x,y3,'.'); ax3.plot(x[2],y3[2],'o',color='C1') \nax3.set_title(\"(c)\")\nax4.plot(x4,y4,'.'); ax4.plot(x4[-4],y4[-4],'o',color='C1')\nax4.set_title(\"(d)\")\nfig.suptitle(\"Anscombe's quartet\",size=15)\nplt.tight_layout()\n\n\n\n\n\n소윤: (a)의 경우 \\((x_i,y_i)\\)의 산점도가 직선형태이므로 표본상관계수의 값을 해석하는 것이 두 자료의 관계를 파악할때 도움을 준다.\n다호: (b)의 경우 \\((x_i,y_i)\\)의 산점도가 이차곡선이므로 표본상관계수의 해석으로 두 자료의 관계를 모두 파악할 수 없다.\n하니: (c)의 경우 주황색으로 표시된 점을 제외한다면 표본상관계수로 자료를 해석하기에 바람직하다.\n도한: (d)도 (c)와 마찬가지로 주황색으로 표시된 점을 제외한다면 표본상관계수로 자료를 해석하기에 바람직하다.\n\n(풀이)\n\n정답: 소윤, 다호, 하니가 맞게 서술함.\n도한이 틀린이유: 주황색점을 제외할 경우 \\(x\\)의 변화량이 0이므로 분모가 0으로 수렴. 따라서 상관계수의 해석이 무의미하다.\n\n(2) 아래의 그림을 보고 올바르게 해석한 것을 모두 고르라. (모두 맞출경우만 정답으로 인정) - 그림에 대한 배경설명은 10월17일,19일의 “아이스크림을 많이 먹으면 걸리는 병”을 참고\n\n#hide_input\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/icecream.csv')\nggplot(data=df.assign(temp=pd.cut(df.temp,[-np.inf,0,5,10,15,20,25,30,np.inf])))\\\n+geom_point(aes(x='icecream',y='disease',color='temp'))\\\n+geom_smooth(aes(x='icecream',y='disease',color='temp'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8776319243321)>\n\n\n\n소윤: 아이스크림과 소아마비는 상관계수는 양수이다.\n다호: 상관계수가 양수라는 정보만으로는 소아마비와 아이스크림사이에 인과성이 있다고 주장하기 어렵다.\n하니: 소아마비와 아이스크림 사이에 존재하는 은닉변수 온도를 통제한다면 소아마비와 아이스크림 사이의 상관계수는 0에 가깝다.\n도한: 하니의 분석에 따르면 소아마비와 아이스크림 사이의 인과성은 없다고 보아야 한다. (단 소아마비와 아이스크림 사이의 은닉된 변수는 온도가 유일하다고 가정한다)\n\n(풀이)\n\n정답: 소윤, 다호, 하니, 도한 모두 맞게 서술함"
  },
  {
    "objectID": "posts/2022-10-30-9wk-1-mid.html#시각화구현-i---다음을-잘-읽고-물음에-답하라.-10점",
    "href": "posts/2022-10-30-9wk-1-mid.html#시각화구현-i---다음을-잘-읽고-물음에-답하라.-10점",
    "title": "midterm",
    "section": "2. 시각화구현 I - 다음을 잘 읽고 물음에 답하라. (10점)",
    "text": "2. 시각화구현 I - 다음을 잘 읽고 물음에 답하라. (10점)\n(1)~(3) 주어진 자료에 대하여 다음을 시각화 하라. (maplotlib 이용)\n\nx=[1,2,3,4]\ny=[1,2,3,2]\n\n(1) 출제의도: 마커변경, 색깔변경\n\nplt.plot(x,y,'x',color='C1');\n\n\n\n\n\n채점기준: 색깔이 정확하게 일치하지 않을 경우 0점으로 처리\n\n(2) 출제의도: title설정\n\nplt.plot(x,y,)\nplt.title('TITLE',size=15);\n\n\n\n\n(3) 출제의도: linetype 변경, dot connected-plot\n\nplt.plot(x,y,'or--');\n\n\n\n\n\n(4) ~ (5) 주어진 자료에 대하여 다음을 시각화 하라.\n\nx=[1,2,3,4]\ny1=[1,2,4,3]\ny2=[1.1,1.9,3,5]\n\n(4) 출제의도: legend\n\nplt.plot(x,y1,'o--',label='y1')\nplt.plot(x,y2,'o--',label='y2')\nplt.legend();\n\n\n\n\n(5) 출제의도: linetype, linewidth 변경\n\nfig,ax = plt.subplots(1,2)\nax[0].plot(x,y1,'--',lw=2)\nax[1].plot(x,y2,'--',lw=4);\n\n\n\n\n\n채점기준: 선의두께가 예시와 조금 달라도 만점으로 인정 (두께의 변화만 있으면 정답으로 인정함)"
  },
  {
    "objectID": "posts/2022-10-30-9wk-1-mid.html#시각화구현-ii-다음을-잘-읽고-물음에-답하라.-10점",
    "href": "posts/2022-10-30-9wk-1-mid.html#시각화구현-ii-다음을-잘-읽고-물음에-답하라.-10점",
    "title": "midterm",
    "section": "3. 시각화구현 II – 다음을 잘 읽고 물음에 답하라. (10점)",
    "text": "3. 시각화구현 II – 다음을 잘 읽고 물음에 답하라. (10점)\n주어진 자료가 아래와 같다고 하자.\n\nnp.random.seed(43052)\nx1,y1 =  np.random.multivariate_normal([-2,-2],[[1,-0.8],[-0.8,1]],size=500).T\nx2,y2 =  np.random.multivariate_normal([2,2],[[1,-0.7],[-0.7,1]],size=500).T\n\n(1) matplotlib와 seaborn을 이용하여 아래와 같이 시각화 하라.\n\nalpha=0.1을 사용\n\n\nfig,ax = plt.subplots(2,2)\nax[0,0].plot(x1,y1,'.')\nax[0,0].plot(x2,y2,'.',alpha=0.1)\nax[0,0].set_title(\"(a) matplotlib - highlight (x1,y1)\")\nsns.scatterplot(x=x1,y=y1,ax=ax[0,1])\nsns.scatterplot(x=x2,y=y2,ax=ax[0,1],alpha=0.1)\nax[0,1].set_title(\"(b) seaborn - highlight (x1,y1)\")\nax[1,0].plot(x1,y1,'.',alpha=0.1)\nax[1,0].plot(x2,y2,'.')\nsns.scatterplot(x=x1,y=y1,ax=ax[1,1],alpha=0.1)\nax[1,0].set_title(\"(c) matplotlib - highlight (x2,y2)\")\nsns.scatterplot(x=x2,y=y2,ax=ax[1,1])\nax[1,1].set_title(\"(d) seaborn - highlight (x2,y2)\")\nplt.tight_layout()\n\n\n\n\n\n채점기준: (b)와 (d)의 그림을 seaborn으로 생성하지 않을 경우 정답으로 인정안함\n\n(2) plotnine을 이용하여 아래와 같이 시각화하라. - alpha=0.1을 사용\n\nx=np.concatenate([x1,x2])\ny=np.concatenate([y1,y2])\ndf = pd.DataFrame({'x':x,'y':y,'cat':['A']*len(x1)+['B']*len(x2)})\nggplot(df)+geom_point(aes(x='x',y='y',color='cat'),alpha=0.1)\\\n+geom_smooth(aes(x='x',y='y',color='cat'))\\\n+geom_smooth(aes(x='x',y='y'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8776325576381)>\n\n\n\n채점기준: 산점도, 그룹별추세선, 전체추세선이 모두 있을 경우만 정답으로 인정"
  },
  {
    "objectID": "posts/2022-10-30-9wk-1-mid.html#자료분석-및-시각화-i-40점-fifa22자료",
    "href": "posts/2022-10-30-9wk-1-mid.html#자료분석-및-시각화-i-40점-fifa22자료",
    "title": "midterm",
    "section": "4. 자료분석 및 시각화 I (40점) – FIFA22자료",
    "text": "4. 자료분석 및 시각화 I (40점) – FIFA22자료\n아래의 코드를 활용하여 FIFA22의 자료를 불러온뒤 물음에 답하라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2021/master/_notebooks/2021-10-25-FIFA22_official_data.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      SlidingTackle\n      GKDiving\n      GKHandling\n      GKKicking\n      GKPositioning\n      GKReflexes\n      Best Position\n      Best Overall Rating\n      Release Clause\n      DefensiveAwareness\n    \n  \n  \n    \n      0\n      212198\n      Bruno Fernandes\n      26\n      https://cdn.sofifa.com/players/212/198/22_60.png\n      Portugal\n      https://cdn.sofifa.com/flags/pt.png\n      88\n      89\n      Manchester United\n      https://cdn.sofifa.com/teams/11/30.png\n      ...\n      65.0\n      12.0\n      14.0\n      15.0\n      8.0\n      14.0\n      CAM\n      88.0\n      €206.9M\n      72.0\n    \n    \n      1\n      209658\n      L. Goretzka\n      26\n      https://cdn.sofifa.com/players/209/658/22_60.png\n      Germany\n      https://cdn.sofifa.com/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.com/teams/21/30.png\n      ...\n      77.0\n      13.0\n      8.0\n      15.0\n      11.0\n      9.0\n      CM\n      87.0\n      €160.4M\n      74.0\n    \n    \n      2\n      176580\n      L. Suárez\n      34\n      https://cdn.sofifa.com/players/176/580/22_60.png\n      Uruguay\n      https://cdn.sofifa.com/flags/uy.png\n      88\n      88\n      Atlético de Madrid\n      https://cdn.sofifa.com/teams/240/30.png\n      ...\n      38.0\n      27.0\n      25.0\n      31.0\n      33.0\n      37.0\n      ST\n      88.0\n      €91.2M\n      42.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      30\n      https://cdn.sofifa.com/players/192/985/22_60.png\n      Belgium\n      https://cdn.sofifa.com/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.com/teams/10/30.png\n      ...\n      53.0\n      15.0\n      13.0\n      5.0\n      10.0\n      13.0\n      CM\n      91.0\n      €232.2M\n      68.0\n    \n    \n      4\n      224334\n      M. Acuña\n      29\n      https://cdn.sofifa.com/players/224/334/22_60.png\n      Argentina\n      https://cdn.sofifa.com/flags/ar.png\n      84\n      84\n      Sevilla FC\n      https://cdn.sofifa.com/teams/481/30.png\n      ...\n      82.0\n      8.0\n      14.0\n      13.0\n      13.0\n      14.0\n      LB\n      84.0\n      €77.7M\n      80.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      16705\n      240558\n      18 L. Clayton\n      17\n      https://cdn.sofifa.com/players/240/558/18_60.png\n      England\n      https://cdn.sofifa.com/flags/gb-eng.png\n      53\n      70\n      Cheltenham Town\n      https://cdn.sofifa.com/teams/1936/30.png\n      ...\n      12.0\n      55.0\n      54.0\n      52.0\n      50.0\n      59.0\n      GK\n      52.0\n      €238K\n      NaN\n    \n    \n      16706\n      262846\n      �. Dobre\n      20\n      https://cdn.sofifa.com/players/262/846/22_60.png\n      Romania\n      https://cdn.sofifa.com/flags/ro.png\n      53\n      63\n      FC Academica Clinceni\n      https://cdn.sofifa.com/teams/113391/30.png\n      ...\n      12.0\n      57.0\n      52.0\n      53.0\n      48.0\n      58.0\n      GK\n      53.0\n      €279K\n      5.0\n    \n    \n      16707\n      241317\n      21 Xue Qinghao\n      19\n      https://cdn.sofifa.com/players/241/317/21_60.png\n      China PR\n      https://cdn.sofifa.com/flags/cn.png\n      47\n      60\n      Shanghai Shenhua FC\n      https://cdn.sofifa.com/teams/110955/30.png\n      ...\n      9.0\n      49.0\n      48.0\n      45.0\n      38.0\n      52.0\n      GK\n      47.0\n      €223K\n      21.0\n    \n    \n      16708\n      259646\n      A. Shaikh\n      18\n      https://cdn.sofifa.com/players/259/646/22_60.png\n      India\n      https://cdn.sofifa.com/flags/in.png\n      47\n      67\n      ATK Mohun Bagan FC\n      https://cdn.sofifa.com/teams/113146/30.png\n      ...\n      13.0\n      49.0\n      41.0\n      39.0\n      45.0\n      49.0\n      GK\n      47.0\n      €259K\n      7.0\n    \n    \n      16709\n      178453\n      07 A. Censori\n      17\n      https://cdn.sofifa.com/players/178/453/07_60.png\n      Italy\n      https://cdn.sofifa.com/flags/it.png\n      28\n      38\n      Arezzo\n      https://cdn.sofifa.com/teams/110907/30.png\n      ...\n      NaN\n      7.0\n      1.0\n      36.0\n      6.0\n      9.0\n      ST\n      36.0\n      NaN\n      NaN\n    \n  \n\n16710 rows × 65 columns\n\n\n\n(1) 연령별로 선수들의 잠재력을 시각화하고 싶다. 여기에서 잠재력은 아래의 수식의 Potential2를 의미한다.\nPotential2 = Potential - Overall\n아래의 세부지침에 맞추어 연령별 Potential2의 산점도와 boxplot을 그려라. – (10점)\n(세부지침)\nstep1: 결측치가 가장 많은 2개의 컬럼을 찾고 이를 제거하라.\nstep2: dropna()를 이용하여 결측치를 제거하라.\nstep3: Potential2 = Potential - Overall 를 이용하여 Potential2를 구하라.\nstep4: 구간 [0,20,22,26,100]를 설정하고 이를 기준으로 Age를 그룹화하라. (총 4개의 그룹으로 나누어져야 한다)\nstep5: 그룹화된 Age를 x축으로, Potential2를 y축으로, 색깔을 그룹화된 Age로 설정한 뒤 산점도와 박스플랏을 겹쳐그려라. - 산점도의 파라메터: alpha=0.5,size=0.1,position=‘jitter’ - 박스플랏의 파라메터: alpha=0.8\n(풀이)\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16710 entries, 0 to 16709\nData columns (total 65 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        16710 non-null  int64  \n 1   Name                      16710 non-null  object \n 2   Age                       16710 non-null  int64  \n 3   Photo                     16710 non-null  object \n 4   Nationality               16710 non-null  object \n 5   Flag                      16710 non-null  object \n 6   Overall                   16710 non-null  int64  \n 7   Potential                 16710 non-null  int64  \n 8   Club                      16446 non-null  object \n 9   Club Logo                 16710 non-null  object \n 10  Value                     16710 non-null  object \n 11  Wage                      16710 non-null  object \n 12  Special                   16710 non-null  int64  \n 13  Preferred Foot            16710 non-null  object \n 14  International Reputation  16710 non-null  float64\n 15  Weak Foot                 16710 non-null  float64\n 16  Skill Moves               16710 non-null  float64\n 17  Work Rate                 16710 non-null  object \n 18  Body Type                 16681 non-null  object \n 19  Real Face                 16681 non-null  object \n 20  Position                  16684 non-null  object \n 21  Jersey Number             16684 non-null  float64\n 22  Joined                    15198 non-null  object \n 23  Loaned From               1132 non-null   object \n 24  Contract Valid Until      16359 non-null  object \n 25  Height                    16710 non-null  object \n 26  Weight                    16710 non-null  object \n 27  Crossing                  16710 non-null  float64\n 28  Finishing                 16710 non-null  float64\n 29  HeadingAccuracy           16710 non-null  float64\n 30  ShortPassing              16710 non-null  float64\n 31  Volleys                   16673 non-null  float64\n 32  Dribbling                 16710 non-null  float64\n 33  Curve                     16673 non-null  float64\n 34  FKAccuracy                16710 non-null  float64\n 35  LongPassing               16710 non-null  float64\n 36  BallControl               16710 non-null  float64\n 37  Acceleration              16710 non-null  float64\n 38  SprintSpeed               16710 non-null  float64\n 39  Agility                   16673 non-null  float64\n 40  Reactions                 16710 non-null  float64\n 41  Balance                   16673 non-null  float64\n 42  ShotPower                 16710 non-null  float64\n 43  Jumping                   16673 non-null  float64\n 44  Stamina                   16710 non-null  float64\n 45  Strength                  16710 non-null  float64\n 46  LongShots                 16710 non-null  float64\n 47  Aggression                16710 non-null  float64\n 48  Interceptions             16702 non-null  float64\n 49  Positioning               16702 non-null  float64\n 50  Vision                    16673 non-null  float64\n 51  Penalties                 16710 non-null  float64\n 52  Composure                 16459 non-null  float64\n 53  Marking                   892 non-null    float64\n 54  StandingTackle            16710 non-null  float64\n 55  SlidingTackle             16673 non-null  float64\n 56  GKDiving                  16710 non-null  float64\n 57  GKHandling                16710 non-null  float64\n 58  GKKicking                 16710 non-null  float64\n 59  GKPositioning             16710 non-null  float64\n 60  GKReflexes                16710 non-null  float64\n 61  Best Position             16710 non-null  object \n 62  Best Overall Rating       16710 non-null  float64\n 63  Release Clause            14961 non-null  object \n 64  DefensiveAwareness        15818 non-null  float64\ndtypes: float64(40), int64(5), object(20)\nmemory usage: 8.3+ MB\n\n\n\n’Loaned From’와 ’Marking’이 가장 결측치가 많이 포함되어있음\n\n\ndata1= df.drop(columns=['Loaned From', 'Marking']).dropna()\\\n.eval('Potential2 = Potential- Overall')\\\n.assign(Age = lambda df: pd.cut(df['Age'],[0,20,22,26,100]))\ndata1 \n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      GKDiving\n      GKHandling\n      GKKicking\n      GKPositioning\n      GKReflexes\n      Best Position\n      Best Overall Rating\n      Release Clause\n      DefensiveAwareness\n      Potential2\n    \n  \n  \n    \n      0\n      212198\n      Bruno Fernandes\n      (22, 26]\n      https://cdn.sofifa.com/players/212/198/22_60.png\n      Portugal\n      https://cdn.sofifa.com/flags/pt.png\n      88\n      89\n      Manchester United\n      https://cdn.sofifa.com/teams/11/30.png\n      ...\n      12.0\n      14.0\n      15.0\n      8.0\n      14.0\n      CAM\n      88.0\n      €206.9M\n      72.0\n      1\n    \n    \n      1\n      209658\n      L. Goretzka\n      (22, 26]\n      https://cdn.sofifa.com/players/209/658/22_60.png\n      Germany\n      https://cdn.sofifa.com/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.com/teams/21/30.png\n      ...\n      13.0\n      8.0\n      15.0\n      11.0\n      9.0\n      CM\n      87.0\n      €160.4M\n      74.0\n      1\n    \n    \n      2\n      176580\n      L. Suárez\n      (26, 100]\n      https://cdn.sofifa.com/players/176/580/22_60.png\n      Uruguay\n      https://cdn.sofifa.com/flags/uy.png\n      88\n      88\n      Atlético de Madrid\n      https://cdn.sofifa.com/teams/240/30.png\n      ...\n      27.0\n      25.0\n      31.0\n      33.0\n      37.0\n      ST\n      88.0\n      €91.2M\n      42.0\n      0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      (26, 100]\n      https://cdn.sofifa.com/players/192/985/22_60.png\n      Belgium\n      https://cdn.sofifa.com/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.com/teams/10/30.png\n      ...\n      15.0\n      13.0\n      5.0\n      10.0\n      13.0\n      CM\n      91.0\n      €232.2M\n      68.0\n      0\n    \n    \n      4\n      224334\n      M. Acuña\n      (26, 100]\n      https://cdn.sofifa.com/players/224/334/22_60.png\n      Argentina\n      https://cdn.sofifa.com/flags/ar.png\n      84\n      84\n      Sevilla FC\n      https://cdn.sofifa.com/teams/481/30.png\n      ...\n      8.0\n      14.0\n      13.0\n      13.0\n      14.0\n      LB\n      84.0\n      €77.7M\n      80.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      16703\n      259718\n      F. Gebhardt\n      (0, 20]\n      https://cdn.sofifa.com/players/259/718/22_60.png\n      Germany\n      https://cdn.sofifa.com/flags/de.png\n      52\n      66\n      FC Basel 1893\n      https://cdn.sofifa.com/teams/896/30.png\n      ...\n      53.0\n      45.0\n      47.0\n      52.0\n      57.0\n      GK\n      52.0\n      €361K\n      6.0\n      14\n    \n    \n      16704\n      251433\n      B. Voll\n      (0, 20]\n      https://cdn.sofifa.com/players/251/433/22_60.png\n      Germany\n      https://cdn.sofifa.com/flags/de.png\n      58\n      69\n      F.C. Hansa Rostock\n      https://cdn.sofifa.com/teams/27/30.png\n      ...\n      59.0\n      60.0\n      56.0\n      55.0\n      61.0\n      GK\n      58.0\n      €656K\n      5.0\n      11\n    \n    \n      16706\n      262846\n      �. Dobre\n      (0, 20]\n      https://cdn.sofifa.com/players/262/846/22_60.png\n      Romania\n      https://cdn.sofifa.com/flags/ro.png\n      53\n      63\n      FC Academica Clinceni\n      https://cdn.sofifa.com/teams/113391/30.png\n      ...\n      57.0\n      52.0\n      53.0\n      48.0\n      58.0\n      GK\n      53.0\n      €279K\n      5.0\n      10\n    \n    \n      16707\n      241317\n      21 Xue Qinghao\n      (0, 20]\n      https://cdn.sofifa.com/players/241/317/21_60.png\n      China PR\n      https://cdn.sofifa.com/flags/cn.png\n      47\n      60\n      Shanghai Shenhua FC\n      https://cdn.sofifa.com/teams/110955/30.png\n      ...\n      49.0\n      48.0\n      45.0\n      38.0\n      52.0\n      GK\n      47.0\n      €223K\n      21.0\n      13\n    \n    \n      16708\n      259646\n      A. Shaikh\n      (0, 20]\n      https://cdn.sofifa.com/players/259/646/22_60.png\n      India\n      https://cdn.sofifa.com/flags/in.png\n      47\n      67\n      ATK Mohun Bagan FC\n      https://cdn.sofifa.com/teams/113146/30.png\n      ...\n      49.0\n      41.0\n      39.0\n      45.0\n      49.0\n      GK\n      47.0\n      €259K\n      7.0\n      20\n    \n  \n\n14398 rows × 64 columns\n\n\n\n\nfig = ggplot(data=data1)\nscatter = geom_point(aes(x='Age',y='Potential2',colour='Age'),alpha=0.5,size=0.1,position='jitter')\nboxplot = geom_boxplot(aes(x='Age',y='Potential2',colour='Age'),alpha=0.8)\nfig+scatter+boxplot\n\n\n\n\n<ggplot: (8776319269061)>\n\n\n\n채점기준: Age의 Label을 사용하지 않아도 만점으로 인정함.\n\n(2) 포지션별로 선수들의 능력치와 Wage를 시각화하고 싶다. 아래의 dictionary를 이용하여 Position을 재정의하라.\n\nposition_dict = {\n    'GOALKEEPER':{'GK'},\n    'DEFENDER':{'CB','RCB','LCB','RB','LB','RWB','LWB'},\n    'MIDFIELDER':{'CM','RCM','LCM','CDM','RDM','LDM','CAM','RAM','LAM','RM','LM'},\n    'FORWARD':{'ST','CF','RF','LF','RW','LW','RS','LS'},\n    'SUB':{'SUB'},\n    'RES':{'RES'}\n}\nposition_dict\n\n{'GOALKEEPER': {'GK'},\n 'DEFENDER': {'CB', 'LB', 'LCB', 'LWB', 'RB', 'RCB', 'RWB'},\n 'MIDFIELDER': {'CAM',\n  'CDM',\n  'CM',\n  'LAM',\n  'LCM',\n  'LDM',\n  'LM',\n  'RAM',\n  'RCM',\n  'RDM',\n  'RM'},\n 'FORWARD': {'CF', 'LF', 'LS', 'LW', 'RF', 'RS', 'RW', 'ST'},\n 'SUB': {'SUB'},\n 'RES': {'RES'}}\n\n\n아래의 세부지침에 맞추어 포지션별 ShotPower와 SlidingTackle의 산점도를 그려라. – (30점)\n세부지침\nstep1: 결측치가 가장 많은 2개의 컬럼을 찾고 이를 제거하라.\nstep2: dropna()를 이용하여 결측치를 제거하라.\nstep3: hint1과 position_dict을 참고하여 Position을 적절하게 변환하라. (변환된 값을 Position으로 저장할 것)\nstep4: hint2를 참고하여 Wage를 적절하게 변환하라. (변환된 값을 Wage에 저장할 것)\nstep5: Position==“DEFENDER” or Position==“FORWARD”에 해당하는 관측치를 고른 뒤 x축에 ShotPower, y축에 SlidingTackle 을 시각화하라. Position은 color로 구분하고 Wage는 size와 alpha로 구분하라.\nhint1: Position column의 변환을 위한 코드\n\n'<span class=\"pos pos18\">CAM'.split('>')\n\n['<span class=\"pos pos18\"', 'CAM']\n\n\nhint2: Wage column의 변환을 위한 함수\n\ndef f(x):\n    if x[-1] == 'K' :\n        y= float(x[1:-1])*1000\n    elif x[-1] == 'M' : \n        y= float(x[1:-1])*1000000\n    else:\n        y= 0 \n    return y \n\n(풀이)\n\ndata2=df.drop(columns=['Loaned From', 'Marking']).dropna()\\\n.assign(Wage = lambda df: list(map(f,df['Wage'])))\\\n.assign(Position = lambda df: list(map(lambda x: x.split('>')[-1], df.Position)))\\\n.assign(Position = lambda df: \n        [key for x in df.Position for key in position_dict if x in position_dict[key]]\n       )\ndata2\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      SlidingTackle\n      GKDiving\n      GKHandling\n      GKKicking\n      GKPositioning\n      GKReflexes\n      Best Position\n      Best Overall Rating\n      Release Clause\n      DefensiveAwareness\n    \n  \n  \n    \n      0\n      212198\n      Bruno Fernandes\n      26\n      https://cdn.sofifa.com/players/212/198/22_60.png\n      Portugal\n      https://cdn.sofifa.com/flags/pt.png\n      88\n      89\n      Manchester United\n      https://cdn.sofifa.com/teams/11/30.png\n      ...\n      65.0\n      12.0\n      14.0\n      15.0\n      8.0\n      14.0\n      CAM\n      88.0\n      €206.9M\n      72.0\n    \n    \n      1\n      209658\n      L. Goretzka\n      26\n      https://cdn.sofifa.com/players/209/658/22_60.png\n      Germany\n      https://cdn.sofifa.com/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.com/teams/21/30.png\n      ...\n      77.0\n      13.0\n      8.0\n      15.0\n      11.0\n      9.0\n      CM\n      87.0\n      €160.4M\n      74.0\n    \n    \n      2\n      176580\n      L. Suárez\n      34\n      https://cdn.sofifa.com/players/176/580/22_60.png\n      Uruguay\n      https://cdn.sofifa.com/flags/uy.png\n      88\n      88\n      Atlético de Madrid\n      https://cdn.sofifa.com/teams/240/30.png\n      ...\n      38.0\n      27.0\n      25.0\n      31.0\n      33.0\n      37.0\n      ST\n      88.0\n      €91.2M\n      42.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      30\n      https://cdn.sofifa.com/players/192/985/22_60.png\n      Belgium\n      https://cdn.sofifa.com/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.com/teams/10/30.png\n      ...\n      53.0\n      15.0\n      13.0\n      5.0\n      10.0\n      13.0\n      CM\n      91.0\n      €232.2M\n      68.0\n    \n    \n      4\n      224334\n      M. Acuña\n      29\n      https://cdn.sofifa.com/players/224/334/22_60.png\n      Argentina\n      https://cdn.sofifa.com/flags/ar.png\n      84\n      84\n      Sevilla FC\n      https://cdn.sofifa.com/teams/481/30.png\n      ...\n      82.0\n      8.0\n      14.0\n      13.0\n      13.0\n      14.0\n      LB\n      84.0\n      €77.7M\n      80.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      16703\n      259718\n      F. Gebhardt\n      19\n      https://cdn.sofifa.com/players/259/718/22_60.png\n      Germany\n      https://cdn.sofifa.com/flags/de.png\n      52\n      66\n      FC Basel 1893\n      https://cdn.sofifa.com/teams/896/30.png\n      ...\n      10.0\n      53.0\n      45.0\n      47.0\n      52.0\n      57.0\n      GK\n      52.0\n      €361K\n      6.0\n    \n    \n      16704\n      251433\n      B. Voll\n      20\n      https://cdn.sofifa.com/players/251/433/22_60.png\n      Germany\n      https://cdn.sofifa.com/flags/de.png\n      58\n      69\n      F.C. Hansa Rostock\n      https://cdn.sofifa.com/teams/27/30.png\n      ...\n      10.0\n      59.0\n      60.0\n      56.0\n      55.0\n      61.0\n      GK\n      58.0\n      €656K\n      5.0\n    \n    \n      16706\n      262846\n      �. Dobre\n      20\n      https://cdn.sofifa.com/players/262/846/22_60.png\n      Romania\n      https://cdn.sofifa.com/flags/ro.png\n      53\n      63\n      FC Academica Clinceni\n      https://cdn.sofifa.com/teams/113391/30.png\n      ...\n      12.0\n      57.0\n      52.0\n      53.0\n      48.0\n      58.0\n      GK\n      53.0\n      €279K\n      5.0\n    \n    \n      16707\n      241317\n      21 Xue Qinghao\n      19\n      https://cdn.sofifa.com/players/241/317/21_60.png\n      China PR\n      https://cdn.sofifa.com/flags/cn.png\n      47\n      60\n      Shanghai Shenhua FC\n      https://cdn.sofifa.com/teams/110955/30.png\n      ...\n      9.0\n      49.0\n      48.0\n      45.0\n      38.0\n      52.0\n      GK\n      47.0\n      €223K\n      21.0\n    \n    \n      16708\n      259646\n      A. Shaikh\n      18\n      https://cdn.sofifa.com/players/259/646/22_60.png\n      India\n      https://cdn.sofifa.com/flags/in.png\n      47\n      67\n      ATK Mohun Bagan FC\n      https://cdn.sofifa.com/teams/113146/30.png\n      ...\n      13.0\n      49.0\n      41.0\n      39.0\n      45.0\n      49.0\n      GK\n      47.0\n      €259K\n      7.0\n    \n  \n\n14398 rows × 63 columns\n\n\n\n\nfig = ggplot(data=data2.query('Position==\"DEFENDER\" or Position==\"FORWARD\"'))\nscatter = geom_point(aes(x='ShotPower',y='SlidingTackle',color='Position',size='Wage',alpha='Wage'))\nfig+scatter\n\n\n\n\n<ggplot: (8776325574701)>\n\n\n\n채점기준: df[‘Position’]이 아니라 df[‘Best Position’]을 이용하여 자료를 변형하고 시각화 하는 경우 부분점수 없이 0점임"
  },
  {
    "objectID": "posts/2022-10-30-9wk-1-mid.html#자료분석-및-시각화-ii-20점-hrdataset_v14",
    "href": "posts/2022-10-30-9wk-1-mid.html#자료분석-및-시각화-ii-20점-hrdataset_v14",
    "title": "midterm",
    "section": "5. 자료분석 및 시각화 II (20점) – HRDataset_v14",
    "text": "5. 자료분석 및 시각화 II (20점) – HRDataset_v14\n아래의 코드를 활용하여 Kaggle의 HRdataset을 불러오고 물음에 답하라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/HRDataset_v14.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Employee_Name\n      EmpID\n      MarriedID\n      MaritalStatusID\n      GenderID\n      EmpStatusID\n      DeptID\n      PerfScoreID\n      FromDiversityJobFairID\n      Salary\n      ...\n      ManagerName\n      ManagerID\n      RecruitmentSource\n      PerformanceScore\n      EngagementSurvey\n      EmpSatisfaction\n      SpecialProjectsCount\n      LastPerformanceReview_Date\n      DaysLateLast30\n      Absences\n    \n  \n  \n    \n      0\n      Adinolfi, Wilson  K\n      10026\n      0\n      0\n      1\n      1\n      5\n      4\n      0\n      62506\n      ...\n      Michael Albert\n      22.0\n      LinkedIn\n      Exceeds\n      4.60\n      5\n      0\n      1/17/2019\n      0\n      1\n    \n    \n      1\n      Ait Sidi, Karthikeyan\n      10084\n      1\n      1\n      1\n      5\n      3\n      3\n      0\n      104437\n      ...\n      Simon Roup\n      4.0\n      Indeed\n      Fully Meets\n      4.96\n      3\n      6\n      2/24/2016\n      0\n      17\n    \n    \n      2\n      Akinkuolie, Sarah\n      10196\n      1\n      1\n      0\n      5\n      5\n      3\n      0\n      64955\n      ...\n      Kissy Sullivan\n      20.0\n      LinkedIn\n      Fully Meets\n      3.02\n      3\n      0\n      5/15/2012\n      0\n      3\n    \n    \n      3\n      Alagbe,Trina\n      10088\n      1\n      1\n      0\n      1\n      5\n      3\n      0\n      64991\n      ...\n      Elijiah Gray\n      16.0\n      Indeed\n      Fully Meets\n      4.84\n      5\n      0\n      1/3/2019\n      0\n      15\n    \n    \n      4\n      Anderson, Carol\n      10069\n      0\n      2\n      0\n      5\n      5\n      3\n      0\n      50825\n      ...\n      Webster Butler\n      39.0\n      Google Search\n      Fully Meets\n      5.00\n      4\n      0\n      2/1/2016\n      0\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      306\n      Woodson, Jason\n      10135\n      0\n      0\n      1\n      1\n      5\n      3\n      0\n      65893\n      ...\n      Kissy Sullivan\n      20.0\n      LinkedIn\n      Fully Meets\n      4.07\n      4\n      0\n      2/28/2019\n      0\n      13\n    \n    \n      307\n      Ybarra, Catherine\n      10301\n      0\n      0\n      0\n      5\n      5\n      1\n      0\n      48513\n      ...\n      Brannon Miller\n      12.0\n      Google Search\n      PIP\n      3.20\n      2\n      0\n      9/2/2015\n      5\n      4\n    \n    \n      308\n      Zamora, Jennifer\n      10010\n      0\n      0\n      0\n      1\n      3\n      4\n      0\n      220450\n      ...\n      Janet King\n      2.0\n      Employee Referral\n      Exceeds\n      4.60\n      5\n      6\n      2/21/2019\n      0\n      16\n    \n    \n      309\n      Zhou, Julia\n      10043\n      0\n      0\n      0\n      1\n      3\n      3\n      0\n      89292\n      ...\n      Simon Roup\n      4.0\n      Employee Referral\n      Fully Meets\n      5.00\n      3\n      5\n      2/1/2019\n      0\n      11\n    \n    \n      310\n      Zima, Colleen\n      10271\n      0\n      4\n      0\n      1\n      5\n      3\n      0\n      45046\n      ...\n      David Stanley\n      14.0\n      LinkedIn\n      Fully Meets\n      4.50\n      5\n      0\n      1/30/2019\n      0\n      2\n    \n  \n\n311 rows × 36 columns\n\n\n\n(1) 데이터를 조사하고 올바르게 분석한 사람을 모두 고르라. (모두 맞칠경우만 정답으로 인정)\n\n소윤: 근무인원수가 가장 많은 인종(RaceDesc)은 ’White’이며 이는 ’Asian’인종과 ’Black or African American’의 합보다 많다.\n다호: ’RaceDesc==White’의 성별(Sex)임금차이는 2000이상이다.\n하니: 퇴직한사람(Termd==1)은 모두 104명이며 백인여성의 퇴직자수가 가장 많다.\n도한: 퇴직한사람중 아시아인의 비율은 10%가 넘지 않는다.\n\n(풀이)\n모두 참이다.\n데이터조사\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 311 entries, 0 to 310\nData columns (total 36 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   Employee_Name               311 non-null    object \n 1   EmpID                       311 non-null    int64  \n 2   MarriedID                   311 non-null    int64  \n 3   MaritalStatusID             311 non-null    int64  \n 4   GenderID                    311 non-null    int64  \n 5   EmpStatusID                 311 non-null    int64  \n 6   DeptID                      311 non-null    int64  \n 7   PerfScoreID                 311 non-null    int64  \n 8   FromDiversityJobFairID      311 non-null    int64  \n 9   Salary                      311 non-null    int64  \n 10  Termd                       311 non-null    int64  \n 11  PositionID                  311 non-null    int64  \n 12  Position                    311 non-null    object \n 13  State                       311 non-null    object \n 14  Zip                         311 non-null    int64  \n 15  DOB                         311 non-null    object \n 16  Sex                         311 non-null    object \n 17  MaritalDesc                 311 non-null    object \n 18  CitizenDesc                 311 non-null    object \n 19  HispanicLatino              311 non-null    object \n 20  RaceDesc                    311 non-null    object \n 21  DateofHire                  311 non-null    object \n 22  DateofTermination           104 non-null    object \n 23  TermReason                  311 non-null    object \n 24  EmploymentStatus            311 non-null    object \n 25  Department                  311 non-null    object \n 26  ManagerName                 311 non-null    object \n 27  ManagerID                   303 non-null    float64\n 28  RecruitmentSource           311 non-null    object \n 29  PerformanceScore            311 non-null    object \n 30  EngagementSurvey            311 non-null    float64\n 31  EmpSatisfaction             311 non-null    int64  \n 32  SpecialProjectsCount        311 non-null    int64  \n 33  LastPerformanceReview_Date  311 non-null    object \n 34  DaysLateLast30              311 non-null    int64  \n 35  Absences                    311 non-null    int64  \ndtypes: float64(2), int64(16), object(18)\nmemory usage: 87.6+ KB\n\n\n\nEmpID가 missing이 없는 열임\n\n소윤: 근무인원수가 가장 많은 인종(RaceDesc)은 ’White’이며 이는 ’Asian’인종과 ’Black or African American’의 합보다 많다. — 참\n\ndf.groupby(by='RaceDesc').agg({'EmpID':len})\n\n\n\n\n\n  \n    \n      \n      EmpID\n    \n    \n      RaceDesc\n      \n    \n  \n  \n    \n      American Indian or Alaska Native\n      3\n    \n    \n      Asian\n      29\n    \n    \n      Black or African American\n      80\n    \n    \n      Hispanic\n      1\n    \n    \n      Two or more races\n      11\n    \n    \n      White\n      187\n    \n  \n\n\n\n\n\n29+80\n\n109\n\n\n다호: ’RaceDesc==White’의 성별(Sex)임금차이는 2000이상이다. — 참\n\ndf.groupby(by=['RaceDesc','Sex']).agg({'Salary':np.mean})\n\n\n\n\n\n  \n    \n      \n      \n      Salary\n    \n    \n      RaceDesc\n      Sex\n      \n    \n  \n  \n    \n      American Indian or Alaska Native\n      F\n      63436.500000\n    \n    \n      M\n      70545.000000\n    \n    \n      Asian\n      F\n      67520.117647\n    \n    \n      M\n      69939.416667\n    \n    \n      Black or African American\n      F\n      66963.829787\n    \n    \n      M\n      85066.121212\n    \n    \n      Hispanic\n      M\n      83667.000000\n    \n    \n      Two or more races\n      F\n      58068.500000\n    \n    \n      M\n      62313.800000\n    \n    \n      White\n      F\n      68846.519231\n    \n    \n      M\n      65334.132530\n    \n  \n\n\n\n\n\n68846.519231 - 65334.132530\n\n3512.386700999996\n\n\n하니: 퇴직한사람(Termd==1)은 모두 104명이며 백인여성의 퇴직자수가 가장 많다. — 참\n\n(df.Termd==1).sum()\n\n104\n\n\n\ndf.groupby(by=['RaceDesc','Sex']).agg({'Termd':np.sum})\n\n\n\n\n\n  \n    \n      \n      \n      Termd\n    \n    \n      RaceDesc\n      Sex\n      \n    \n  \n  \n    \n      American Indian or Alaska Native\n      F\n      0\n    \n    \n      M\n      0\n    \n    \n      Asian\n      F\n      6\n    \n    \n      M\n      3\n    \n    \n      Black or African American\n      F\n      15\n    \n    \n      M\n      14\n    \n    \n      Hispanic\n      M\n      0\n    \n    \n      Two or more races\n      F\n      2\n    \n    \n      M\n      1\n    \n    \n      White\n      F\n      37\n    \n    \n      M\n      26\n    \n  \n\n\n\n\n도한: 퇴직한사람중 아시아인의 비율은 10%가 넘지 않는다. — 참\n\n(df.Termd==1).sum()\n\n104\n\n\n\ndf.groupby(by=['RaceDesc']).agg({'Termd':np.sum})\n\n\n\n\n\n  \n    \n      \n      Termd\n    \n    \n      RaceDesc\n      \n    \n  \n  \n    \n      American Indian or Alaska Native\n      0\n    \n    \n      Asian\n      9\n    \n    \n      Black or African American\n      29\n    \n    \n      Hispanic\n      0\n    \n    \n      Two or more races\n      3\n    \n    \n      White\n      63\n    \n  \n\n\n\n\n\n9/104\n\n0.08653846153846154\n\n\n(2) White, Black or African American, Asian 인종(RaceDesc)에 대하여 남여급여차이를 조사하고자 한다. 아래와 같은 Boxplot을 생성하라.\n(풀이)\n\nggplot(data=df.query('RaceDesc == \"White\" or RaceDesc == \"Black or African American\" or RaceDesc == \"Asian\"'))\\\n+geom_boxplot(aes(x='RaceDesc',y='Salary',color='Sex'))\n\n\n\n\n<ggplot: (8776333683953)>"
  },
  {
    "objectID": "posts/2022-11-21-12wk-1.html",
    "href": "posts/2022-11-21-12wk-1.html",
    "title": "12wk-1",
    "section": "",
    "text": "folium– 기본지도 그리기, 기본지도 위에 마커 추가, heatmap, heatmap animation"
  },
  {
    "objectID": "posts/2022-11-21-12wk-1.html#folium.map",
    "href": "posts/2022-11-21-12wk-1.html#folium.map",
    "title": "12wk-1",
    "section": "folium.Map()",
    "text": "folium.Map()\n- global view\n\nfolium.Map(scrollWheelZoom=False)\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n줌스크롤을 False 시키는 방법: scrollWheelZoom=False\n이 옵션을 확인하려면? (1) 도움말 (2) folium 공식홈페이지 (3) Leaflet 공식홈페이지\n\n- location과 scale을 조정하는 방법\n\nfolium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대 \n    zoom_start=20\n)\n# 35.8475,127.1305 # 자연대본관 \n# 35.8468,127.1294 # 분수대 \n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- tiles 옵션을 주어서 지도의 외형을 변경하여 보자.\n\ntiles=\"OpenStreetMap\"\ntiles=\"Stamen Terrain\", tiles=\"Stamen Toner\", tiles=\"Stamen Watercolor\"\ntiles=\"CartoDB positron\", tiles=\"CartoDB dark_matter\"\n\n\nfolium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대 \n    zoom_start=15,\n    tiles=\"CartoDB positron\"\n)\n# 35.8475,127.1305 # 자연대본관 \n# 35.8468,127.1294 # 분수대 \n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-21-12wk-1.html#folium.marker",
    "href": "posts/2022-11-21-12wk-1.html#folium.marker",
    "title": "12wk-1",
    "section": "folium.Marker()",
    "text": "folium.Marker()\n- 마커생성\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305] # 자연대본관  \n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118] # 집 \n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 마커에 팝업내용 추가\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    popup = \"JBNU\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"HOME\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 마커의 아이콘 변경\n\nfolium.Marker()에서 icon=folium.Icon(color='red',icon='university',prefix='fa') 와 같은 식으로 옵션을 추가\nicon=‘university’ 대신에 `street-view’,‘tree’,‘plane’,‘bell’ 등을 추가할 수 있음.\n아이콘들은 여기 참고. ’glyphicon glyphicon-” 부분을 제외한 문자열을 넣으면 된다.\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = \"JBNU\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"HOME\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 마커의 팝업내용을 HTML로 넣기 (1)\n\n\"JBNU\" 대신에 \"<h2> JBNU </h2><br>\"\n\"HOME\" 대신에 \"<h5> HOME </h5><br>\"\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = \"<h2> JBNU </h2><br>\"\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 마커의 팝업내용을 HTML로 넣기 (2)\n\n데이터프레임을 HTML로 바꾸어서 넣어보자.\n\n\n_df = pd.DataFrame({'year':[2019,2020,2021,2022], 'students':[35,30,33,26]})\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = '<h2> JBNU </h2><br>' + _df.to_html()\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 마커의 팝업내용을 HTML로 넣기 (3)\n\n데이터프레임을 HTML로 바꾸어서 넣어보자.\n팝업시 크기를 조절할 수 있게 해보자. (folium.IFrame, folium.Popup 이용)\n\n\n_iframe = folium.IFrame('<h2> JBNU </h2><br>'+_df.to_html(),width=150,height=200)\n_popup = folium.Popup(_iframe)\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = _popup\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 마커의 팝업내용을 HTML로 넣기 (4)\n\n논리구조상 HTML 오브젝트를 아무거나 넣을 수 있음 \\(\\to\\) 그림도 넣을 수 있을까?\n그림파일을 HTML로 바꾸어서 넣어보자.\n\n\nimport matplotlib.pyplot as plt\n\n\n_df.plot.line(x='year',y='students')\nfig = plt.gcf() \n\n\n\n\n\nfig.savefig('test.png') \n\n\nimport base64\n\n\n_encoded = base64.b64encode(open('test.png','rb').read())\n_myhtml = '<img src=\"data:image/png;base64,{}\">'.format\n_iframe = folium.IFrame(_myhtml(_encoded.decode('UTF-8')),width=400,height=300)\n_popup = folium.Popup(_iframe)\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.Marker(\n    location = [35.8475,127.1305], # 자연대본관  \n    icon=folium.Icon(color='red',icon='university',prefix='fa'),\n    popup = _popup\n)\nhome = folium.Marker(\n    location = [35.8368, 127.1118], # 집 \n    popup = \"<h5> HOME </h5><br>\",\n    tooltip = \"클릭해주세요\"\n)\njbnu.add_to(m)\nhome.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-21-12wk-1.html#folium.circlemarker",
    "href": "posts/2022-11-21-12wk-1.html#folium.circlemarker",
    "title": "12wk-1",
    "section": "folium.CircleMarker()",
    "text": "folium.CircleMarker()\n- 서클마커 생성\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\"\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 서클마커 색상 및 크기변경\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\",\n    radius = 20,\n    color='red'\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n- 서클마커 테두리 삭제 및 fill\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8475,127.1305], # 자연대본관  \n    zoom_start=14,\n    tiles=\"CartoDB positron\"\n)\njbnu = folium.CircleMarker(\n    location = [35.8475,127.1305], \n    popup = \"JBNU\",\n    radius = 20,\n    color=None,\n    fill=True,\n    fill_color='blue'\n)\njbnu.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n실제로는 라인, 사각형, 폴리곤등 좀 더 다양한 마커가 있다. folium으로 공간정보를 시각화할때는 마커를 그냥 지옴처럼 생각하고 시각화하는 경우가 많다. 그런데 하나의 지옴을 만드는데 너무 많은 노력이 들어가는 점이 단점"
  },
  {
    "objectID": "posts/2022-11-21-12wk-1.html#folium.plugins.heatmap",
    "href": "posts/2022-11-21-12wk-1.html#folium.plugins.heatmap",
    "title": "12wk-1",
    "section": "folium.plugins.HeatMap()",
    "text": "folium.plugins.HeatMap()\n- Heatmap은 폴리움에서 데이터 시각화를 하기에 적합한 기본도구임\n\nnp.random.seed(43052)\ndata = np.random.multivariate_normal(mean=[28,77],cov=[[5,0],[0,5]],size=30)\ndata\n\narray([[28.85735428, 79.42428788],\n       [30.55532984, 77.68847119],\n       [28.53170889, 77.79593099],\n       [24.28125031, 73.90802517],\n       [23.69144396, 73.67671933],\n       [28.01548519, 76.92198975],\n       [27.2317469 , 78.58527488],\n       [24.53184497, 80.00897792],\n       [27.87356664, 75.1436758 ],\n       [24.72650472, 76.20709939],\n       [27.23438418, 78.69678208],\n       [32.97480623, 73.16060104],\n       [31.55348967, 77.83018414],\n       [29.72735877, 76.03486715],\n       [29.72105093, 79.05284743],\n       [26.98894987, 77.71250511],\n       [29.82617838, 76.63020934],\n       [30.53293541, 77.4658718 ],\n       [24.23985514, 76.32658052],\n       [29.39532886, 76.33151468],\n       [27.43952815, 74.4129713 ],\n       [25.10890152, 75.58970704],\n       [26.43701446, 79.83294912],\n       [29.88171925, 73.72508327],\n       [27.62328548, 79.88574109],\n       [28.81568439, 76.77756838],\n       [26.14680892, 75.5387959 ],\n       [28.15755534, 71.48729756],\n       [31.11434115, 76.87627808],\n       [26.11894251, 76.15653999]])\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [28,77],\n    zoom_start=5\n)\nfolium.plugins.HeatMap(data).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-21-12wk-1.html#folium.plugins.heatmapwithtime",
    "href": "posts/2022-11-21-12wk-1.html#folium.plugins.heatmapwithtime",
    "title": "12wk-1",
    "section": "folium.plugins.HeatMapWithTime()",
    "text": "folium.plugins.HeatMapWithTime()\n\nnp.random.seed(43052)\ndata1 = np.random.multivariate_normal(mean=[28,77],cov=[[5,0],[0,5]],size=20)\ndata2 = np.random.multivariate_normal(mean=[25,80],cov=[[5,0],[0,5]],size=20)\ndata3 = np.random.multivariate_normal(mean=[31,70],cov=[[5,0],[0,5]],size=20)\ndata = np.array([data1,data2,data3])\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [28,77],\n    zoom_start=5\n)\nfolium.plugins.HeatMapWithTime(\n    data.tolist(),\n    index=['t1','t2','t3'], # time_index \n    radius=15,\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-21-12wk-1.html#예제-earthquakes",
    "href": "posts/2022-11-21-12wk-1.html#예제-earthquakes",
    "title": "12wk-1",
    "section": "예제: earthquakes",
    "text": "예제: earthquakes\n\nStep1: Pandas 정리\n\ndf=pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Latitude\n      Longitude\n      Magnitude\n    \n  \n  \n    \n      0\n      01/02/1965\n      19.2460\n      145.6160\n      6.0\n    \n    \n      1\n      01/04/1965\n      1.8630\n      127.3520\n      5.8\n    \n    \n      2\n      01/05/1965\n      -20.5790\n      -173.9720\n      6.2\n    \n    \n      3\n      01/08/1965\n      -59.0760\n      -23.5570\n      5.8\n    \n    \n      4\n      01/09/1965\n      11.9380\n      126.4270\n      5.8\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      23407\n      12/28/2016\n      38.3917\n      -118.8941\n      5.6\n    \n    \n      23408\n      12/28/2016\n      38.3777\n      -118.8957\n      5.5\n    \n    \n      23409\n      12/28/2016\n      36.9179\n      140.4262\n      5.9\n    \n    \n      23410\n      12/29/2016\n      -9.0283\n      118.6639\n      6.3\n    \n    \n      23411\n      12/30/2016\n      37.3973\n      141.4103\n      5.5\n    \n  \n\n23412 rows × 4 columns\n\n\n\n\nlst =[ \n    df.assign(Year = list(map(lambda x: x.split('/')[-1], df.Date)))\\\n    .assign(Year = lambda df: list(map(lambda x: x.split('-')[0] ,df.Year)))\\\n    .groupby('Year')\\\n    .pipe(list)[_year][1]\\\n    .loc[:,['Latitude','Longitude']]\\\n    .pipe(np.array).tolist()\n    \n    for _year in range(2016-1965+1) # 현장강의에서 실수한것 수정\n]\n\n\n현장강의에서 실수한것 수정\n\n\n\nStep2: folium\n\nm=folium.Map(scrollWheelZoom=False)\nfolium.plugins.HeatMapWithTime(\n    lst,\n    radius=5,\n    index=list(range(1965,2017)) # 현장강의에서 실수한것 수정\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html",
    "href": "posts/2022-11-14-11wk-1.html",
    "title": "11wk-1",
    "section": "",
    "text": "판다스백엔드– 야후 파이낸스, 핸드폰점유율, 팁, 인사자료 분석"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#line",
    "href": "posts/2022-11-14-11wk-1.html#line",
    "title": "11wk-1",
    "section": "line",
    "text": "line"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#data1-야후-파이낸스",
    "href": "posts/2022-11-14-11wk-1.html#data1-야후-파이낸스",
    "title": "11wk-1",
    "section": "data1: 야후 파이낸스",
    "text": "data1: 야후 파이낸스\n- yahoo finance: https://finance.yahoo.com/\n\nsymbols = ['AMZN','AAPL','GOOG','MSFT','NFLX','NVDA','TSLA']\nstart = '2020-01-01'\nend = '2022-10-30'\ndf = pdr.get_data_yahoo(symbols,start,end)['Adj Close']\n\n\ndf\n\n\n\n\n\n  \n    \n      Symbols\n      AMZN\n      AAPL\n      GOOG\n      MSFT\n      NFLX\n      NVDA\n      TSLA\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2019-12-31\n      92.391998\n      71.920570\n      66.850998\n      153.313202\n      323.570007\n      58.637028\n      27.888666\n    \n    \n      2020-01-02\n      94.900497\n      73.561531\n      68.368500\n      156.151947\n      329.809998\n      59.785847\n      28.684000\n    \n    \n      2020-01-03\n      93.748497\n      72.846367\n      68.032997\n      154.207596\n      325.899994\n      58.828911\n      29.534000\n    \n    \n      2020-01-06\n      95.143997\n      73.426834\n      69.710503\n      154.606186\n      335.829987\n      59.075623\n      30.102667\n    \n    \n      2020-01-07\n      95.343002\n      73.081490\n      69.667000\n      153.196518\n      330.750000\n      59.790825\n      31.270666\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2022-10-24\n      119.820000\n      149.202484\n      102.970001\n      246.555176\n      282.450012\n      125.989998\n      211.250000\n    \n    \n      2022-10-25\n      120.599998\n      152.087708\n      104.930000\n      249.955582\n      291.019989\n      132.610001\n      222.419998\n    \n    \n      2022-10-26\n      115.660004\n      149.102661\n      94.820000\n      230.669937\n      298.619995\n      128.960007\n      224.639999\n    \n    \n      2022-10-27\n      110.959999\n      144.560196\n      92.599998\n      226.112778\n      296.940002\n      131.759995\n      225.089996\n    \n    \n      2022-10-28\n      103.410004\n      155.482086\n      96.580002\n      235.207138\n      295.720001\n      138.339996\n      228.520004\n    \n  \n\n714 rows × 7 columns"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-1개의-y를-그리기",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-1개의-y를-그리기",
    "title": "11wk-1",
    "section": "matplotlib: 1개의 y를 그리기",
    "text": "matplotlib: 1개의 y를 그리기\n- 예시1: 1개의 y를 그리기\n\ndf.reset_index().plot(x='Date',y='AMZN')\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n\ndf.reset_index().plot(x='Date',y='AMZN',kind='line')\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n\ndf.reset_index().plot.line(x='Date',y='AMZN')\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-2개의-y를-겹쳐서-그리기",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-2개의-y를-겹쳐서-그리기",
    "title": "11wk-1",
    "section": "matplotlib: 2개의 y를 겹쳐서 그리기",
    "text": "matplotlib: 2개의 y를 겹쳐서 그리기\n- 2개의 y를 겹쳐그리기\n\ndf.reset_index().plot(x='Date',y=['AMZN','AAPL'])\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-모든-y를-겹쳐서-그리기",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-모든-y를-겹쳐서-그리기",
    "title": "11wk-1",
    "section": "matplotlib: 모든 y를 겹쳐서 그리기",
    "text": "matplotlib: 모든 y를 겹쳐서 그리기\n- 모든 y를 겹쳐서 그리기\n\ndf.reset_index().plot(x='Date')\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-그림크기조정",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-그림크기조정",
    "title": "11wk-1",
    "section": "matplotlib: 그림크기조정",
    "text": "matplotlib: 그림크기조정\n- 모든 y를 겹쳐서 그리기 + 그림크기조정\n\ndf.reset_index().plot(x='Date',figsize=(8,8))\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-서브플랏",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-서브플랏",
    "title": "11wk-1",
    "section": "matplotlib: 서브플랏",
    "text": "matplotlib: 서브플랏\n- 예시1: 기본 서브플랏\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(15,15))\n\narray([<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>,\n       <AxesSubplot:xlabel='Date'>], dtype=object)\n\n\n\n\n\n- 예시2: 레이아웃 조정\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(15,15),layout=(4,2))\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-폰트조정",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-폰트조정",
    "title": "11wk-1",
    "section": "matplotlib: 폰트조정",
    "text": "matplotlib: 폰트조정\n- 예시1\n\ndf.reset_index().plot.line(x='Date',subplots=True,figsize=(15,15),layout=(4,2),fontsize=15)\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-레전드삭제",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-레전드삭제",
    "title": "11wk-1",
    "section": "matplotlib: 레전드삭제",
    "text": "matplotlib: 레전드삭제\n- 레전드삭제\n\ndf.reset_index().plot.line(x='Date',subplots=True,layout=(4,2),legend=False,figsize=(10,10))\n\narray([[<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n       [<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-모든y를-겹쳐서-그리기",
    "href": "posts/2022-11-14-11wk-1.html#plotly-모든y를-겹쳐서-그리기",
    "title": "11wk-1",
    "section": "plotly 모든y를 겹쳐서 그리기",
    "text": "plotly 모든y를 겹쳐서 그리기\n\ndf.reset_index().melt(id_vars='Date').plot.line(backend='plotly',x='Date',y='value',color='Symbols')"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#data2-핸드폰점유율",
    "href": "posts/2022-11-14-11wk-1.html#data2-핸드폰점유율",
    "title": "11wk-1",
    "section": "data2: 핸드폰점유율",
    "text": "data2: 핸드폰점유율\n\ndf = pd.read_csv('https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Samsung\n      Apple\n      Huawei\n      Xiaomi\n      Oppo\n      Mobicel\n      Motorola\n      LG\n      Others\n      Realme\n      Google\n      Nokia\n      Lenovo\n      OnePlus\n      Sony\n      Asus\n    \n  \n  \n    \n      0\n      2019-10\n      31.49\n      22.09\n      10.02\n      7.79\n      4.10\n      3.15\n      2.41\n      2.40\n      9.51\n      0.54\n      2.35\n      0.95\n      0.96\n      0.70\n      0.84\n      0.74\n    \n    \n      1\n      2019-11\n      31.36\n      22.90\n      10.18\n      8.16\n      4.42\n      3.41\n      2.40\n      2.40\n      9.10\n      0.78\n      0.66\n      0.97\n      0.97\n      0.73\n      0.83\n      0.75\n    \n    \n      2\n      2019-12\n      31.37\n      24.79\n      9.95\n      7.73\n      4.23\n      3.19\n      2.50\n      2.54\n      8.13\n      0.84\n      0.75\n      0.90\n      0.87\n      0.74\n      0.77\n      0.70\n    \n    \n      3\n      2020-01\n      31.29\n      24.76\n      10.61\n      8.10\n      4.25\n      3.02\n      2.42\n      2.40\n      7.55\n      0.88\n      0.69\n      0.88\n      0.86\n      0.79\n      0.80\n      0.69\n    \n    \n      4\n      2020-02\n      30.91\n      25.89\n      10.98\n      7.80\n      4.31\n      2.89\n      2.36\n      2.34\n      7.06\n      0.89\n      0.70\n      0.81\n      0.77\n      0.78\n      0.80\n      0.69\n    \n    \n      5\n      2020-03\n      30.80\n      27.03\n      10.70\n      7.70\n      4.30\n      2.87\n      2.35\n      2.28\n      6.63\n      0.93\n      0.73\n      0.72\n      0.74\n      0.78\n      0.76\n      0.66\n    \n    \n      6\n      2020-04\n      30.41\n      28.79\n      10.28\n      7.60\n      4.20\n      2.75\n      2.51\n      2.28\n      5.84\n      0.90\n      0.75\n      0.69\n      0.71\n      0.80\n      0.76\n      0.70\n    \n    \n      7\n      2020-05\n      30.18\n      26.72\n      10.39\n      8.36\n      4.70\n      3.12\n      2.46\n      2.19\n      6.31\n      1.04\n      0.70\n      0.73\n      0.77\n      0.81\n      0.78\n      0.76\n    \n    \n      8\n      2020-06\n      31.06\n      25.26\n      10.69\n      8.55\n      4.65\n      3.18\n      2.57\n      2.11\n      6.39\n      1.04\n      0.68\n      0.74\n      0.75\n      0.77\n      0.78\n      0.75\n    \n    \n      9\n      2020-07\n      30.95\n      24.82\n      10.75\n      8.94\n      4.69\n      3.46\n      2.45\n      2.03\n      6.41\n      1.13\n      0.65\n      0.76\n      0.74\n      0.76\n      0.75\n      0.72\n    \n    \n      10\n      2020-08\n      31.04\n      25.15\n      10.73\n      8.90\n      4.69\n      3.38\n      2.39\n      1.96\n      6.31\n      1.18\n      0.63\n      0.74\n      0.72\n      0.75\n      0.73\n      0.70\n    \n    \n      11\n      2020-09\n      30.57\n      24.98\n      10.58\n      9.49\n      4.94\n      3.50\n      2.27\n      1.88\n      6.12\n      1.45\n      0.63\n      0.74\n      0.67\n      0.81\n      0.69\n      0.67\n    \n    \n      12\n      2020-10\n      30.25\n      26.53\n      10.44\n      9.67\n      4.83\n      2.54\n      2.21\n      1.79\n      6.04\n      1.55\n      0.63\n      0.69\n      0.65\n      0.85\n      0.67\n      0.64"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-2개의-y를-겹쳐그리기",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-2개의-y를-겹쳐그리기",
    "title": "11wk-1",
    "section": "matplotlib: 2개의 y를 겹쳐그리기",
    "text": "matplotlib: 2개의 y를 겹쳐그리기\n- 예시1\n\ndf.plot.bar(x='Date',y=['Samsung','Apple'])\n\n<AxesSubplot:xlabel='Date'>\n\n\n\n\n\n- 예시2: width 옵션으로 폭조정\n\ndf.plot.bar(x='Date',y=['Samsung','Apple'],width=0.8)\n\n<AxesSubplot:xlabel='Date'>"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#matplotlib-2개의-y를-겹쳐그리기-xy-플립",
    "href": "posts/2022-11-14-11wk-1.html#matplotlib-2개의-y를-겹쳐그리기-xy-플립",
    "title": "11wk-1",
    "section": "matplotlib: 2개의 y를 겹쳐그리기 + x,y 플립",
    "text": "matplotlib: 2개의 y를 겹쳐그리기 + x,y 플립\n- 예시1: barh를 이용하여 플립\n\ndf.plot.barh(x='Date',y=['Samsung','Apple'],width=0.8)\n\n<AxesSubplot:ylabel='Date'>"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-모든y를-stacked-bar로-나타내기",
    "href": "posts/2022-11-14-11wk-1.html#plotly-모든y를-stacked-bar로-나타내기",
    "title": "11wk-1",
    "section": "plotly: 모든y를 stacked bar로 나타내기",
    "text": "plotly: 모든y를 stacked bar로 나타내기\n- 예시1\n\ndf.melt(id_vars='Date').plot.bar(backend='plotly',x='Date',y='value',color='variable')"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-3개의-y를-겹쳐그리기",
    "href": "posts/2022-11-14-11wk-1.html#plotly-3개의-y를-겹쳐그리기",
    "title": "11wk-1",
    "section": "plotly: 3개의 y를 겹쳐그리기",
    "text": "plotly: 3개의 y를 겹쳐그리기\n- 예시1\n\ndf.melt(id_vars='Date')\\\n.query(' variable==\"Samsung\" or variable==\"Apple\" or variable==\"Huawei\"')\\\n.plot.bar(backend='plotly',x='Date',y='value',color='variable',barmode='group')"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-3개의-y를-겹쳐그리기-text",
    "href": "posts/2022-11-14-11wk-1.html#plotly-3개의-y를-겹쳐그리기-text",
    "title": "11wk-1",
    "section": "plotly: 3개의 y를 겹쳐그리기 + text",
    "text": "plotly: 3개의 y를 겹쳐그리기 + text\n- 예시1\n\ndf.melt(id_vars='Date')\\\n.query(' variable==\"Samsung\" or variable==\"Apple\" or variable==\"Huawei\"')\\\n.plot.bar(backend='plotly',x='value',y='Date',color='variable',barmode='group',text='value',height=1200)"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-면분할로-subplot그리기-facet_col",
    "href": "posts/2022-11-14-11wk-1.html#plotly-면분할로-subplot그리기-facet_col",
    "title": "11wk-1",
    "section": "plotly: 면분할로 subplot그리기 (facet_col)",
    "text": "plotly: 면분할로 subplot그리기 (facet_col)\n\ndf.melt(id_vars='Date').query(' variable==\"Samsung\" or variable==\"Apple\"')\\\n.plot.bar(backend='plotly',x='Date',y='value',color='variable',barmode='group',facet_col='variable')"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-면분할로-subplot그리기-facet_row",
    "href": "posts/2022-11-14-11wk-1.html#plotly-면분할로-subplot그리기-facet_row",
    "title": "11wk-1",
    "section": "plotly: 면분할로 subplot그리기 (facet_row)",
    "text": "plotly: 면분할로 subplot그리기 (facet_row)\n\ndf.melt(id_vars='Date').query(' variable==\"Samsung\" or variable==\"Apple\"')\\\n.plot.bar(backend='plotly',x='Date',y='value',color='variable',barmode='group',facet_row='variable')"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#data3-팁",
    "href": "posts/2022-11-14-11wk-1.html#data3-팁",
    "title": "11wk-1",
    "section": "data3: 팁",
    "text": "data3: 팁\n\nimport plotly.express as px \ndf = px.data.tips() \ndf\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n    \n  \n\n244 rows × 7 columns"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-팁의-박스플랏",
    "href": "posts/2022-11-14-11wk-1.html#plotly-팁의-박스플랏",
    "title": "11wk-1",
    "section": "plotly: 팁의 박스플랏",
    "text": "plotly: 팁의 박스플랏\n- y=‘tip’\n\ndf.plot.box(backend='plotly',y='tip',width=500,height=500)"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-시간에-따른-팁의-박스플랏",
    "href": "posts/2022-11-14-11wk-1.html#plotly-시간에-따른-팁의-박스플랏",
    "title": "11wk-1",
    "section": "plotly: 시간에 따른 팁의 박스플랏",
    "text": "plotly: 시간에 따른 팁의 박스플랏\n- y='tip', x='time'\n\ndf.plot.box(backend='plotly',x='time',y='tip',width=500,height=500)\n\n\n                                                \n\n\n\n저녁에 좀 더 잘주는것 같음"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-시간과-성별에-따른-팁의-박스플랏",
    "href": "posts/2022-11-14-11wk-1.html#plotly-시간과-성별에-따른-팁의-박스플랏",
    "title": "11wk-1",
    "section": "plotly: 시간과 성별에 따른 팁의 박스플랏",
    "text": "plotly: 시간과 성별에 따른 팁의 박스플랏\n- 예시1: y='tip', x='time', color='sex'\n\ndf.plot.box(backend='plotly',x='time',y='tip',color='sex',width=500,height=500)\n\n\n                                                \n\n\n- 예시2: y='tip', x='time', color='sex', points='all'\n\ndf.plot.box(backend='plotly',x='time',y='tip',color='sex',points='all',width=500,height=500)"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-시간성별요일에-따른-팁의-박스플랏",
    "href": "posts/2022-11-14-11wk-1.html#plotly-시간성별요일에-따른-팁의-박스플랏",
    "title": "11wk-1",
    "section": "plotly: 시간,성별,요일에 따른 팁의 박스플랏",
    "text": "plotly: 시간,성별,요일에 따른 팁의 박스플랏\n- 예시1: y='tip', x='time', color='sex', facet_col='day'\n\ndf.plot.box(backend='plotly', facet_row='day',x='time',y='tip',color='sex',points='all',height=1000)\n\n\n                                                \n\n\n- 예시2: y='tip', color='sex', facet_col='time', facet_row='day'\n\ndf.plot.box(backend='plotly',facet_col='time', facet_row='day',y='tip',color='sex',points='all',height=1000)"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#plotly-시간성별요일흡연에-따른-팁의-박스플랏",
    "href": "posts/2022-11-14-11wk-1.html#plotly-시간성별요일흡연에-따른-팁의-박스플랏",
    "title": "11wk-1",
    "section": "plotly: 시간,성별,요일,흡연에 따른 팁의 박스플랏",
    "text": "plotly: 시간,성별,요일,흡연에 따른 팁의 박스플랏\n\ndf.plot.box(backend='plotly',facet_col='time', facet_row='day',x='smoker',y='tip',color='sex',points='all',height=1000)"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#data4-인사자료",
    "href": "posts/2022-11-14-11wk-1.html#data4-인사자료",
    "title": "11wk-1",
    "section": "data4: 인사자료",
    "text": "data4: 인사자료\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/HRDataset_v14.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Employee_Name\n      EmpID\n      MarriedID\n      MaritalStatusID\n      GenderID\n      EmpStatusID\n      DeptID\n      PerfScoreID\n      FromDiversityJobFairID\n      Salary\n      ...\n      ManagerName\n      ManagerID\n      RecruitmentSource\n      PerformanceScore\n      EngagementSurvey\n      EmpSatisfaction\n      SpecialProjectsCount\n      LastPerformanceReview_Date\n      DaysLateLast30\n      Absences\n    \n  \n  \n    \n      0\n      Adinolfi, Wilson  K\n      10026\n      0\n      0\n      1\n      1\n      5\n      4\n      0\n      62506\n      ...\n      Michael Albert\n      22.0\n      LinkedIn\n      Exceeds\n      4.60\n      5\n      0\n      1/17/2019\n      0\n      1\n    \n    \n      1\n      Ait Sidi, Karthikeyan\n      10084\n      1\n      1\n      1\n      5\n      3\n      3\n      0\n      104437\n      ...\n      Simon Roup\n      4.0\n      Indeed\n      Fully Meets\n      4.96\n      3\n      6\n      2/24/2016\n      0\n      17\n    \n    \n      2\n      Akinkuolie, Sarah\n      10196\n      1\n      1\n      0\n      5\n      5\n      3\n      0\n      64955\n      ...\n      Kissy Sullivan\n      20.0\n      LinkedIn\n      Fully Meets\n      3.02\n      3\n      0\n      5/15/2012\n      0\n      3\n    \n    \n      3\n      Alagbe,Trina\n      10088\n      1\n      1\n      0\n      1\n      5\n      3\n      0\n      64991\n      ...\n      Elijiah Gray\n      16.0\n      Indeed\n      Fully Meets\n      4.84\n      5\n      0\n      1/3/2019\n      0\n      15\n    \n    \n      4\n      Anderson, Carol\n      10069\n      0\n      2\n      0\n      5\n      5\n      3\n      0\n      50825\n      ...\n      Webster Butler\n      39.0\n      Google Search\n      Fully Meets\n      5.00\n      4\n      0\n      2/1/2016\n      0\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      306\n      Woodson, Jason\n      10135\n      0\n      0\n      1\n      1\n      5\n      3\n      0\n      65893\n      ...\n      Kissy Sullivan\n      20.0\n      LinkedIn\n      Fully Meets\n      4.07\n      4\n      0\n      2/28/2019\n      0\n      13\n    \n    \n      307\n      Ybarra, Catherine\n      10301\n      0\n      0\n      0\n      5\n      5\n      1\n      0\n      48513\n      ...\n      Brannon Miller\n      12.0\n      Google Search\n      PIP\n      3.20\n      2\n      0\n      9/2/2015\n      5\n      4\n    \n    \n      308\n      Zamora, Jennifer\n      10010\n      0\n      0\n      0\n      1\n      3\n      4\n      0\n      220450\n      ...\n      Janet King\n      2.0\n      Employee Referral\n      Exceeds\n      4.60\n      5\n      6\n      2/21/2019\n      0\n      16\n    \n    \n      309\n      Zhou, Julia\n      10043\n      0\n      0\n      0\n      1\n      3\n      3\n      0\n      89292\n      ...\n      Simon Roup\n      4.0\n      Employee Referral\n      Fully Meets\n      5.00\n      3\n      5\n      2/1/2019\n      0\n      11\n    \n    \n      310\n      Zima, Colleen\n      10271\n      0\n      4\n      0\n      1\n      5\n      3\n      0\n      45046\n      ...\n      David Stanley\n      14.0\n      LinkedIn\n      Fully Meets\n      4.50\n      5\n      0\n      1/30/2019\n      0\n      2\n    \n  \n\n311 rows × 36 columns"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#인종별-급여비교-단순-groupby",
    "href": "posts/2022-11-14-11wk-1.html#인종별-급여비교-단순-groupby",
    "title": "11wk-1",
    "section": "인종별 급여비교 (단순 groupby)",
    "text": "인종별 급여비교 (단순 groupby)\n\ndf.groupby('RaceDesc').agg({'Salary':[np.mean,\"count\"]})\n\n\n\n\n\n  \n    \n      \n      Salary\n    \n    \n      \n      mean\n      count\n    \n    \n      RaceDesc\n      \n      \n    \n  \n  \n    \n      American Indian or Alaska Native\n      65806.000000\n      3\n    \n    \n      Asian\n      68521.206897\n      29\n    \n    \n      Black or African American\n      74431.025000\n      80\n    \n    \n      Hispanic\n      83667.000000\n      1\n    \n    \n      Two or more races\n      59998.181818\n      11\n    \n    \n      White\n      67287.545455\n      187"
  },
  {
    "objectID": "posts/2022-11-14-11wk-1.html#급여의-시각화",
    "href": "posts/2022-11-14-11wk-1.html#급여의-시각화",
    "title": "11wk-1",
    "section": "급여의 시각화",
    "text": "급여의 시각화\n- 예시1\n\ndf.query('RaceDesc == \"Black or African American\" or RaceDesc == \"White\"')\\\n.plot.hist(backend='plotly',x='Salary',color='RaceDesc',facet_col='RaceDesc')\n\n\n                                                \n\n\n- 예시2\n\ndf.query('RaceDesc == \"Black or African American\" or RaceDesc == \"White\"')\\\n.plot.hist(backend='plotly',x='Salary',color='RaceDesc',facet_col='RaceDesc',histnorm='probability')\n\n\n                                                \n\n\n\n현장강의에서 histnorm=’probability density’에서 histnorm=’probability’로 수정"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html",
    "href": "posts/2022-09-26-4wk-1.html",
    "title": "04wk-1",
    "section": "",
    "text": "산점도 응용예제 4 (무상관과 독립), mpl의 미세먼지 팁 (1)"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#예제자료",
    "href": "posts/2022-09-26-4wk-1.html#예제자료",
    "title": "04wk-1",
    "section": "예제자료",
    "text": "예제자료\n예시1: 사각형\n\nx1 = np.random.uniform(low=-1,high=1,size=10000)\ny1 = np.random.uniform(low=-1,high=1,size=10000)\n\n\nplt.plot(x1,y1,',')\n\n\n\n\n예시2: 원\n\n_r2 = x1**2+y1**2\n\n\nx2=x1[_r2<1]\ny2=y1[_r2<1]\n\n\nplt.plot(x2,y2,',')\n\n\n\n\n예시3: 이변량정규분포\n\nx3 = np.random.randn(10000)\ny3 = np.random.randn(10000)\n\n\nplt.plot(x3,y3,',')"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#상관계수",
    "href": "posts/2022-09-26-4wk-1.html#상관계수",
    "title": "04wk-1",
    "section": "상관계수",
    "text": "상관계수\n- 예시1, 예시2, 예시3의 산점도를 보고 상관계수가 얼마인지 예상해보라. 실제 계산결과와 확인하라.\n\nnp.corrcoef([x1,y1])\n\narray([[ 1.        , -0.00255095],\n       [-0.00255095,  1.        ]])\n\n\n\nnp.corrcoef([x2,y2])\n\narray([[ 1.        , -0.01437794],\n       [-0.01437794,  1.        ]])\n\n\n\nnp.corrcoef([x3,y3])\n\narray([[ 1.        , -0.02282708],\n       [-0.02282708,  1.        ]])"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#독립",
    "href": "posts/2022-09-26-4wk-1.html#독립",
    "title": "04wk-1",
    "section": "독립",
    "text": "독립\n- 예시1,2,3 중 독립인것은 무엇인가?\n- 예시1 vs 예시2\n\nfig, ax = plt.subplots(1,2,figsize=(8,4)) \nax[0].plot(x1,y1,',',color='gray')\nax[1].plot(x2,y2,',',color='gray')\n\n\n\n\n\ndef g(intval, data, ax, col = 'r'):\n    a,b = intval\n    x,y = data\n    idx = (a<x)&(x<b) \n    ax.plot(x[idx],y[idx],',',color=col)\n\n\ng([-0.1,0.1],[x1,y1],ax[0])\ng([-0.1,0.1],[x2,y2],ax[1])\nfig\n\n\n\n\n\ng([0.79,0.99],[x1,y1],ax[0],col='b')\ng([0.79,0.99],[x2,y2],ax[1],col='b')\nfig\n\n\n\n\n- 예시3\n\nfig,ax = plt.subplots()\nax.plot(x3,y3,',',color='gray')\n\n\n\n\n\ng([-2.5,-1.5],[x3,y3],ax,col='r')\ng([-0.5,+0.5],[x3,y3],ax,col='b')\ng([+1.5,+2.5],[x3,y3],ax,col='g')\nfig\n\n\n\n\n\ndef h(intval, data, ax, col):\n    a,b = intval\n    x,y = data \n    idx = (a<x) & (x<b) \n    ax.hist(y[idx],color=col) \n\n\nfig,ax = plt.subplots(5,2,figsize=(8,16))\nax[0,0].plot(x3,y3,',',color='gray'); g([-2.5,-1.5],[x3,y3],ax[0,0],col='r')\nax[1,0].plot(x3,y3,',',color='gray'); g([-1.5,-0.5],[x3,y3],ax[1,0],col='g')\nax[2,0].plot(x3,y3,',',color='gray'); g([-0.5,+0.5],[x3,y3],ax[2,0],col='b')\nax[3,0].plot(x3,y3,',',color='gray'); g([+0.5,+1.5],[x3,y3],ax[3,0],col='m')\nax[4,0].plot(x3,y3,',',color='gray'); g([+1.5,+2.5],[x3,y3],ax[4,0],col='lime')\n\nh([-2.5,-1.5],[x3,y3],ax[0,1],col='r')\nh([-1.5,-0.5],[x3,y3],ax[1,1],col='g')\nh([-0.5,+0.5],[x3,y3],ax[2,1],col='b')\nh([+0.5,+1.5],[x3,y3],ax[3,1],col='m')\nh([+1.5,+2.5],[x3,y3],ax[4,1],col='lime')"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#그림만-보고-싶을때",
    "href": "posts/2022-09-26-4wk-1.html#그림만-보고-싶을때",
    "title": "04wk-1",
    "section": "그림만 보고 싶을때",
    "text": "그림만 보고 싶을때\n\nplt.plot([1,2,3,4],[2,3,4,5]);"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#marker-size-line-width",
    "href": "posts/2022-09-26-4wk-1.html#marker-size-line-width",
    "title": "04wk-1",
    "section": "marker size, line width",
    "text": "marker size, line width\n\nplt.plot([1,2,3,4],[2,3,4,2],'o',ms=10)\n\n\n\n\n\nplt.plot([1,2,3,4],[2,3,4,5],'--',lw=10)"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#label-legend",
    "href": "posts/2022-09-26-4wk-1.html#label-legend",
    "title": "04wk-1",
    "section": "label + legend",
    "text": "label + legend\n\nplt.plot([1,2,3,4],[1,2,3,2],'--o',label='A')\nplt.plot([1,2,3,4],[3,2.1,1,3],'--o',label='B')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f5889ead210>"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#색깔조정-c0c1",
    "href": "posts/2022-09-26-4wk-1.html#색깔조정-c0c1",
    "title": "04wk-1",
    "section": "색깔조정 (C0,C1,…)",
    "text": "색깔조정 (C0,C1,…)\n\nplt.plot([1,2,3,4],[1,2,3,2],'--o',label='A',color='C1')\nplt.plot([1,2,3,4],[3,2.1,1,3],'--o',label='B',color='C0')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f588a29ef10>"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#title-설정",
    "href": "posts/2022-09-26-4wk-1.html#title-설정",
    "title": "04wk-1",
    "section": "title 설정",
    "text": "title 설정\n- (방법1)\n\nplt.plot([1,2,3,4],[1,2,3,2],'--o',label='A',color='C1')\nplt.plot([1,2,3,4],[3,2.1,1,3],'--o',label='B',color='C0')\nplt.legend()\nplt.title('title')\n\nText(0.5, 1.0, 'title')\n\n\n\n\n\n- (방법2)\n\nfig, ax = plt.subplots()\nax.plot([1,2,3,4],[1,2,3,2],'--o',label='A',color='C1')\nax.plot([1,2,3,4],[3,2.1,1,3],'--o',label='B',color='C0')\nax.legend()\nax.set_title('title')\n\nText(0.5, 1.0, 'title')"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#suptitle-설정",
    "href": "posts/2022-09-26-4wk-1.html#suptitle-설정",
    "title": "04wk-1",
    "section": "suptitle 설정",
    "text": "suptitle 설정\n\nfig, ax = plt.subplots(2,2)\nax[0,0].plot([1,2,3,2],'--o',label='A',color='C0')\nax[0,0].set_title('(a)')\nax[0,1].plot([3,2.1,1,3],'--o',label='B',color='C1')\nax[0,1].set_title('(b)')\nax[1,0].plot([-3,-2.1,-1,-3],'--o',label='B',color='C2')\nax[1,0].set_title('(c)')\nax[1,1].plot([3,-2.1,1,-3],'--o',label='B',color='C3')\nax[1,1].set_title('(d)')\n#plt.suptitle('suptitle')\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#tight_layout",
    "href": "posts/2022-09-26-4wk-1.html#tight_layout",
    "title": "04wk-1",
    "section": "tight_layout()",
    "text": "tight_layout()\n\nfig\n\n\n\n\n\nfig.tight_layout()\n\n\nfig"
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#fig-ax-plt-소속",
    "href": "posts/2022-09-26-4wk-1.html#fig-ax-plt-소속",
    "title": "04wk-1",
    "section": "fig, ax, plt 소속",
    "text": "fig, ax, plt 소속\n- 일단 그림 하나 그리고 이야기좀 해보자.\n\nfig, ax = plt.subplots()\nax.plot([1,2,3,1])\n\n\n\n\n- fig에는 있고 ax에는 없는 것\nadd_axes, tight_layout, suptitle, …\n- ax에는 있고 fig에는 없는 것\nboxplot, hist, plot, set_title, …\n- plt는 대부분 다 있음. (의미상 명확한건 대충 알아서 fig, ax에 접근해서 처리해준다)\n\nplt.tight_layout, plt.suptitle, plt.boxplot, plt.hist, plot.plot\nplt.set_title 은 없지만 plt.title 은 있음\nplt.add_axes 는 없음.."
  },
  {
    "objectID": "posts/2022-09-26-4wk-1.html#x축-y축-label-설정",
    "href": "posts/2022-09-26-4wk-1.html#x축-y축-label-설정",
    "title": "04wk-1",
    "section": "x축, y축 label 설정",
    "text": "x축, y축 label 설정\n\nax.xaxis.set_label_text('xlabel',size=16,family='serif',weight=1000,style='italic')\n#_fontsettings={'size':16,'family':'serif','weight'=1000,'style':'italic'}\n#ax.xaxis.set_label_text('xlabel',_fontsettings)\nfig\n\n\n\n\n폰트ref - size: - fontweight: 0~1000 - family: ‘serif’, ‘sans-serif’, ‘monospace’ - style: ‘normal’, ‘italic’\n\nax.set_ylabel('ylabel',size=16)\nfig"
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html",
    "href": "posts/2022-11-02-9wk-2.html",
    "title": "09wk-2",
    "section": "",
    "text": "Presentation vs Exploration, 메시지를 뒷받침하는 그림, 흥미로운 자료와 틀린해석, 예쁜그림의 함정, (line,bar,scatter)의 용도"
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html#presentation",
    "href": "posts/2022-11-02-9wk-2.html#presentation",
    "title": "09wk-2",
    "section": "Presentation",
    "text": "Presentation\n\n- 프리젠테이션방식의 시각화는 화자가 다듬은 이야기를 전달하기에 좋은 시각화이다. 즉 잘 정리된 메시지를 전달하기에 좋다."
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html#exploration",
    "href": "posts/2022-11-02-9wk-2.html#exploration",
    "title": "09wk-2",
    "section": "Exploration",
    "text": "Exploration\n\n\n문학적유기체라는 작품이다. 링크.\n어떤 소설책을 시각화.\n수형도 + 칼라\n수형도의 의미: 단원, 문단, 문장, 단어 (수형도 계층적 구조를 시각화 하기에 뛰어남. ex: 리그레션트리!)\n색깔: 여행, 음악, 파티 등 소설에서 자주 등장하는 소재 (색은 범주형 변수를 표현하기에 뛰어남)\n\n- 익스플로래이션 방식은 독자가 스스로 그림에서 메시지를 찾아낸다.\n- 소설을 읽어보지 않은 사람: 이 그래픽으로 소설책의 전체 주제를 미리 파악가능\n- 소설을 이미 읽어본 사람: 분석 & 탐구를 할 수 있음. ex: 파티와 음악이 동시에 등장하는 경우가 많다."
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html#절충",
    "href": "posts/2022-11-02-9wk-2.html#절충",
    "title": "09wk-2",
    "section": "절충",
    "text": "절충\n- 카이로: 사실 프리젠테이션과 익스플로레이션은 절충가능함\n\n\naes(x=‘GDP’,y=‘불평등’,text=‘년도’,color=‘정부’)\n초록색정부: 소득이 증가 & 불평등이 훨씬 더 증가\n갈색정부: 매우 빠른 경제 성장\n포인트간의 간격이 조밀하다 = 변화가 더디다 // 포인트간의 간격이 넓다 = 변화가 빠르다.\n\n- 언뜻보기에는 우리에게 익숙한 라인플랏인듯 보이지만 의외로 정보를 해석할만한 요소가 있다.\n\n익스플로레이션형의 그래프는 그릴줄도 알아야 하지만 남이 그린 그래프를 해석할 수도 있어야함."
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html#인구문제에-대한-편견",
    "href": "posts/2022-11-02-9wk-2.html#인구문제에-대한-편견",
    "title": "09wk-2",
    "section": "인구문제에 대한 편견",
    "text": "인구문제에 대한 편견\n- 주장1 (맬서스주의자): 가난한 나라들의 출산율이 너무 높음 \\(\\to\\) 세계인구가 90억까지 증가할 것이다. (현재 70억)\n- 주장2: 잘사는 나라에서는 애를 적게 낳음 \\(\\to\\) 고령화 문제"
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html#에서-제기된-리들리의-메시지",
    "href": "posts/2022-11-02-9wk-2.html#에서-제기된-리들리의-메시지",
    "title": "09wk-2",
    "section": "<이성적 낙관주의자>에서 제기된 리들리의 메시지",
    "text": "<이성적 낙관주의자>에서 제기된 리들리의 메시지\n- 둘다 틀렸다.\n- 주장1의 반박: 가난한 나라의 출산율은 점점 감소하고 있음. (특히 가난하다가 막 부유해진 나라는 이러한 감소폭이 드라마틱함, ex: 브라질)\n- 주장2의 반박: 평균적으로 잘사는 국가들의 출산률이 매우 낮은것은 사실이나 최근들어 약간 증가하는 경향을 보임. (ex: 스웨덴, 영국, 노르웨이, 스페인)\n- 리들리의 주장: 결국 세계의 인구는 안정화 될 것 (증가하지도 감소하지도 않는다)\n- 리들리의 주장을 뒷받침하기 위해 그린 그림\n\n\n이 그림은 간단명료해 보이지만 리들리의 주장을 뒷받침하기에는 부족하다.\n그림에서 얻을 수 있는 정보: 인구변화를 연도별로 나열했더니 성장속도가 둔화된다는 사실\n리들리가 주장한 다양한 패턴은 이 그림에 보이지 않는다. (출산률이 회복되고 있다는 선진국이라든가, 브라질/인도와 같은 나라의 인구안정화에 대한 주장)\n\n\n카이로\n- 리들러의 메시지는 아래의 그림들이 더 잘 전달한다.\n\n\n스웨덴, 노르웨이 -> 출산률 증가\n브라질, 인도 -> 출산률 대폭감소\n\n\n\n소감\n- 어떠한 통계량 혹은 현상을 살펴볼때 그것의 부분집합들이 역시 그러한지 살펴보는것은 기본임 (그룹별로 파악하면 정반대의 결과가 나올 수 있음)\n- 중요한 선을 제외한 나머지는 회색처리(일러스트레이터 사용) 한 것이 시각적으로 우수하며, 인상적이었음\n- 과학적인 논문작업에 들어갈 그림이라면 임의로 회색처리한 것이 다소 비판을 받을 수 있음."
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html#사례1-남미국가의-국방력",
    "href": "posts/2022-11-02-9wk-2.html#사례1-남미국가의-국방력",
    "title": "09wk-2",
    "section": "사례1: 남미국가의 국방력",
    "text": "사례1: 남미국가의 국방력\n- 아래는 남미국가들의 국방력을 시각화한 그림\n\n\n쓸모없는 그래픽\n뭐 기억나는 것이 있나요?\n\n- 아래가 더 우수한 그림이다. 더 정확한 비교를 할 수 있어요.\n\n- 그리고 위의 그림보다 아래의 그림이 더 우수한 시각화이다.\n\n\n브라질이 국방력도 우수하고 예산도 많이 투자하는 것 같지만 인구가 흑막인것 같다.\n\n- 흑막을 제거\n\n- 최종적으로 제안하는 그래프\n\n\n좌측하단: aes(x=‘인구’, y=‘군인수’, size=‘예산’)\n우측하단: 관심있는 그래프가 아님\n\n사실 저는 좌측하단의 그래프가 좋은 시각화라고 생각안해요\n- 1사분면의 의미: 인구도 높고 군인수도 많은 나라 (똑같은 정보임 의미가 없다. 마치 x축이 토익점수, y축이 텝스점수 같은느낌임)\n\n모든 점들이 직선에 몰려있다면? \\(\\to\\) 왜 2차원으로 표현함?\n\n- 저같으면 aes(x=‘예산(인구효과제거)’, y=‘군인수(인구효과제거)’,size=‘인구’)로 할것 같아요.\n\n1사분면의 의미: 예산도 많이 쓰고 군인수도 많은나라 = 콜롬비아.\n4사분면의 의미: 예산은 많이 쓰는데 군인수가 적은나라 = 브라질\n\n- 산점도에서 데이터를 한눈에 파악하고 특징을 요약하기 위해서는 X,Y를 너무 비슷한 성질의 변수로 설정하지마라.\n아래중 어떤것이 더 바람직한 그래프인가?\n\naes(x=‘토익’, y=‘텝스’, color=‘합/불’, shape=‘회사의종류’)\naes(x=‘토익’, y=‘GPA’, color=‘합/불’, shape=‘회사의종류’)"
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html#사례2-스페인의-실업률",
    "href": "posts/2022-11-02-9wk-2.html#사례2-스페인의-실업률",
    "title": "09wk-2",
    "section": "사례2: 스페인의 실업률",
    "text": "사례2: 스페인의 실업률\n\n\n명암으로 왜 크기비교를 하는것인가?\n\n- 비교를 위해서는 바플랏이 더 우수하다."
  },
  {
    "objectID": "posts/2022-11-02-9wk-2.html#사례3-버블의-남용",
    "href": "posts/2022-11-02-9wk-2.html#사례3-버블의-남용",
    "title": "09wk-2",
    "section": "사례3: 버블의 남용",
    "text": "사례3: 버블의 남용\n- 카이로교수님의 강의자료에 등장하는 그림\n- 회색이 befor, 검은색이 after\n\n\n크기비교는 바플랏으로 하는것이 아니다.\n\n- 우리눈은 작원원이 큰원의 절반정도 차지한다고 느껴진다.\n\n- 그렇지만 실제로는 아래와 같음\n\n- 버블차트는 크기를 왜곡시킨다.\n\n- 하지만 아래의 버블차트는 우수하다.\n\n- 선거지도는 수치비교에 별로 관심이 없다.\n- 대신에 민주당표와 공화당표가 어떤 지역에 몰렸는지 파악하는 것이중요\n- 따라서 aes중 가장 중요한 x,y를 모두 지역에 투자함"
  },
  {
    "objectID": "posts/2022-12-14-A2.html",
    "href": "posts/2022-12-14-A2.html",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "",
    "text": "모르고 살았어도 좋았을 내용"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#비상식적인-append",
    "href": "posts/2022-12-14-A2.html#비상식적인-append",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "비상식적인 append",
    "text": "비상식적인 append\n- 아래의 코드를 관찰하자.\n\na=[1,2,3]\nb=a\na=a+[4]\n\n현재 a,b의 출력결과는?\n\nprint('a=', a)\nprint('b=', b)\n\na= [1, 2, 3, 4]\nb= [1, 2, 3]\n\n\n- 이제 다시 아래의 코드를 관찰하자.\n\na=[1,2,3]\nb=a\na.append(4) \n\n현재 a,b의 출력결과는?\n\nprint('a=', a)\nprint('b=', b)\n\na= [1, 2, 3, 4]\nb= [1, 2, 3]"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#append의-동작원리-틀린상상",
    "href": "posts/2022-12-14-A2.html#append의-동작원리-틀린상상",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "append의 동작원리: 틀린상상",
    "text": "append의 동작원리: 틀린상상\n- 상자로서의 변수: 변수가 데이터를 저장하는 일종의 상자와 같다. <– 아주 흔한 오해 (Fluent Python)\n\n흔히 비유하는 ‘상자로서의 변수’ 개념이 실제로는 객체지향적 언어에서 참조변수를 이해하는 데 방해가 된다.\n\n- “상자로서의 변수” 관점에서 아래의 코드를 해석하자. (일단 아래의 해석들이 틀린해석이라는 사실을 명심할 것)\na=[1,2,3]\nb=a\na.append(4)\na,b라는 변수들은 메모리에 어떻게 저장이 되어있을까?\n상상력을 조금 발휘하면 아래와 같이 여길 수 있다.\n\n메모리는 변수를 담을 방이 여러개 있는 호텔이라고 생각하자.\n아래를 실행하였을 경우\n\na=[1,2,3]\n\n메모리주소1에 존재하는 방을 a라고 하고, 그 방에 [1,2,3]을 넣는다.\n\n\n아래를 실행하였을 경우\n\nb=a\n\n메모리주소2에 존재하는 방을 b라고 하고, 그 방에 a를 넣어야하는데, a는 [1,2,3]이니까 [1,2,3]을 넣는다.\n\n\n아래를 실행하면\n\na.append(4)\n\n방 a로가서 [1,2,3]을 [1,2,3,4]로 바꾼다.\n그리고 방 b에는 아무것도 하지 않는다.\n\n- R에서는 맞는 비유인데, 파이썬은 적절하지 않은 비유이다.\n\n틀린이유\n\nid(a)\n\n139753545242336\n\n\n\nid(b)\n\n139753545242336\n\n\n실제로는 a,b가 저장된 메모리 주소가 동일함"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#append의-동작원리-올바른-상상",
    "href": "posts/2022-12-14-A2.html#append의-동작원리-올바른-상상",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "append의 동작원리: 올바른 상상",
    "text": "append의 동작원리: 올바른 상상\n\n파이썬에서의 변수는 자바에서의 참조변수와 같으므로 변수는 객체에 붙은 레이블이라고 생각하는 것이 좋다.\n\n- 파이썬에서는 아래가 더 적절한 비유이다.\n\n메모리는 변수를 담을 방이 여러개 있는 호텔이라고 생각하자.\n아래를 실행하였을 경우\n\na=[1,2,3]\n\n메모리주소 139753545242336에서 [1,2,3]을 생성\n방 139753545242336의 방문에 a라는 포스트잇을 붙인다.\n앞으로 [1,2,3]에 접근하기 위해서는 여러 메모리방중에서 a라는 포스트잇이 붙은 방을 찾아가면 된다.\n\n\n아래를 실행하였을 경우\n\nb=a\n\na라는 포스트잇이 지칭하는 객체를 가져옴. 그리고 그 객체에 b라는 포스트잇을 붙인다.\n쉽게말하면 b라는 포스트잇을 방 139753545242336의 방문에 붙인다는 이야기.\n앞으로 [1,2,3]에 접근하기 위해서는 여러 메모리방중에서 a라는 포스트잇이 붙어 있거나 b라는 포스트잇이 붙어있는 방을 찾아가면 된다.\n\n\n아래를 실행하면\n\na.append(4)\n\na라는 포스트잇이 붙어있는 방으로 가서, 그 내용물에 append함수를 적용하여 4를 추가하라. 즉 내용물 [1,2,3]을 [1,2,3,4]로 바꾸라.\n같은방(139753545242336)에 a,b라는 포스트잇이 모두 붙어있음. 따라서 b라는 포스트잇이 붙은 방을 찾아가서 내용물을 열어보면 [1,2,3,4]가 나온다."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제1-같은-value-다른-id",
    "href": "posts/2022-12-14-A2.html#예제1-같은-value-다른-id",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제1: 같은 value, 다른 id",
    "text": "예제1: 같은 value, 다른 id\n\na=[1,2,3]\nb=a\na.append(4)\nc=[1,2,3,4]\n\n여기에서 a,b,c는 모두 같은 value를 가진다.\n\na\n\n[1, 2, 3, 4]\n\n\n\nb\n\n[1, 2, 3, 4]\n\n\n\nc\n\n[1, 2, 3, 4]\n\n\n하지만 그 id까지 같은 것은 아니다.\n\nid(a), id(b), id(c)\n\n(139851739924096, 139851739924096, 139851742724800)"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제2",
    "href": "posts/2022-12-14-A2.html#예제2",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제2",
    "text": "예제2\n(관찰)\n\na=[1,2,3] # 할당\nb=a # 에일리어싱 \na=[1,2,3]+[4] # 재할당 \nprint('a=',a)\nprint('b=',b)\n\na= [1, 2, 3, 4]\nb= [1, 2, 3]\n\n\n(해설)\n\nid(a),id(b)\n\n(140346713595728, 140346713595168)\n\n\n\n포인트: [1,2,3]+[4] 가 실행되는 순간 새로운 오브젝트가 만들어지고 그 오브젝트를 a라는 이름으로 다시 할당되었음. (재할당)"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제1",
    "href": "posts/2022-12-14-A2.html#예제1",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제1",
    "text": "예제1\n\na=1+2021\nid(a)\n\n139753546122608\n\n\n\nb=2023-1\nid(b)\n\n139753545299280\n\n\n\nid(2022)\n\n139753545299472\n\n\n\n당연한결과임."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제2-이제-다-이해했다고-생각했는데..",
    "href": "posts/2022-12-14-A2.html#예제2-이제-다-이해했다고-생각했는데..",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제2: 이제 다 이해했다고 생각했는데..",
    "text": "예제2: 이제 다 이해했다고 생각했는데..\n\na=1+2 \nid(a)\n\n7394720\n\n\n\nb=4-1\nid(b)\n\n7394720\n\n\n\nid(a)와 id(b)가 왜 똑같지..?\n\n(해설) 파이썬의 경우 효율성을 위해서 -5~256까지의 정수를 미리 저장해둠.\n\nid(3)\n\n7394720\n\n\n\n3은 언제나 7394720에 지박령마냥 밖혀있음"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제1-1",
    "href": "posts/2022-12-14-A2.html#예제1-1",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제1",
    "text": "예제1\n(관찰) 아래의 예제를 살펴보자. 참조를 제대로 이해했다면 아래의 예제는 자연스럽게 이해가능할 것임.\n\nl1 = [3, [66,55,44]]\nl2 = l1 \nprint('시점1')\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1[0]=4 \nprint('시점2')\nprint('l1=',l1)\nprint('l2=',l2)\n\nl2.append(5)\nprint('시점3')\nprint('l1=',l1)\nprint('l2=',l2)\n\n시점1\nl1= [3, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n시점2\nl1= [4, [66, 55, 44]]\nl2= [4, [66, 55, 44]]\n시점3\nl1= [4, [66, 55, 44], 5]\nl2= [4, [66, 55, 44], 5]\n\n\n(해설)\n\nl1 = [3, [66,55,44]]\nl2 = l1 \n\n\nid(l1),id(l2)\n\n(139753545268832, 139753545268832)\n\n\n이해는 되지만 우리가 원한건 이런게 아니야"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제2-r과-같이-를-쓰고-싶다면",
    "href": "posts/2022-12-14-A2.html#예제2-r과-같이-를-쓰고-싶다면",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제2: R과 같이 = 를 쓰고 싶다면?",
    "text": "예제2: R과 같이 = 를 쓰고 싶다면?\n(관찰)\n\nl1 = [3, [66,55,44]]\nl2 = l1.copy()\nprint('시점1')\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1[0]=4 \nprint('시점2')\nprint('l1=',l1)\nprint('l2=',l2)\n\nl2.append(5)\nprint('시점3')\nprint('l1=',l1)\nprint('l2=',l2)\n\n시점1\nl1= [3, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n시점2\nl1= [4, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n시점3\nl1= [4, [66, 55, 44]]\nl2= [3, [66, 55, 44], 5]\n\n\n(해설)\n\nl1 = [3, [66,55,44]]\nl2 = l1.copy()\n\n\nid(l1),id(l2) ## 드디어 주소가 달라졌다.\n\n(140346713602720, 140346713599104)"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제3-이제-다-이해했다고-생각했는데..",
    "href": "posts/2022-12-14-A2.html#예제3-이제-다-이해했다고-생각했는데..",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제3: 이제 다 이해했다고 생각했는데..",
    "text": "예제3: 이제 다 이해했다고 생각했는데..\n(관찰)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1[1].append(33)\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n(의문)\n\nid(l1),id(l2)\n\n(140346713608432, 140346731755152)\n\n\n\nl1이랑 l2의 주소도 다르게 나오는데 왜 또 참조한것마냥 l1과 l2가 같이 바뀌고 있지?"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제1-2",
    "href": "posts/2022-12-14-A2.html#예제1-2",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제1",
    "text": "예제1\n(관찰+해설)\n\na=2222\nb=2222\n\n\nid(a),id(b)\n\n(139753545300880, 139753545301808)\n\n\n메모리 상황\n\n2222라는 오브젝트가 어떤공간(139753545300880)에 생성되고 그 공간에 a라는 라벨이 붙음\n2222라는 오브젝트가 어떤공간(139753545301808)에 생성되고 그 공간에 b라는 라벨이 붙음\n\n즉 -5~256 이외의 2개의 메모리 공간을 추가적으로 사용"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제2-1",
    "href": "posts/2022-12-14-A2.html#예제2-1",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제2",
    "text": "예제2\n(관찰)\n\na=[1,2,2222]\nb=[1,2,2222]\na.append(4)\nprint('a=',a)\nprint('b=',b)\n\na= [1, 2, 2222, 4]\nb= [1, 2, 2222]\n\n\n(해설)\n\na=[1,2,2222]\nb=[1,2,2222]\n\n\nid(a), [id(a[0]),id(a[1]),id(a[2])] # a=[1,2,2222]\n\n(139753182327904, [7394656, 7394688, 139753178093776])\n\n\n\nid(b), [id(b[0]),id(b[1]),id(b[2])] # b=[1,2,2222] \n\n(139753173818656, [7394656, 7394688, 139753178095568])\n\n\n\na.append(4)\n\n\na\n\n[1, 2, 2222, 4]\n\n\n\nb\n\n[1, 2, 2222]\n\n\n메모리상황\n\n-5~256까지의 숫자는 미리 메모리에 저장되어 있다. 이중에서 1은 7394656, 2는 7394688에 저장되어있음.\n2222가 공간 139753178093776에서 만들어진다.\n어떠한 리스트오브젝트가 공간 139753182327904에서 만들어지고 원소로 [1,2,2222]를 가진다. 이 공간에 a라는 포스트잇을 붙인다.\n2222가 공간 139753178095568에서 만들어진다.\n어떠한 리스트오브젝트가 공간 139753173818656에서 만들어지고 원소로 [1,2,2222]를 가진다. 이 공간에 b라는 포스트잇을 붙인다.\na라는 포스트잇이 붙은 공간으로 이동하여 원소에 4를 추가시킨다.\n\n즉 -5~256이외에 4개의 메모리 공간을 추가사용 (a,b,a의 2222,b의 2222)"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제3",
    "href": "posts/2022-12-14-A2.html#예제3",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제3",
    "text": "예제3\n(관찰)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1[0] = 7777\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1= [7777, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n\n\n(해설)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139753183437040, [7394720, 139753183707216])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753182311120, [7394720, 139753183707216])\n\n\n메모리상황\n\n-5~256까지의 숫자가 메모리에 저장되어 있다.\n저장된 숫자중 66,55,44를 묶어서 리스트로 구성하고 이 리스트를 공간 139753183707216에 저장.\n숫자 3과 공간 139753183707216에 저장된 리스트 [66,55,44]를 하나로 묶어서 새로운 리스트를 구성하고 이를 공간 139753183437040에 저장. 공간 139753183437040에 l1이라는 포스트잇 생성.\n공간 139753182311120에 l1의 원소들을 모아서 새로운 리스트를 구성함. 공간 139753182311120에 l2라는 포스트잇 생성.\n\n\nl1[0] = 7777\nl1,l2\n\n([7777, [66, 55, 44]], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139753183437040, [139753178092080, 139753183707216])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753182311120, [7394720, 139753183707216])\n\n\n\nl1[0]은 원래 공간 7394720와 binding 되어 있었음.\n\n그런데 7777이라는 새로운 오브젝트가 공간 139753178092080에 생성되고 l1[0]이 공간 139753178092080와 다시 binding 됨."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제4",
    "href": "posts/2022-12-14-A2.html#예제4",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제4",
    "text": "예제4\n(관찰)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1.append(7777)\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1= [3, [66, 55, 44], 7777]\nl2= [3, [66, 55, 44]]\n\n\n(해설)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1.append(7777)\n\n\nl1,l2\n\n([3, [66, 55, 44], 7777], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1]), id(l1[2])]\n\n(139753183257056, [7394720, 139753184484240, 139753180268560])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753183216656, [7394720, 139753184484240])\n\n\n\n예제3, 예제4를 통하여 리스트가 가변형객체라는 것을 확인할 수 있다. 예제3의 경우 l1이 저장되어있던 메모리공간의 내용물이 [3,[66,55,44]] 에서 [7777,[66,55,44]] 로 바뀌었다. 예제4의 경우 l1이 저장되어있던 메모리공간의 내용물이 [3,[66,55,44]] 에서 [3,[66,55,44],7777] 로 바뀌었다."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제5-우리를-힘들게-했던-그-예제.",
    "href": "posts/2022-12-14-A2.html#예제5-우리를-힘들게-했던-그-예제.",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제5: 우리를 힘들게 했던 그 예제.",
    "text": "예제5: 우리를 힘들게 했던 그 예제.\n(관찰)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1[1].append(7777)\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1= [3, [66, 55, 44, 7777]]\nl2= [3, [66, 55, 44, 7777]]\n\n\n(해설-시점1)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\n\n\nl1,l2\n\n([3, [66, 55, 44]], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139753181411920, [7394720, 139753181409920])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753181409440, [7394720, 139753181409920])\n\n\n(해설-시점2)\n\nl1[1].append(7777)\n\n\nl1,l2\n\n([3, [66, 55, 44, 7777]], [3, [66, 55, 44, 7777]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139753181411920, [7394720, 139753181409920])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753181409440, [7394720, 139753181409920])\n\n\n해설: 사실 시점1에서 메모리 주소상황을 잘 이해했다면 신기한 일이 아니다. .copy()는 l1과 l2의 주소만 다르게 만들 뿐 내용물인 l1[0],l1[1]는 동일하니까."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제6-신임교수최규빈이영미",
    "href": "posts/2022-12-14-A2.html#예제6-신임교수최규빈이영미",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제6: 신임교수=[‘최규빈’,‘이영미’]",
    "text": "예제6: 신임교수=[‘최규빈’,‘이영미’]\n- 최규빈, 이영미는 신임교수임\n\n신임교수 = ['최규빈','이영미']\n\n\nid(신임교수), id('최규빈'), id('이영미')\n\n(139753182527808, 139753171447312, 139753171447408)\n\n\n- 신임교수를 누군가는 막내들이라고 부르기도 함.\n\n막내들 = 신임교수 \n\n\nid(막내들), id(신임교수)\n\n(139753182527808, 139753182527808)\n\n\n“막내들”이라는 단어와 “신임교수”라는 단어는 사실 같은 말임\n- 새로운 교수 “박혜원”이 뽑혔음.\n\n신임교수.append(\"박혜원\")\n\n\n신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- 전북대 통계학과에서 R특강팀을 구성하여 방학중 R교육을 실시하고자함. 특강팀은 우선 신임교수들로 구성.\n\nR특강팀 = 신임교수.copy()\nR특강팀 \n\n['최규빈', '이영미', '박혜원']\n\n\n- R특강팀에 최혜미교수님 추가. (그렇지만 최혜미교수님이 막내는 아니야.. // 참조와 shallow copy의 차이점)\n\nR특강팀.append(\"최혜미\") \n\n\nR특강팀, 신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원', '최혜미'], ['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- R특강팀에서 양성준 교수를 추가하여 파이썬 특강팀을 구성 (R특강팀의 구분을 위해서 중첩리스트 구조로 만들자)\n\n파이썬특강팀 = [R특강팀, \"양성준\"]\n파이썬특강팀\n\n[['최규빈', '이영미', '박혜원', '최혜미'], '양성준']\n\n\n- 이영미교수는 다른 일이 많아서 R특강 팀에서 제외됨. (그럼 자연히 파이썬에서도 제외됨!!)\n\nR특강팀.remove(\"이영미\")\n\n\nR특강팀, 파이썬특강팀\n\n(['최규빈', '박혜원', '최혜미'], [['최규빈', '박혜원', '최혜미'], '양성준'])\n\n\n하지만 이영미교수는 여전히 신임교수이면서 막내들임\n\n신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- 새로운 교수로 “손흥민”이 임용됨.\n\n막내들.append(\"손흥민\")\n\n\n막내들, 신임교수\n\n(['최규빈', '이영미', '박혜원', '손흥민'], ['최규빈', '이영미', '박혜원', '손흥민'])\n\n\n- 그렇다고 해서 손흥민 교수가 바로 R이나 파이썬 특강팀에 자동소속되는건 아님\n\nR특강팀, 파이썬특강팀\n\n(['최규빈', '박혜원', '최혜미'], [['최규빈', '박혜원', '최혜미'], '양성준'])"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제1-motivation-example",
    "href": "posts/2022-12-14-A2.html#예제1-motivation-example",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제1: Motivation example",
    "text": "예제1: Motivation example\n- 아래의 상황을 다시 생각해보자.\n\n파이썬특강팀 = [\"양성준\",[\"최규빈\",\"이영미\",\"최혜미\"]]\nADSP특강팀 = 파이썬특강팀.copy()\n파이썬특강팀[-1].remove(\"이영미\")\n\n\n파이썬특강팀, ADSP특강팀\n\n(['양성준', ['최규빈', '최혜미']], ['양성준', ['최규빈', '최혜미']])\n\n\n이슈: 이영미교수가 파이썬특강에서 제외되면서 ADSP특강팀에서도 제외되었음. 그런데 사실 이영미교수가 파이썬특강팀에서만 제외되길 원한 것이지 ADSP특강팀에서 제외되길 원한게 아닐수도 있음.\n해결: Deep copy의 사용\n\nimport copy\n\n\n파이썬특강팀 = [\"양성준\",[\"최규빈\",\"이영미\",\"최혜미\"]]\nADSP특강팀 = copy.deepcopy(파이썬특강팀)\n파이썬특강팀[-1].remove(\"이영미\")\n\n\n파이썬특강팀, ADSP특강팀\n\n(['양성준', ['최규빈', '최혜미']], ['양성준', ['최규빈', '이영미', '최혜미']])"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제2-2",
    "href": "posts/2022-12-14-A2.html#예제2-2",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제2",
    "text": "예제2\n- deepcopy\n\nl1 = [3,[66,[55,44]]] \nl2 = copy.deepcopy(l1)\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 140346731797872\nl2: 140346713502576\n\n\n\n레벨1: l1,l2 의 메모리 주소가 다름을 확인\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 140346731797872 [7394720, 140346713544496]\nl2: 140346713502576 [7394720, 140346478134928]\n\n\n\n레벨2: l1안에 있는 [66,[55,44]]와 l2안에 있는 [66,[55,44]]의 메모리 주소가 다름도 확인.\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 140346731797872 [7394720, [7396736, 140346713594848]]\nl2: 140346713502576 [7394720, [7396736, 140346477770704]]\n\n\n\n레벨3: l1안의 [66,[55,44]] 안의 [55,44]와 l2안의 [66,[55,44]] 안의 [55,44]의 메모리 주소까지도 다름을 확인.\n\n- 비교를 위한 shallow copy\n\nl1 = [3,[66,[55,44]]] \nl2 = l1.copy()\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44, 33]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 140346478137008\nl2: 140346477791984\n\n\n\n레벨1: l1,l2 의 메모리 주소가 다름을 확인\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 140346713603280 [7394720, 140346713602720]\nl2: 140346713602880 [7394720, 140346713602720]\n\n\n\n레벨2: l1안에 있는 [66,[55,44]]와 l2안에 있는 [66,[55,44]]의 메모리 주소는 같음!!\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 140346713603280 [7394720, [7396736, 140346713556624]]\nl2: 140346713602880 [7394720, [7396736, 140346713556624]]\n\n\n\n레벨3: l1안의 [66,[55,44]] 안의 [55,44]와 l2안의 [66,[55,44]] 안의 [55,44]의 메모리 주소도 같음!!\n\n- 비교를 위한 참조\n\nl1 = [3,[66,[55,44]]] \nl2 = l1\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44, 33]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 140346478134288\nl2: 140346478134288\n\n\n\n레벨1: l1,l2 여기서부터 메모리 주소가 같다.\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 140346478134288 [7394720, 140346713615648]\nl2: 140346478134288 [7394720, 140346713615648]\n\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 140346478134288 [7394720, [7396736, 140346713786480]]\nl2: 140346478134288 [7394720, [7396736, 140346713786480]]\n\n\n\n문헌에 따라서 shallow copy를 레벨1 deep copy라고 부르기도 한다."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제1-3",
    "href": "posts/2022-12-14-A2.html#예제1-3",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제1",
    "text": "예제1\n- 아래의 코드결과를 예측하라. 결과가 나오는 이유를 설명하라.\n\nl1= [3,[66,55,44]]\nl2= l1.copy() \nl1[-1].append(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n\n포인트: shallow copy (=level 1 deep copy) 이므로 l1안의 [66,55,44]와 l2안의 [66,55,44]는 같은 메모리 주소를 가짐"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제2-3",
    "href": "posts/2022-12-14-A2.html#예제2-3",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제2",
    "text": "예제2\n- 아래의 코드결과를 예측하라. 결과가 나오는 이유를 설명하라.\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44]]\n\n\n\n포인트: l1[-1]+[33]가 실행되는 순간 새로운 오브젝트가 생성되고 이 새로운 오브젝트가 l1의 마지막 원소에 새롭게 할당된다."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제3-1",
    "href": "posts/2022-12-14-A2.html#예제3-1",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제3",
    "text": "예제3\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n\n\n\n포인트: 이 상황에서 l1안의 [66,55,44]와 l2안의 [66,55,44]는 서로 다른 메모리 주소를 가진다."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제4-1",
    "href": "posts/2022-12-14-A2.html#예제4-1",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제4",
    "text": "예제4\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\nl1[-1].append(33)\n\n(잘못된 상상) 아래의 코드와 결과가 같을거야!!\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \n# l1[-1] = l1[-1]+[33] \n# l1[-1].remove(33)\nl1[-1].append(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n(하지만 현실은)\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\nl1[-1].append(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44]]\n\n\n\n포인트: 예제3을 이해했다면 그냥 이해되는것"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#예제5",
    "href": "posts/2022-12-14-A2.html#예제5",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "예제5",
    "text": "예제5\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] += [33] # l1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\nl1[-1].append(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n\n포인트: += 연산자의 올바른 이해\n\n\n??? 예제4랑 예제5는 같은코드가 아니었음!!! a += [1] 는 새로운 오브젝트를 만드는게 아니고, 기존의 오브젝트를 변형하는 스타일의 코드였음! (마치 append 메소드처럼)"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#motivation-example",
    "href": "posts/2022-12-14-A2.html#motivation-example",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "Motivation example",
    "text": "Motivation example\n- 우리는 이제 아래의 내용은 마스터함\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] += [33] # l1[-1].append(33)이랑 같은거..\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n- 아래의 결과를 한번 예측해볼까?\n\nl1=[3,(66,55,44)]\nl2=l1.copy()\nl2[1] += (33,)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, (66, 55, 44)]\nl2= [3, (66, 55, 44, 33)]"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#해설",
    "href": "posts/2022-12-14-A2.html#해설",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "해설",
    "text": "해설\n(시점1)\n\nl1=[3,(66,55,44)]\nl2=l1.copy()\n\n\nl1,l2\n\n([3, (66, 55, 44)], [3, (66, 55, 44)])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 139753183621520\nl2: 139753181521472\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 139753183621520 [7394720, 139753182280032]\nl2: 139753181521472 [7394720, 139753182280032]\n\n\n(시점2)\n\nl2[1] += (33,)\n\n\nl1,l2\n\n([3, (66, 55, 44)], [3, (66, 55, 44, 33)])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 139753183621520\nl2: 139753181521472\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 139753183621520 [7394720, 139753182280032]\nl2: 139753181521472 [7394720, 139753174874064]\n\n\n주소 139753182280032에 있는 값을 바꾸고 싶지만 불변형이라 못바꿈 \\(\\to\\) 그냥 새로 만들자. 그래서 그걸 139753174874064에 저장하자."
  },
  {
    "objectID": "posts/2022-12-14-A2.html#차원의-실체",
    "href": "posts/2022-12-14-A2.html#차원의-실체",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "2차원의 실체",
    "text": "2차원의 실체\n- 2차원 array a,b를 선언하자.\n\na = np.array([[11,22,33,44]]).reshape(2,2)\nb = np.array([[11,22,33,44,55,66]]).reshape(2,3)\nc = np.array([11,22,33,44]).reshape(4,1)\nd = np.array([11,22,33,44])\n\n- a,b,c,d 속성비교\n\na.shape, b.shape, c.shape, d.shape ## 차원 \n\n((2, 2), (2, 3), (4, 1), (4,))\n\n\n\na.strides, b.strides, c.strides, d.strides ## 차원이랑 관련이 있어보임.. + 8의 배수 \n\n((16, 8), (24, 8), (8, 8), (8,))\n\n\n- ((16, 8), (24, 8), (8, 8), (8,)) 와 같은 저 숫자들이 도데체 무엇을 의미하는거야?!\n\n사전지식: 컴퓨터는 하나의 숫자를 저장하는데 메모리를 8칸 쓴다.\n가정: 만약에 컴퓨터가 1차원으로만 숫자를 저장한다면??\nstrides의 의미: (다음 행으로 가기위해서 JUMP해야하는 메모리 공간수, 다음 열로 가기위해서 JUMP해야하는 메모리 공간수)\n\n- 통찰: strides의 존재로 인해서 유추할 수 있는 것은 a,b,c,d 는 모두 1차원으로 저장되어있다는 사실이다. (중첩된 리스트꼴이 아니라)\n- 그렇다면.. shallow copy = deep copy?!\n\nA1=[[1,2],[3,4]]\nA2=A1.copy()\nB1=np.array([[1,2],[3,4]])\nB2=B1.copy()\n\n\nA2[0][0]=11\nB2[0][0]=11\n\n\nA1,A2\n\n([[11, 2], [3, 4]], [[11, 2], [3, 4]])\n\n\n\nB1,B2\n\n(array([[1, 2],\n        [3, 4]]),\n array([[11,  2],\n        [ 3,  4]]))\n\n\n- 잠깐 생각좀..\n\nA2를 바꿨는데 A1이 같이 바뀌는 것은 의도하지 않은 side effect임.\n이러한 side effect가 생기는 이유는 파이썬이 메모리를 저장하기 위해서 shallow copy라는 희한한 짓을 하기 때문임.\n이런 side effect을 방지하기 위해서는 deep copy를 써야함. 이 deep copy는 메모리를 더 많이 잡아먹는 단점이 있다.\n요약하면 side effect 방지와 메모리사용은 trade off 관계에 있음.\n그런데 생각해보니까 B2역시 B1의 shallow copy 임. 따라서 deep copy보다 메모리를 적게씀. 그런데 side effect도 발생하지 않음!?\n\n- B1에서 B2를 만드는 과정은 메모리를 적게 쓰지만 side effect과 가은 문제가 없음! (천재인데..?)\n- 용어정리: (필요할까..?)\n\nnumpy 한정 .copy() 는 copy모듈의 deepcopy와 동등한 효과를 준다. 하지만 실제로는 shallow copy 이다. 공식문서에는 “Note that np.copy is a shallow copy and will not copy object elements within arrays.” 라고 명시되어 있음.\n일부 블로그에서 deep copy라고 주장하기도 함. 블로그1, 블로그2, 블로그3 // 블로그2의 경우 참조와 shallow copy도 구분못함..\n이따가 view라는 개념도 나올텐데 .copy()를 deep copy라고 주장하는 블로거들 대부분 .view()를 shallow copy 혹은 참조라고 주장한다. 하지만 copy와 view를 설명하는 공식문서에서는 view가 shallow copy라는 말을 찾아볼 수 없음.\n사실 좀 애매한게 copy가 shallow copy 와 deep copy 둘만 있는건 아님. 사실 .view()와 .copy() 만 놓고 비교할 때 .view()가 .copy()보다 더 얕은 수준의 복사를 하는것도 사실임 (반대로 .copy() 가 .view()보다 더 깊은 수준의 복사를 하는 것도 사실임)"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#참조",
    "href": "posts/2022-12-14-A2.html#참조",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "참조",
    "text": "참조\n- a를 선언, b는 a의 참조\n\na=np.array([[1,2],[3,4]])\nb=a ## 참조 \n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\na.shape\n\n(2, 2)\n\n\n\nb.shape\n\n(2, 2)\n\n\n- a의 shape을 바꾸어보자 \\(\\to\\) b도 같이 바뀐다\n\na.shape = (4,)\n\n\na\n\narray([1, 2, 3, 4])\n\n\n\nb\n\narray([1, 2, 3, 4])\n\n\n\nid(a),id(b)\n\n(139753605843920, 139753605843920)"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#view",
    "href": "posts/2022-12-14-A2.html#view",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "view",
    "text": "view\n- a를 선언, b는 a의 view\n\na=np.array([[1,2],[3,4]]) \nb=a.view() ## 어떤 블로그등에서는 shallow copy 라고 부르기도 한다. \n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\na.shape\n\n(2, 2)\n\n\n\nb.shape\n\n(2, 2)\n\n\n\na.shape= (4,1)\n\n\na\n\narray([[1],\n       [2],\n       [3],\n       [4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nid(a), id(b)\n\n(140105048258768, 140105048259152)\n\n\n- 그런데..\n\na[0]=100\n\n\na\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\nb\n\narray([[100,   2],\n       [  3,   4]])\n\n\n- 출생의 비밀\n\nb\n\narray([[100,   2],\n       [  3,   4]])\n\n\n\nb.base\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\n? 이거 바뀐 a아니야?\n\n\nid(b.base), id(a)\n\n(140105048258768, 140105048258768)\n\n\n- View\n\nb가 a의 뷰라는 의미는, b가 a를 소스로하여 만들어진 오브젝트란 의미이다.\n따라서 이때 b.base는 a가 된다.\nb는 자체적으로 데이터를 가지고 있지 않으며 a와 공유한다.\n\nnote1 원본 ndarray의 일 경우는 .base가 None으로 나온다.\n\na.base\n\nnote2 b.base의 shpae과 b의 shape은 아무 관련없다.\n\nb.shape\n\n(2, 2)\n\n\n\nb.base.shape # a.shape과 같음\n\n(4, 1)\n\n\n- numpy에서 view를 사용하는 예시 (transpose)\n\nX = np.random.normal(size=[100,2])\nid((X.T).base), id(X)\n\n(140104289713104, 140104289713104)\n\n\n\nX.T 는 X의 view 이다.\n\n\nX.T @ X ## 실제로 X.T를 메모리공간에 새로 만들어 숫자를 저장하지않고 X.T @ X를 계산할 수 있음 (R과차이점) \n\narray([[81.26122629,  4.44010058],\n       [ 4.44010058, 82.45450712]])"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#copy",
    "href": "posts/2022-12-14-A2.html#copy",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "copy",
    "text": "copy\n- a를 선언, b는 a의 copy\n\na=np.array([[1,2],[3,4]])\nb=a.copy() # 껍데기를 새로 생성 (strides, shape) + 데이터도 a와 독립적으로 새로 생성하여 따로 메모리에 저장함. \n\n\nid(a),id(b)\n\n(139753151672016, 139753151660368)\n\n\n- a의 shape을 바꿔도 b에는 적용되지 않음\n\na.shape = (4,1)\na\n\narray([[1],\n       [2],\n       [3],\n       [4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n- 그리고 a[0]의 값을 바꿔도 b에는 적용되지 않음.\n\na[0]=100\n\n\na\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n- b의 출생을 조사해보니..\n\na.base,b.base\n\n(None, None)\n\n\n출생의 비밀은 없었다. 둘다 원본.\n- .view() 는 껍데기만 새로생성 // .copy() 는 껍데기와 데이터를 모두 새로 생성\n\nAppendix: .copy의 한계(?)\n(관찰)\n\na=np.array([1,[1,2]],dtype='O')\nb=a.copy()\nprint('시점1')\nprint('a=',a)\nprint('b=',b)\n\na[0]=222\nprint('시점2')\nprint('a=',a)\nprint('b=',b)\n\na[1][0]=333\nprint('시점2')\nprint('a=',a)\nprint('b=',b)\n\n시점1\na= [1 list([1, 2])]\nb= [1 list([1, 2])]\n시점2\na= [222 list([1, 2])]\nb= [1 list([1, 2])]\n시점2\na= [222 list([333, 2])]\nb= [1 list([333, 2])]\n\n\n\n왜 또 시점2에서는 a와 b가 같이 움직여?\n\n해결책: 더 깊은 복사\n\na=np.array([1,[1,2]],dtype='O')\nb=copy.deepcopy(a)\nprint('시점1')\nprint('a=',a)\nprint('b=',b)\n\na[0]=222\nprint('시점2')\nprint('a=',a)\nprint('b=',b)\n\na[1][0]=333\nprint('시점2')\nprint('a=',a)\nprint('b=',b)\n\n시점1\na= [1 list([1, 2])]\nb= [1 list([1, 2])]\n시점2\na= [222 list([1, 2])]\nb= [1 list([1, 2])]\n시점2\na= [222 list([333, 2])]\nb= [1 list([1, 2])]\n\n\n- 중간요약\n\n사실 b=a.copy()는 에서 .copy()는 사실 온전한 deep-copy가 아니다.\n그래서 a의 데이터가 중첩구조를 가지는 경우는 온전한 deep-copy가 수행되지 않는다.\n그런데 일반적으로 넘파이를 이용할때 자주 사용하는 데이터 구조인 행렬, 텐서등은 데이터가 중첩구조를 가지지 않는다. (1차원 array로만 저장되어 있음)\n따라서 행렬, 텐서에 한정하면 .copy()는 온전한 deep-copy라고 이해해도 무방하다. <– 이것만 기억해!"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#요약",
    "href": "posts/2022-12-14-A2.html#요약",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "요약",
    "text": "요약\n아래를 구분할 수 있으면 잘 이해한 것!!\narr = np.array(...) # arr -- [arr.shape, arr.strides, arr.base, ... ] \narr2 = arr \narr2 = arr.view()\narr2 = arr.copy()\narr2 = copy.deepcopy(arr)"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#별명-뷰-카피",
    "href": "posts/2022-12-14-A2.html#별명-뷰-카피",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "별명, 뷰, 카피",
    "text": "별명, 뷰, 카피\n- test 함수 작성\n\ndef test(a,b): \n    if id(a) == id(b): \n        print(\"별명\")\n    elif id(a) == id(b.base) or id(a.base)==id(b): \n        print(\"뷰\")\n    elif (id(a.base)!=id(None) and id(b.base)!=id(None)) and id(a.base) == id(b.base):\n        print(\"공통의 base를 가짐\")\n    else: \n        print(\"카피, 혹은 아무 관련없는 오브젝트\") \n\n- 잘 동작하나?\n(테스트1)\n\na=np.array([1,2,3,4])\nb=a\n\n\ntest(a,b)\n\n별명\n\n\n(테스트2)\n\na=np.array([1,2,3,4])\nb=a.view()\n\n\ntest(a,b)\n\n뷰\n\n\n(테스트3)\n\na=np.array([1,2,3,4])\nb=a.view()\nc=a.view()\n\n\ntest(b,c)\n\n공통의 base를 가짐\n\n\n\ntest(a,b)\n\n뷰\n\n\n\ntest(a,c)\n\n뷰\n\n\n(테스트4)\n\na=np.array([1,2,3,4])\nb=a.copy()\n\n\ntest(a,b)\n\n카피, 혹은 아무 관련없는 오브젝트"
  },
  {
    "objectID": "posts/2022-12-14-A2.html#결론",
    "href": "posts/2022-12-14-A2.html#결론",
    "title": "A2: 깊은복사와 얕은복사",
    "section": "결론",
    "text": "결론\n- 참조, 뷰, 카피의 개념을 잘 알고 있고 때에 따라 이들을 적절하게 사용하며 효율적으로 메모리를 쓰고 싶을것 같음. 하지만 이건 불가능한 소망임.\n- 우리가 사용했던 어떠한 것들이 뷰가 나올지 카피가 나올지 잘 모른다. (그래서 원리를 이해해도 대응할 방법이 사실없음)\n\n예시1\n\na=np.array([1,2,3,4])\nb=a[:3]\n\n\na\n\narray([1, 2, 3, 4])\n\n\n\nb\n\narray([1, 2, 3])\n\n\n\ntest(a,b)\n\n뷰\n\n\n\nc=a[[0,1,2]]\nc\n\narray([1, 2, 3])\n\n\n\ntest(a,c)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n\n\n예시2\n\na=np.array([[1,2],[3,4]])\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb=a.flatten()\nc=a.ravel()\nd=a.reshape(-1)\n\n\ntest(a,b)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n\ntest(a,c)\n\n뷰\n\n\n\ntest(a,d)\n\n뷰\n\n\n\ntest(c,d)\n\n공통의 base를 가짐\n\n\n\ntest(b,c)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n- 심지어 copy인줄 알았던것이 사실 view라서 원치않는 side effect이 생길수 있음. \\(\\to\\) 그냥 방어적 프로그래밍이 최선인듯"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html",
    "href": "posts/2022-10-12-6wk-12.html",
    "title": "06wk-1,2",
    "section": "",
    "text": "lambda, map, 판다스–인덱싱(1)"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#lambda",
    "href": "posts/2022-10-12-6wk-12.html#lambda",
    "title": "06wk-1,2",
    "section": "lambda",
    "text": "lambda\n- 예제1: 람다표현식(lambda expression)자체가 하나의 오브젝트임\n\nlambda x: (x-2)**2 ### lambda x: (x-2)**2 가 실행되는 순간 메모리상에 함수 오브젝트가 저장됨 \n\n<function __main__.<lambda>(x)>\n\n\n\n“lambda x: (x-2)**2” 는 \\(lambda(x)=(x-2)^2\\)의 느낌으로 기억하면 쉬움\n\n(사용방법)\n\n(lambda x: (x-2)**2)(2) # 입력2 -> 출력 (2-2)^2 =0 \n\n0\n\n\n\n(lambda x: (x-2)**2)(4) # 입력5 -> 출력 (4-2)^2 =4 \n\n4\n\n\n\n(lambda x: (x-2)**2)(6) # 입력6 -> 출력 (6-2)^2 =16\n\n16\n\n\n\n(lambda x: (x-2)**2)(-2) # 입력-2 -> 출력 (-2-2)^2 =16\n\n16\n\n\n- 예제2: 람다표현식에 이름을 줄 수 있음.\n\nf = lambda x: (x-2)**2\n\n\nf(2),f(4),f(6),f(-2)\n\n(0, 4, 16, 16)\n\n\n위의 코드는 아래와 같다.\n\ndef f(x):\n    return (x-2)**2\nf(2),f(4),f(6),f(-2)\n\n(0, 4, 16, 16)\n\n\n- 예제3: 조건부 출력\n\nf = lambda x,y: x if x>y else y # x,y가 입력 -> x>y 일때만 x를 리턴하고 그렇지않으면 y를 리턴 = 큰값을 리턴하라는 소리임 \n\n\nf(1,20)\n\n20\n\n\n- 예제4: 람다표현식들의 리스트\n\nfl = [lambda x: x, lambda x: x**2, lambda x: x**3]\n\n\nfor f in fl: \n    print(f(2))\n\n2\n4\n8\n\n\n\nx = np.linspace(-1,1,100)\nfor f in fl:\n    plt.plot(x,f(x),'--') \n\n\n\n\n- 예제5: 람다표현식들의 딕셔너리\n\nfd = {'f1':lambda x: x, 'f2':lambda x: x**2, 'f3':lambda x: x**3}\nfd\n\n{'f1': <function __main__.<lambda>(x)>,\n 'f2': <function __main__.<lambda>(x)>,\n 'f3': <function __main__.<lambda>(x)>}\n\n\n\nfor k in fd:\n    plt.plot(x,fd[k](x),'--')\n\n\n\n\n- 예제6: 람다표현식을 리턴하는 함수 (함수를 리턴하는 함수)\n(예비학습) 함수 \\(g(x)\\)가 정의되어 있을때 \\(\\frac{d}{dx}g(x)\\)의 값을 계산해보기\n\ng = lambda x: x**2 \n\n\ngg = lambda x : (g(x+0.001)-g(x))/0.001\n\n\ngg(4)\n\n8.0010000000037\n\n\n(목표) 도함수를 구해주는 derivate 함수를 정의하자. 이 함수는 임의의 함수 g를 입력으로 받으면, g의 도함수(gg)가 리턴되는 기능을 가진다.\n\ndef derivate(g):\n    return lambda x: (g(x+0.001)-g(x))/0.001 \n\n(사용1)\n\ng = lambda x: np.sin(x) \n\n\ngg = derivate(g) \n\n\nx = np.linspace(0,6.28,1000) \n\n\nplt.plot(x,g(x),label=r'$f(x)=sin(x)$')\nplt.plot(x,gg(x),label=r'$\\frac{d}{dx}f(x)=cos(x)$')\nplt.legend(fontsize=15)\n\n<matplotlib.legend.Legend at 0x7fa54cde3a50>\n\n\n\n\n\n(사용2)\n\ng0 = lambda x: (1/6)*x**3\ng1 = derivate(g0) # (1/2)x^2 \ng2 = derivate(g1) # x \n\n\nx = np.linspace(-1,1,100)\nplt.plot(x,g0(x),'--',label=r'$g_0(x)=\\frac{1}{6}x^3$')\nplt.plot(x,g1(x),'--',label=r'$g_1(x)=\\frac{1}{2}x^2$')\nplt.plot(x,g2(x),'--',label=r'$g_2(x)=x$')\nplt.legend(fontsize=15)\n\n<matplotlib.legend.Legend at 0x7fa54cccc2d0>\n\n\n\n\n\n- 예제7: 예제6의 다른표현\n\nderivate = lambda g: lambda x: (g(x+0.001)-g(x))/0.001 \n\n(사용1)\n\ng = lambda x: np.sin(x) \n\n\ngg = derivate(g) \n\n\nx = np.linspace(0,6.28,1000) \n\n\nplt.plot(x,g(x),label=r'$f(x)=sin(x)$')\nplt.plot(x,gg(x),label=r'$\\frac{d}{dx}f(x)=cos(x)$')\nplt.legend(fontsize=15)\n\n<matplotlib.legend.Legend at 0x7fa54cdb1b10>\n\n\n\n\n\n(사용2)\n\ng0 = lambda x: (1/6)*x**3\ng1 = derivate(g0) # (1/2)x^2 \ng2 = derivate(g1) # x \n\n\nx = np.linspace(-1,1,100)\nplt.plot(x,g0(x),'--',label=r'$g_0(x)=\\frac{1}{6}x^3$')\nplt.plot(x,g1(x),'--',label=r'$g_1(x)=\\frac{1}{2}x^2$')\nplt.plot(x,g2(x),'--',label=r'$g_2(x)=x$')\nplt.legend(fontsize=15)\n\n<matplotlib.legend.Legend at 0x7fa54cee96d0>"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#map",
    "href": "posts/2022-10-12-6wk-12.html#map",
    "title": "06wk-1,2",
    "section": "map",
    "text": "map\n- 개념: $(f,[x_1,x_2,,x_n] )=$\n- 예제1:\n\nx=[1,2,3] \nf = lambda x: x+1 \ny = list(map(f,x))\n\n(다른구현1)\n\nlist(map(lambda x: x+1,[1,2,3]))\n\n[2, 3, 4]\n\n\n(다른구현2)\n\nf = lambda x: x+1 \n[f(xi) for xi in [1,2,3]]\n\n[2, 3, 4]\n\n\n(다른구현3)\n\n[(lambda x: x+1)(xi) for xi in [1,2,3]]\n\n[2, 3, 4]\n\n\n(다른구현4)–최악\n\ny = [] \nx = [1,2,3] \nf = lambda x: x+1 \nfor xi in x:\n    y.append(f(xi))\n\n\ny\n\n[2, 3, 4]\n\n\n(다른구현5)–더 최악\n\ny = [] \nx = [1,2,3] \nf = lambda x: x+1 \nfor i in range(len(x)):\n    y.append(f(x[i]))\n\n\ny\n\n[2, 3, 4]\n\n\n- 예제2: 문자열을 입력으로 받고 대문자이면 True, 소문자이면 False\n입력: A,B,C,a,b,c\n출력: T,T,T,F,F,F\n\nx= list('ABCabc')\n# x = ['A','B','C','a','b','c']\nf = lambda s: s.isupper()\ny = list(map(f,x))\n\n\nx,y\n\n(['A', 'B', 'C', 'a', 'b', 'c'], [True, True, True, False, False, False])\n\n\n- 예제3: 두개의 입력을 받는 함수 (map을 이용하는 것이 리스트 컴프리헨션보다 조금 편한것 같다)\n\nlist(map(lambda x,y: x+y, [1,2,3],[-1,-2,-3]))\n\n[0, 0, 0]\n\n\n(다른구현)– 리스트컴프리헨션\n\nf = lambda x,y: x+y \n[f(x,y) for x,y in zip([1,2,3],[-1,-2,-3])] \n\n[0, 0, 0]\n\n\n- 예제4: map은 “하나의 함수에 다양한 입력”을 적용하는 경우에만 사용가능, 리스트컴프리헨션은 “다양한 함수에 다양한 입력” 지원\n\nflst = [lambda x: x+1, lambda x: x+2, lambda x:x+3] \n\nmap으로 구현시도 \\(\\to\\) 실패\n\nlist(map(flst,[-1,-2,-3])) # 결과가 0,0,0\n\nTypeError: 'list' object is not callable\n\n\n리스트컴프리헨션으로 구현시도 \\(\\to\\) 성공\n\n[f(x) for f,x in zip(flst,[-1,-2,-3])]\n\n[0, 0, 0]\n\n\n- 종합: map과 리스트컴프리헨션과 비교\n\nmap은 for문을 위한 \\(i\\)등의 인덱스를 쓰지 않지만 리스트컴프리헨션은 필요함\nmap은 좀더 리스트컴프리헨션보다 제약적으로 사용할 수 밖에 없음."
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#데이터프레임-준비",
    "href": "posts/2022-10-12-6wk-12.html#데이터프레임-준비",
    "title": "06wk-1,2",
    "section": "데이터프레임 준비",
    "text": "데이터프레임 준비\n- 데이터준비\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/dv2022.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n200 rows × 4 columns\n\n\n\n- 앞으로는 위와 같은 df형태를 가정할 것이다. 즉 column의 이름은 문자열, row의 이름은 0부터 시작하는 정수로 가정한다.\n- 아래와 같은 형태는 일단 생각하지 않는다.\n\npd.DataFrame({'att':[60,65,80,90],'rep':[50,100,90,100]},index=['규빈','영미','성준','혜미'])\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      규빈\n      60\n      50\n    \n    \n      영미\n      65\n      100\n    \n    \n      성준\n      80\n      90\n    \n    \n      혜미\n      90\n      100"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#df의-4가지-컨셉",
    "href": "posts/2022-10-12-6wk-12.html#df의-4가지-컨셉",
    "title": "06wk-1,2",
    "section": "df의 4가지 컨셉",
    "text": "df의 4가지 컨셉\n- 원소에 접근하는 4가지 방법: ., [], .iloc[], .loc[]"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#컨셉1-클래스느낌",
    "href": "posts/2022-10-12-6wk-12.html#컨셉1-클래스느낌",
    "title": "06wk-1,2",
    "section": "컨셉1: 클래스느낌",
    "text": "컨셉1: 클래스느낌\n- 컨셉1: df는 인스턴스이다. 그리고 df.att, df.rep,df.mid, df.fin 와 같이 col이름에 대응하는 속성이 있다.\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n  \n\n\n\n\n\ndf.fin\n\n0      10\n1      10\n2      20\n3       5\n4      70\n       ..\n195    95\n196    85\n197    10\n198    60\n199    85\nName: fin, Length: 200, dtype: int64\n\n\n- 언제유용? col의 이름을 대충 알고 있을 경우 자동완성으로 쉽게 선택가능"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#컨셉2-딕셔너리-alpha-느낌",
    "href": "posts/2022-10-12-6wk-12.html#컨셉2-딕셔너리-alpha-느낌",
    "title": "06wk-1,2",
    "section": "컨셉2: 딕셔너리 + \\(\\alpha\\) 느낌",
    "text": "컨셉2: 딕셔너리 + \\(\\alpha\\) 느낌\n- 컨셉2: df는 컬럼이름이 key, 컬럼의데이터가 value가 되는 dictionary로 이해할 수 있다. 즉 아래의 dct와 같은 딕셔너리로 이해할 수 있다.\n\ndct = dict(df) \n#dct\n\n(예시) .keys() 메소드를 이용하여 컬럼들의 이름을 살펴볼 수 있음.\n\ndct.keys(), df.keys()\n\n(dict_keys(['att', 'rep', 'mid', 'fin']),\n Index(['att', 'rep', 'mid', 'fin'], dtype='object'))\n\n\n\n# col indexing\n- 예시1: dct가 가능하면 df도 가능하다.\n\ndf['att']\n#dct['att'] \n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: dct가 가능하면 df도 가능하다. (2)\n\ndf.get('att')\n#dct.get('att') \n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시3: dct에서 불가능하지만 df에서 가능한것도 있다.\n\ndct.get(['att','rep'])\n\nTypeError: unhashable type: 'list'\n\n\n\ndf.get(['att','rep'])\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      1\n      95\n      30\n    \n    \n      2\n      65\n      85\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      60\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      197\n      85\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시4: dct에서 불가능하지만 df에서 가능한것도 있다. (2)\n\ndct[['att','rep']]\n\nTypeError: unhashable type: 'list'\n\n\n\ndf[['att','rep']]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      1\n      95\n      30\n    \n    \n      2\n      65\n      85\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      60\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      197\n      85\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n200 rows × 2 columns\n\n\n\n\n\n# row indexing\n- 예시5: dct에서 불가능하지만 df에서 가능한것도 있다. (3)\n\ndct[:5] \n\nTypeError: unhashable type: 'slice'\n\n\n\ndf[:5]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#컨셉3-넘파이느낌",
    "href": "posts/2022-10-12-6wk-12.html#컨셉3-넘파이느낌",
    "title": "06wk-1,2",
    "section": "컨셉3: 넘파이느낌",
    "text": "컨셉3: 넘파이느낌\n- 컨셉3: df.iloc은 넘파이에러이처럼 생각가능하다. 즉 아래의 arr와 같은 넘파이어레이로 생각가능하다.\n\narr = np.array(df)\n#arr\n\n\n# row indexing\n- 예시1: 단일레이블\n\narr[0,:] # first row \narr[0,] \narr[0]\n\narray([65, 45,  0, 10])\n\n\n\ndf.iloc[0,:] # first row \ndf.iloc[0,] \ndf.iloc[0]\n\natt    65\nrep    45\nmid     0\nfin    10\nName: 0, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\narr[[0,1,2],:] # 처음 3개의 row 선택 \narr[[0,1,2],] \narr[[0,1,2]]\n\narray([[65, 45,  0, 10],\n       [95, 30, 60, 10],\n       [65, 85, 15, 20]])\n\n\n\ndf.iloc[[0,1,2],:] # 처음 3개의 row 선택 \ndf.iloc[[0,1,2],] \ndf.iloc[[0,1,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n- 예시3: 슬랑이싱\n\narr[0:3,:] # 처음 3개의 row선택, 끝점포함X\narr[0:3,] \narr[0:3]\n\narray([[65, 45,  0, 10],\n       [95, 30, 60, 10],\n       [65, 85, 15, 20]])\n\n\n\ndf.iloc[0:3,:] # 처음 3개의 row선택, 끝점포함X\ndf.iloc[0:3,] \ndf.iloc[0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n\n\n# col indexing\n- 예시1: 단일레이블\n\ndf.iloc[:,0] # first column \n# arr[:,0] # first column \n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\ndf.iloc[:,[0,2]] # col1, col3 을 선택\n# arr[:,[0,2]] # col1, col3 을 선택\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      65\n      0\n    \n    \n      1\n      95\n      60\n    \n    \n      2\n      65\n      15\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      55\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      40\n    \n    \n      196\n      65\n      25\n    \n    \n      197\n      85\n      100\n    \n    \n      198\n      80\n      35\n    \n    \n      199\n      50\n      45\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시3: 슬랑이싱\n\ndf.iloc[:,0:3] # 처음 3개의 col선택, 끝점포함X\n#arr[:,0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      199\n      50\n      95\n      45\n    \n  \n\n200 rows × 3 columns\n\n\n\n\n\n# row + col indexing\n\ndf.iloc[::2,0:3]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      6\n      65\n      70\n      60\n    \n    \n      8\n      95\n      55\n      65\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      190\n      95\n      35\n      40\n    \n    \n      192\n      100\n      40\n      80\n    \n    \n      194\n      65\n      40\n      65\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      198\n      80\n      65\n      35\n    \n  \n\n100 rows × 3 columns"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#컨셉4-데이터프레임-느낌",
    "href": "posts/2022-10-12-6wk-12.html#컨셉4-데이터프레임-느낌",
    "title": "06wk-1,2",
    "section": "컨셉4: 데이터프레임 느낌",
    "text": "컨셉4: 데이터프레임 느낌\n- 컨셉4: df.loc은 새로운 느낌.. (R에 익숙하면 df.loc이 dataframe 혹은 티블느낌이라고 보시면 됩니다)\n\nimport rpy2\n%load_ext rpy2.ipython \n\n\n%%R \nlibrary(tidyverse) \nmpg[1:5,c('model','year')]\n\n# A tibble: 5 × 2\n  model  year\n  <chr> <int>\n1 a4     1999\n2 a4     1999\n3 a4     2008\n4 a4     2008\n5 a4     1999\n\n\n\n# row indexing\n- 예시1: 단일레이블\n\ndf.loc[0,:] # 첫번째 row를 선택 \ndf.loc[0,]\ndf.loc[0] \n\natt    65\nrep    45\nmid     0\nfin    10\nName: 0, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\ndf.loc[[0,1,2],:] # 처음 3개의 row를 선택 \ndf.loc[[0,1,2],]\ndf.loc[[0,1,2]] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n  \n\n\n\n\n- 예시3: 슬라이싱 (끝점포함 O)\n\ndf.loc[0:3,:] # 처음 4개의 row를 선택, 끝점포함 \ndf.loc[0:3,]\ndf.loc[0:3] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n  \n\n\n\n\n\n\n# col indexing\n- 예시1: 단일레이블\n\ndf.loc[:,'att'] \n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64\n\n\n- 예시2: 레이블의 리스트\n\ndf.loc[:,['att','mid']] \n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      65\n      0\n    \n    \n      1\n      95\n      60\n    \n    \n      2\n      65\n      15\n    \n    \n      3\n      55\n      35\n    \n    \n      4\n      80\n      55\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      40\n    \n    \n      196\n      65\n      25\n    \n    \n      197\n      85\n      100\n    \n    \n      198\n      80\n      35\n    \n    \n      199\n      50\n      45\n    \n  \n\n200 rows × 2 columns\n\n\n\n- 예시3: 슬라이싱 (끝점포함 O)\n\ndf.loc[:,'att':'mid'] # 끝점포함 \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      199\n      50\n      95\n      45\n    \n  \n\n200 rows × 3 columns\n\n\n\n\n\n# row + col indexing\n\ndf.loc[::-1,'att':'mid'] # 끝점포함 \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      199\n      50\n      95\n      45\n    \n    \n      198\n      80\n      65\n      35\n    \n    \n      197\n      85\n      85\n      100\n    \n    \n      196\n      65\n      85\n      25\n    \n    \n      195\n      55\n      70\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      4\n      80\n      60\n      55\n    \n    \n      3\n      55\n      35\n      35\n    \n    \n      2\n      65\n      85\n      15\n    \n    \n      1\n      95\n      30\n      60\n    \n    \n      0\n      65\n      45\n      0\n    \n  \n\n200 rows × 3 columns"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#컨셉14-정리",
    "href": "posts/2022-10-12-6wk-12.html#컨셉14-정리",
    "title": "06wk-1,2",
    "section": "컨셉1~4 정리",
    "text": "컨셉1~4 정리\n\n\n\n\n.\n[]\n.iloc\n.loc\n\n\n\n\nrow/단일레이블\nX\nX\nO\nO\n\n\ncol/단일레이블\nO\nO\nO\nO\n\n\nrow/레이블리스트\nX\nX\nO\nO\n\n\ncol/레이블리스트\nX\nO\nO\nO\n\n\nrow/슬라이싱\nX\nO\nO\nO\n\n\ncol/슬라이싱\nX\nX\nO\nO\n\n\n\n- col 이름을 알아야하는 부담감 - . : 앞글자만 대충 알아도 자동완성 가능 - []: 정확한 col 이름을 알아야 함 - .loc: 보통 정확한 col 이름을 알아야 하지만 슬라이싱 이용시 양 끝의 컬럼이름만 알면 무방 - .iloc: 정확한 col 이름을 몰라도 번호로 인덱싱 가능\n- 자주하는 실수\n\ndf['att'] # 가능 \n# df.loc['att'] # 불가능\ndf.loc[:,'att'] # 가능\n\n0      65\n1      95\n2      65\n3      55\n4      80\n       ..\n195    55\n196    65\n197    85\n198    80\n199    50\nName: att, Length: 200, dtype: int64"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#att-90-and-rep-50",
    "href": "posts/2022-10-12-6wk-12.html#att-90-and-rep-50",
    "title": "06wk-1,2",
    "section": "att > 90 and rep < 50",
    "text": "att > 90 and rep < 50\n- 방법1: .query()를 이용\n\ndf.query('att>90 and rep<50') \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      12\n      95\n      35\n      0\n      25\n    \n    \n      48\n      95\n      45\n      35\n      80\n    \n    \n      56\n      95\n      25\n      95\n      90\n    \n    \n      78\n      95\n      45\n      90\n      35\n    \n    \n      107\n      100\n      30\n      60\n      65\n    \n    \n      112\n      100\n      35\n      70\n      0\n    \n    \n      113\n      95\n      45\n      55\n      65\n    \n    \n      163\n      100\n      25\n      10\n      20\n    \n    \n      174\n      100\n      40\n      40\n      15\n    \n    \n      176\n      100\n      30\n      70\n      70\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n  \n\n\n\n\n\ndf.query('(att>90)&(rep<50)') \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      12\n      95\n      35\n      0\n      25\n    \n    \n      48\n      95\n      45\n      35\n      80\n    \n    \n      56\n      95\n      25\n      95\n      90\n    \n    \n      78\n      95\n      45\n      90\n      35\n    \n    \n      107\n      100\n      30\n      60\n      65\n    \n    \n      112\n      100\n      35\n      70\n      0\n    \n    \n      113\n      95\n      45\n      55\n      65\n    \n    \n      163\n      100\n      25\n      10\n      20\n    \n    \n      174\n      100\n      40\n      40\n      15\n    \n    \n      176\n      100\n      30\n      70\n      70\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n  \n\n\n\n\n\ndf.query('att>90 & rep<50') \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      12\n      95\n      35\n      0\n      25\n    \n    \n      48\n      95\n      45\n      35\n      80\n    \n    \n      56\n      95\n      25\n      95\n      90\n    \n    \n      78\n      95\n      45\n      90\n      35\n    \n    \n      107\n      100\n      30\n      60\n      65\n    \n    \n      112\n      100\n      35\n      70\n      0\n    \n    \n      113\n      95\n      45\n      55\n      65\n    \n    \n      163\n      100\n      25\n      10\n      20\n    \n    \n      174\n      100\n      40\n      40\n      15\n    \n    \n      176\n      100\n      30\n      70\n      70\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n  \n\n\n\n\n- 방법2: [], .iloc, .loc\n\ndf[(df.att > 90)&(df.rep < 50)]\ndf.loc[(df.att > 90)&(df.rep < 50)]\ndf.iloc[list((df.att > 90)&(df.rep < 50))]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      12\n      95\n      35\n      0\n      25\n    \n    \n      48\n      95\n      45\n      35\n      80\n    \n    \n      56\n      95\n      25\n      95\n      90\n    \n    \n      78\n      95\n      45\n      90\n      35\n    \n    \n      107\n      100\n      30\n      60\n      65\n    \n    \n      112\n      100\n      35\n      70\n      0\n    \n    \n      113\n      95\n      45\n      55\n      65\n    \n    \n      163\n      100\n      25\n      10\n      20\n    \n    \n      174\n      100\n      40\n      40\n      15\n    \n    \n      176\n      100\n      30\n      70\n      70\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n  \n\n\n\n\n- 방법3: [], .iloc, .loc // map, lambda\n\ndf[list(map(lambda x,y: (x>90)&(y<50), df.att, df.rep))]\n# df[map(lambda x,y: (x>90)&(y<50), df.att, df.rep)] # 이것은 불가능\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      12\n      95\n      35\n      0\n      25\n    \n    \n      48\n      95\n      45\n      35\n      80\n    \n    \n      56\n      95\n      25\n      95\n      90\n    \n    \n      78\n      95\n      45\n      90\n      35\n    \n    \n      107\n      100\n      30\n      60\n      65\n    \n    \n      112\n      100\n      35\n      70\n      0\n    \n    \n      113\n      95\n      45\n      55\n      65\n    \n    \n      163\n      100\n      25\n      10\n      20\n    \n    \n      174\n      100\n      40\n      40\n      15\n    \n    \n      176\n      100\n      30\n      70\n      70\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n  \n\n\n\n\n\ndf.iloc[list(map(lambda x,y: (x>90)&(y<50), df.att, df.rep))]\ndf.iloc[map(lambda x,y: (x>90)&(y<50), df.att, df.rep)]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      12\n      95\n      35\n      0\n      25\n    \n    \n      48\n      95\n      45\n      35\n      80\n    \n    \n      56\n      95\n      25\n      95\n      90\n    \n    \n      78\n      95\n      45\n      90\n      35\n    \n    \n      107\n      100\n      30\n      60\n      65\n    \n    \n      112\n      100\n      35\n      70\n      0\n    \n    \n      113\n      95\n      45\n      55\n      65\n    \n    \n      163\n      100\n      25\n      10\n      20\n    \n    \n      174\n      100\n      40\n      40\n      15\n    \n    \n      176\n      100\n      30\n      70\n      70\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n  \n\n\n\n\n\ndf.loc[list(map(lambda x,y: (x>90)&(y<50), df.att, df.rep))]\ndf.loc[map(lambda x,y: (x>90)&(y<50), df.att, df.rep)]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      12\n      95\n      35\n      0\n      25\n    \n    \n      48\n      95\n      45\n      35\n      80\n    \n    \n      56\n      95\n      25\n      95\n      90\n    \n    \n      78\n      95\n      45\n      90\n      35\n    \n    \n      107\n      100\n      30\n      60\n      65\n    \n    \n      112\n      100\n      35\n      70\n      0\n    \n    \n      113\n      95\n      45\n      55\n      65\n    \n    \n      163\n      100\n      25\n      10\n      20\n    \n    \n      174\n      100\n      40\n      40\n      15\n    \n    \n      176\n      100\n      30\n      70\n      70\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#att-meanatt",
    "href": "posts/2022-10-12-6wk-12.html#att-meanatt",
    "title": "06wk-1,2",
    "section": "att > mean(att)",
    "text": "att > mean(att)\n- 방법1: .query()를 이용\n\ndf.query('att> att.mean()') \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      8\n      95\n      55\n      65\n      90\n    \n    \n      9\n      90\n      25\n      95\n      50\n    \n    \n      11\n      95\n      60\n      25\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n  \n\n95 rows × 4 columns\n\n\n\n- 방법2: [], .iloc, .loc\n\ndf[df.att > df.att.mean()]\ndf.loc[df.att > df.att.mean()]\ndf.iloc[list(df.att > df.att.mean())]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      8\n      95\n      55\n      65\n      90\n    \n    \n      9\n      90\n      25\n      95\n      50\n    \n    \n      11\n      95\n      60\n      25\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n  \n\n95 rows × 4 columns\n\n\n\n- 방법3: [], .iloc, .loc // map, lambda\n\ndf[list(map(lambda x: x>df.att.mean() , df.att))]\n# df[map(lambda x: x>df.att.mean() , df.att)] # 이것은 불가능\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      8\n      95\n      55\n      65\n      90\n    \n    \n      9\n      90\n      25\n      95\n      50\n    \n    \n      11\n      95\n      60\n      25\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n  \n\n95 rows × 4 columns\n\n\n\n\ndf.iloc[list(map(lambda x: x>df.att.mean() , df.att))]\ndf.iloc[map(lambda x: x>df.att.mean() , df.att)]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      8\n      95\n      55\n      65\n      90\n    \n    \n      9\n      90\n      25\n      95\n      50\n    \n    \n      11\n      95\n      60\n      25\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n  \n\n95 rows × 4 columns\n\n\n\n\ndf.loc[list(map(lambda x: x>df.att.mean() , df.att))]\ndf.loc[map(lambda x: x>df.att.mean() , df.att)]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      8\n      95\n      55\n      65\n      90\n    \n    \n      9\n      90\n      25\n      95\n      50\n    \n    \n      11\n      95\n      60\n      25\n      55\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      184\n      100\n      30\n      30\n      85\n    \n    \n      190\n      95\n      35\n      40\n      95\n    \n    \n      192\n      100\n      40\n      80\n      80\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n  \n\n95 rows × 4 columns\n\n\n\n\n\n\n\n.\n[]\n.iloc\n.loc\n\n\n\n\nrow/단일레이블\nX\nX\nO\nO\n\n\ncol/단일레이블\nO\nO\nO\nO\n\n\nrow/레이블리스트\nX\nX\nO\nO\n\n\ncol/레이블리스트\nX\nO\nO\nO\n\n\nrow/슬라이싱\nX\nO\nO\nO\n\n\ncol/슬라이싱\nX\nX\nO\nO\n\n\nrow/bool,list\nX\nO\nO\nO\n\n\nrow/bool,ser\nX\nO\nX\nO\n\n\nrow/bool,map\nX\nX\nO\nO"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#월12일-숙제",
    "href": "posts/2022-10-12-6wk-12.html#월12일-숙제",
    "title": "06wk-1,2",
    "section": "1. 10월12일 숙제",
    "text": "1. 10월12일 숙제\n아래와 같이 0~9까지 포함된 리스트를 만들어라\n\nx=list(range(10))\nx\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n아래와 동일한 기능을 수행하는 함수를 lambda expression으로 정의하라.\n\ndef f(xi):\n    return '짝' if (xi % 2)==0 else '홀'\n\nmap과 lambda expression 을 이용하여 아래와 같은 결과를 만들어라. (리스트컴프리헨션, for문 사용금지)\n\n# \n# 구현예시\n\n['짝', '홀', '짝', '홀', '짝', '홀', '짝', '홀', '짝', '홀']"
  },
  {
    "objectID": "posts/2022-10-12-6wk-12.html#월14일-숙제",
    "href": "posts/2022-10-12-6wk-12.html#월14일-숙제",
    "title": "06wk-1,2",
    "section": "2. 10월14일 숙제",
    "text": "2. 10월14일 숙제\n다음과 같은 데이터프레임을 불러온 뒤 물음에 답하라\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/_notebooks/dv2022.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      1\n      95\n      30\n      60\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      3\n      55\n      35\n      35\n      5\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      197\n      85\n      85\n      100\n      10\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n200 rows × 4 columns\n\n\n\n(1) 기말고사 성적이 중간고사 성적보다 향상된 학생들을 출력하라. 즉 mid < fin 인 학생들을 출력하라. (다양한 방법으로 연습할 것, 제출은 한 가지 방법으로 구현해도 감점없음)\n\n# 구현결과가 아래와 같아야 한다. \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      45\n      0\n      10\n    \n    \n      2\n      65\n      85\n      15\n      20\n    \n    \n      4\n      80\n      60\n      55\n      70\n    \n    \n      5\n      75\n      40\n      75\n      85\n    \n    \n      6\n      65\n      70\n      60\n      75\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n      65\n      70\n    \n    \n      195\n      55\n      70\n      40\n      95\n    \n    \n      196\n      65\n      85\n      25\n      85\n    \n    \n      198\n      80\n      65\n      35\n      60\n    \n    \n      199\n      50\n      95\n      45\n      85\n    \n  \n\n93 rows × 4 columns\n\n\n\n(2) 기말고사 성적이 중간고사 성적보다 향상된 학생들의 출석과 레포트 점수를 출력하라.\n\n# 구현결과가 아래와 같아야 한다. \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      0\n      65\n      45\n    \n    \n      2\n      65\n      85\n    \n    \n      4\n      80\n      60\n    \n    \n      5\n      75\n      40\n    \n    \n      6\n      65\n      70\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      194\n      65\n      40\n    \n    \n      195\n      55\n      70\n    \n    \n      196\n      65\n      85\n    \n    \n      198\n      80\n      65\n    \n    \n      199\n      50\n      95\n    \n  \n\n93 rows × 2 columns"
  },
  {
    "objectID": "posts/2022-10-19-7wk-2.html",
    "href": "posts/2022-10-19-7wk-2.html",
    "title": "07wk-2",
    "section": "",
    "text": "아이스크림을 많이 먹으면 걸리는 병(2)"
  },
  {
    "objectID": "posts/2022-10-19-7wk-2.html#자료생성-좀-더-그럴듯한-자료-만들기",
    "href": "posts/2022-10-19-7wk-2.html#자료생성-좀-더-그럴듯한-자료-만들기",
    "title": "07wk-2",
    "section": "자료생성: 좀 더 그럴듯한 자료 (만들기)",
    "text": "자료생성: 좀 더 그럴듯한 자료 (만들기)\n- 지난 시간의 toy example은 데이터가 너무 작아서 억지스러움 \\(\\to\\) 기상자료개방포털, 회원가입해야 자료받을 수 있음.\n\n_df=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/temp.csv')\n_df\n\n\n\n\n\n  \n    \n      \n      지점번호\n      지점명\n      일시\n      평균기온(℃)\n      최고기온(℃)\n      최고기온시각\n      최저기온(℃)\n    \n  \n  \n    \n      0\n      146\n      전주\n      2020-01-01\n      -0.5\n      4.3\n      15:09\n      -6.4\n    \n    \n      1\n      146\n      전주\n      2020-01-02\n      1.4\n      6.5\n      14:12\n      -3.0\n    \n    \n      2\n      146\n      전주\n      2020-01-03\n      2.6\n      7.6\n      13:32\n      -0.5\n    \n    \n      3\n      146\n      전주\n      2020-01-04\n      2.0\n      7.7\n      13:51\n      -2.6\n    \n    \n      4\n      146\n      전주\n      2020-01-05\n      2.5\n      8.6\n      14:05\n      -3.2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      146\n      전주\n      2021-10-13\n      19.9\n      25.5\n      14:29\n      15.6\n    \n    \n      652\n      146\n      전주\n      2021-10-14\n      20.4\n      25.5\n      13:36\n      17.0\n    \n    \n      653\n      146\n      전주\n      2021-10-15\n      18.3\n      22.0\n      13:47\n      15.7\n    \n    \n      654\n      146\n      전주\n      2021-10-16\n      12.8\n      17.4\n      0:01\n      6.5\n    \n    \n      655\n      146\n      전주\n      2021-10-17\n      6.7\n      12.4\n      15:18\n      2.2\n    \n  \n\n656 rows × 7 columns\n\n\n\n- 평균기온만 선택\n\npd.Series(_df.columns)\n\n0       지점번호\n1        지점명\n2         일시\n3    평균기온(℃)\n4    최고기온(℃)\n5     최고기온시각\n6    최저기온(℃)\ndtype: object\n\n\n\ntemp = np.array(_df.iloc[:,3])\ntemp[:5]\n\narray([-0.5,  1.4,  2.6,  2. ,  2.5])\n\n\n\n# 숨은진짜상황1: 온도 \\(\\to\\) 아이스크림 판매량\n- 아래와 같은 관계가 있다고 하자.\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1)\neps = np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2*temp + eps\n\n\nplt.plot(temp,icecream,'o',alpha=0.3)\nplt.xlabel(\"temp\",size=15)\nplt.ylabel(\"icecream\",size=15)\n\nText(0, 0.5, 'icecream')\n\n\n\n\n\n\n\n# 숨은진짜상황1: 온도 \\(\\to\\) 아이스크림 판매량\n- 아래와 같은 관계가 있다고 하자.\n\\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(2) \neps=np.random.normal(size=len(temp),scale=1)\ndisease= 30 + 0.5 * temp + eps\n\n\nplt.plot(temp,disease,'o',alpha=0.3)\nplt.xlabel(\"temp\",size=15)\nplt.ylabel(\"disease\",size=15)\n\nText(0, 0.5, 'disease')\n\n\n\n\n\n\n\n# 우리가 관측한 상황 (온도는 은닉되어있음)\n\nplt.plot(icecream,disease,'o',alpha=0.3)\nplt.xlabel(\"icecream\",size=15)\nplt.ylabel(\"disease\",size=15)\n\nText(0, 0.5, 'disease')\n\n\n\n\n\n\nnp.corrcoef(icecream,disease)\n\narray([[1.        , 0.86298975],\n       [0.86298975, 1.        ]])\n\n\n\n0.86정도.."
  },
  {
    "objectID": "posts/2022-10-19-7wk-2.html#직관-여름만-뽑아서-plot-해보자.",
    "href": "posts/2022-10-19-7wk-2.html#직관-여름만-뽑아서-plot-해보자.",
    "title": "07wk-2",
    "section": "직관: 여름만 뽑아서 plot 해보자.",
    "text": "직관: 여름만 뽑아서 plot 해보자.\n- temp>25 (여름으로 간주) 인 관측치만 플랏\n\nplt.plot(icecream[temp>25],disease[temp>25], 'o', color='C1') ## 평균기온이 25도가 넘어가면 여름이라 생각 \n\n\n\n\n- 전체적인 산점도\n\nfig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2,figsize=(8,6)) \nax1.plot(temp,icecream,'o',alpha=0.2); ax1.set_xlabel('temp'); ax1.set_ylabel('icecream'); ax1.set_title(\"hidden1\")\nax2.plot(temp,disease,'o',alpha=0.2); ax2.set_xlabel('temp'); ax2.set_ylabel('disease'); ax2.set_title(\"hidden2\")\nax3.plot(icecream,disease,'o',alpha=0.2); ax3.set_xlabel('icecream'); ax3.set_ylabel('disease'); ax3.set_title(\"observed\")\nax4.plot(icecream,disease,'o',alpha=0.2); ax4.set_xlabel('icecream'); ax4.set_ylabel('disease'); ax4.set_title(\"observed\")\nax4.plot(icecream[temp>25],disease[temp>25],'o',label='temp>25')\nax4.legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2022-10-19-7wk-2.html#ggplot-온도구간을-세분화-하여-시각화",
    "href": "posts/2022-10-19-7wk-2.html#ggplot-온도구간을-세분화-하여-시각화",
    "title": "07wk-2",
    "section": "ggplot: 온도구간을 세분화 하여 시각화",
    "text": "ggplot: 온도구간을 세분화 하여 시각화\n- 목표: 모든 온도구간에 대하여 각각 색을 다르게 하여 그려보자.\n\n사실 지금 변수는 온도, 아이스크림판매량, 소아마비\n온도가 유사한 지역을 색으로 묶으면 3차원 플랏이 가능함\n\n\n# df로 자료정리\n- 일단 데이터 프레임을 정리하자.\n\ndf = pd.DataFrame({'temp':temp,'icecream':icecream,'disease':disease})\ndf\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n    \n  \n\n656 rows × 3 columns\n\n\n\n\n\n# 구간세분화\n- 온도를 카테고리화 하자 \\(\\to\\) 적당한 구긴을 설정하기 위해서 히스토그램을 그려보자.\n\ndf.temp.hist() # ? 이거 14주차쯤 배우는데 미리 스포합니다.. 엄청 편해요 \n\n<AxesSubplot:>\n\n\n\n\n\n\nplt.hist(df.temp) # 원래는 이걸 배웠죠\n\n(array([  3.,   9.,  29.,  60.,  92.,  86.,  65.,  93., 139.,  80.]),\n array([-12.4 ,  -8.16,  -3.92,   0.32,   4.56,   8.8 ,  13.04,  17.28,\n         21.52,  25.76,  30.  ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- 구간은 5정도로 하면 적당할 것 같다.\n\ndef cut(x): # 이거보다 더 좋은 방법이 있을 것 같긴 한데요..\n    if x<0: \n        y='Temp: <0'\n    elif x<5: \n        y='Temp: 0~5'\n    elif x<10: \n        y='Temp: 5~10'\n    elif x<15: \n        y='Temp: 10~15'\n    elif x<20:\n        y='Temp: 15~20'\n    elif x<25: \n        y='Temp: 20~25'\n    else: \n        y='Temp: >30'\n    return y \n\n\ndf.assign(temp2 = list(map(cut,df.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\n\n# ggplot\n- 온도를 색으로 구분하면\n\nfig = ggplot(data=df.assign(temp2 = list(map(cut,df.temp))))\np1 = geom_point(aes(x='icecream',y='disease',colour='temp2'),alpha=0.5)\nfig + p1\n\n\n\n\n<ggplot: (8762005360345)>\n\n\n- 추세선을 추가하면\n\nl1 = geom_smooth(aes(x='icecream',y='disease',colour='temp2'))\n\n\nfig+p1+l1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8762010169613)>\n\n\n\n각 온도별로 추세선은 거의 기울기가 0이다. \\(\\to\\) 온도가 비슷한 구간별로 묶어서 보니까 상관관계가 없다는 거!\n아이스크림 판매량과 소아마비의 corr은 유의미해보이지만, 온도를 통제하였을 경우 아이스크림 판매량과 소아마비의 partial corr은 유의미해보이지 않음.\n\n\n\n# 해석\n- 해피앤딩: 온도를 통제하니까 아이스크림과 질병은 관련이 없어보인다. \\(\\to\\) 아이스크림을 먹으면 소아마비를 유발한다는 이상한 결론이 나올뻔 했지만 우리는 온도라는 흑막을 잘 찾았고 결과적으로 “온도->아이스크림판매량,소아마비” 이라는 합리적인 진리를 얻을 수 있었다.\n\n온도와 같은 변수를 은닉변수라고 한다.\n\n- 또 다른 흑막? 고려할 흑막이 온도뿐이라는 보장이 어디있지? 사실 흑막2, 흑막3이 있어서 그런 흑막들을 고려하다보니까 아이스크림과 소아마비사이의 상관관계가 다시 보이면 어떡하지?\n\n이러한 이유 때문에 상관계수로 인과성을 유추하는건 사실상 불가능.\n그런데 이론적으로는 “세상의 모든 은닉변수를 통제하였을 경우에도 corr(X,Y)의 값이 1에 가깝다면 그때는 인과성이 있다고 봐도 무방함, (물론 이 경우에도 무엇이 원인인지는 통계적으로 따지는것이 불가)” 이라고 주장할 수 있다. 즉 모든 흑막을 제거한다면 “상관성=인과성”이다.\n\n- 실험계획법, 인과추론: 세상의 모든 흑막을 제거하는건 상식적으로 불가능\n\n피셔의주장(실험계획법): 그런데 실험계획을 잘하면 흑막을 제거한 효과가 있음 (무작위로 사람뽑아서 담배를 피우게 한다든가)\n인과추론: 실험계획이 사실상 불가능한 경우가 있음 \\(\\to\\) 모인 데이터에서 최대한 흑막2,3,4,.. 등이 비슷한 그룹끼리 “매칭”을 시킨다!"
  },
  {
    "objectID": "posts/2022-10-19-7wk-2.html#그냥-궁금해서-진짜-만약에-아이스크림과-소아마비가-관련있는-경우라면",
    "href": "posts/2022-10-19-7wk-2.html#그냥-궁금해서-진짜-만약에-아이스크림과-소아마비가-관련있는-경우라면",
    "title": "07wk-2",
    "section": "그냥 궁금해서: 진짜 만약에 아이스크림과 소아마비가 관련있는 경우라면?",
    "text": "그냥 궁금해서: 진짜 만약에 아이스크림과 소아마비가 관련있는 경우라면?\n- 온도는 아이스크림 판매에 여전히 영향을 주지만\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1)\neps=np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2 * temp + eps \n\n- 수영장이 원인이 아니라 진짜 아이스크림을 먹고 소아마비에 걸린상황이라면?\n\\[\\text{소아마비 반응수치} = 30 + 0 \\times \\text{온도} + 0.15 \\times \\text{아이스크림 판매량} + \\epsilon\\]\n\nnp.random.seed(2) \neps = np.random.normal(size=len(temp),scale=2)\ndisease= 30+ 0*temp + 0.15*icecream + eps\n\n\ndf2=pd.DataFrame({'temp':temp,'icecream':icecream,'disease':disease})\ndf2.assign(temp2=list(map(cut,df2.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      34.453002\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      32.389832\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      28.715350\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      35.271089\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      31.461240\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.693811\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.924088\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      41.765212\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.842022\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      37.715537\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\nggplot(data=df2.assign(temp2=list(map(cut,df2.temp))))+\\\ngeom_point(aes(x='icecream',y='disease',colour='temp2'),alpha=0.2)+\\\ngeom_smooth(aes(x='icecream',y='disease',colour='temp2'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8762005194073)>\n\n\n\n이번엔 partial corr도 유의미하게 나옴\n\n- 단순 corr을 봐서는 “온도->아이스크림,소아마비” 인지, “온도->아이스크림->소아마비” 인지 알기 어렵다.\n\ndf.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.975609\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.862990\n    \n    \n      disease\n      0.975609\n      0.862990\n      1.000000\n    \n  \n\n\n\n\n\ndf2.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.725505\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.830539\n    \n    \n      disease\n      0.725505\n      0.830539\n      1.000000"
  },
  {
    "objectID": "posts/2022-09-06-(A1) MPL tips.html",
    "href": "posts/2022-09-06-(A1) MPL tips.html",
    "title": "A1: tips for matploblib",
    "section": "",
    "text": "matplotlib 미세먼지팁\n\n\n그림만 보고 싶을때\n\nplt.plot([1,2,3,4],[2,3,4,5]);\n\n\n\n\n\n\nmarker size, line width\n\nplt.plot([1,2,3,4],[2,3,4,2],'o',ms=10)\n\n\n\n\n\nplt.plot([1,2,3,4],[2,3,4,5],'--',lw=10)\n\n\n\n\n\n\nlabel + legend\n\nplt.plot([1,2,3,4],[1,2,3,2],'--o',label='A')\nplt.plot([1,2,3,4],[3,2.1,1,3],'--o',label='B')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f5889ead210>\n\n\n\n\n\n\n\n색깔조정 (C0,C1,…)\n\nplt.plot([1,2,3,4],[1,2,3,2],'--o',label='A',color='C1')\nplt.plot([1,2,3,4],[3,2.1,1,3],'--o',label='B',color='C0')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f588a29ef10>\n\n\n\n\n\n\n\ntitle 설정\n- (방법1)\n\nplt.plot([1,2,3,4],[1,2,3,2],'--o',label='A',color='C1')\nplt.plot([1,2,3,4],[3,2.1,1,3],'--o',label='B',color='C0')\nplt.legend()\nplt.title('title')\n\nText(0.5, 1.0, 'title')\n\n\n\n\n\n- (방법2)\n\nfig, ax = plt.subplots()\nax.plot([1,2,3,4],[1,2,3,2],'--o',label='A',color='C1')\nax.plot([1,2,3,4],[3,2.1,1,3],'--o',label='B',color='C0')\nax.legend()\nax.set_title('title')\n\nText(0.5, 1.0, 'title')\n\n\n\n\n\n\n\nsuptitle 설정\n\nfig, ax = plt.subplots(2,2)\nax[0,0].plot([1,2,3,2],'--o',label='A',color='C0')\nax[0,0].set_title('(a)')\nax[0,1].plot([3,2.1,1,3],'--o',label='B',color='C1')\nax[0,1].set_title('(b)')\nax[1,0].plot([-3,-2.1,-1,-3],'--o',label='B',color='C2')\nax[1,0].set_title('(c)')\nax[1,1].plot([3,-2.1,1,-3],'--o',label='B',color='C3')\nax[1,1].set_title('(d)')\n#plt.suptitle('suptitle')\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')\n\n\n\n\n\n\n\ntight_layout()\n\nfig\n\n\n\n\n\nfig.tight_layout()\n\n\nfig\n\n\n\n\n\n\nfig, ax, plt 소속\n- 일단 그림 하나 그리고 이야기좀 해보자.\n\nfig, ax = plt.subplots()\nax.plot([1,2,3,1])\n\n\n\n\n- fig에는 있고 ax에는 없는 것\nadd_axes, tight_layout, suptitle, …\n- ax에는 있고 fig에는 없는 것\nboxplot, hist, plot, set_title, …\n- plt는 대부분 다 있음. (의미상 명확한건 대충 알아서 fig, ax에 접근해서 처리해준다) - plt.tight_layout, plt.suptitle, plt.boxplot, plt.hist, plot.plot - plt.set_title 은 없지만 plt.title 은 있음 - plt.add_axes 는 없음..\n\n\nx축, y축 label 설정\n\nax.xaxis.set_label_text('xlabel',size=16,family='serif',weight=1000,style='italic')\n#_fontsettings={'size':16,'family':'serif','weight'=1000,'style':'italic'}\n#ax.xaxis.set_label_text('xlabel',_fontsettings)\nfig\n\n\n\n\n폰트ref - size: - fontweight: 0~1000 - family: ‘serif’, ‘sans-serif’, ‘monospace’ - style: ‘normal’, ‘italic’\n\nax.set_ylabel('ylabel',size=16)\nfig\n\n\n\n\n\n\nLatex\n- 예시1\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nx1= np.linspace(-2,2,1000)\ny1= (x1-1)**2 \nfig, ax = plt.subplots()\nax.plot(x1,y1,'--')\nax.set_title('$y_1=(x_1-1)^2$')\n\nText(0.5, 1.0, '$y_1=(x_1-1)^2$')\n\n\n\n\n\n- 예시2\n\nx1 = np.linspace(-2,2,1000)\ny1 = 0.5*(x1-1)**2 \nfig, ax = plt.subplots()\nax.plot(x1,y1,'--')\nax.set_title(r'$y_1=\\frac{1}{2}(x_1-1)^2$',size=20);\n\n\n\n\n- 예시3\n\nx1 = np.linspace(-2,2,1000)\ny1 = 0.5*(x1-1)**2 \nfig, ax = plt.subplots()\nax.plot(x1,y1,'--')\nax.set_title(r'$y_1=\\frac{1}{2}(x_1-1)^2$',size=20)\nax.set_xlabel(r'$x_1$',size=15)\nax.set_ylabel(r'$y_1$',size=15);\n\n\n\n\n- 예시4\n\nx1 = np.linspace(-2,2,1000)\ny1 = 0.5*(x1-1)**2 \ny2 = 0.5*(x1+1)**2\nfig, ax = plt.subplots()\nax.plot(x1,y1,'--',label=r'$\\frac{1}{2}(x-1)^2$')\nax.plot(x1,y2,'--',label=r'$\\frac{1}{2}(x+1)^2$')\nax.legend()\n\n<matplotlib.legend.Legend at 0x7f0076915510>\n\n\n\n\n\n\n\nfig.subplots()\n\nfig,ax = plt.subplots(2,2)\nax[0,0].plot([1,2,4,3],'o',color='C0')\nax[0,1].plot([1,2,4,3],'o',color='C1')\nax[1,0].plot([1,2,4,3],'o',color='C2')\nax[1,1].plot([1,2,4,3],'o',color='C3')\n\n\n\n\n\nfig = plt.figure()\nax = fig.subplots(2,2)\nax[0,0].plot([1,2,4,3],'o',color='C0')\nax[0,1].plot([1,2,4,3],'o',color='C1')\nax[1,0].plot([1,2,4,3],'o',color='C2')\nax[1,1].plot([1,2,4,3],'o',color='C3')\n\n\n\n\n\n\nplt.subplot\n\n끝에 s가 없어요!!\n\n- 기능1: 몰라도 됩니당.. (아마도)\n- 기능2: 특이해요.. fig를 안받아도 무방함\n\nax1 = plt.subplot(221) \nax2 = plt.subplot(222)\nax3 = plt.subplot(223)\nax4 = plt.subplot(224)\n\nax1.plot([1,2,4,3],'o',color='C0');ax1.set_title('221')\nax2.plot([1,2,4,3],'o',color='C1');ax2.set_title('222')\nax3.plot([1,2,4,3],'o',color='C2');ax3.set_title('223')\nax4.plot([1,2,4,3],'o',color='C3');ax4.set_title('224')\n\nfig=plt.gcf()\nfig.suptitle(\"plt.subplot(22x)\",size=15)\nfig.tight_layout()\n\n\n\n\n위는 아래와 같은 코드임\n\nfig = plt.figure()\nax1 = fig.add_subplot(221)\nax2 = fig.add_subplot(222)\nax3 = fig.add_subplot(223)\nax4 = fig.add_subplot(224)\n\nax1.plot([1,2,4,3],'o',color='C0');ax1.set_title('221')\nax2.plot([1,2,4,3],'o',color='C1');ax2.set_title('222')\nax3.plot([1,2,4,3],'o',color='C2');ax3.set_title('223')\nax4.plot([1,2,4,3],'o',color='C3');ax4.set_title('224')\n\nfig.tight_layout()\nfig.suptitle(\"fig.add_subplot(22x)\",size=15)\nfig.tight_layout()\n\n\n\n\n- fig.add_subplot() vs fig.add_axes()\n\nfig.add_subplot(): 입력으로 nrows, ncols, index 전달 (편하게 쓰기엔 좋아)\nfig.add_axes(): 입력으로 left, bottom, width, height 전달 (이상한 그래프 만들기 좋아)\n\n- plt.subplots() vs plt.subplot()\n\nplt.subplots(): 넣을 수 있는 액시즈 종류가 한가지\nplt.subplot(): 여러 (특이한) 액시즈를 넣을 수 있음\n\n(기본액시즈)\n\nplt.subplot(111,projection=None)\n\n<AxesSubplot:>\n\n\n\n\n\n(3d 액시즈)\n\nax=plt.subplot(111,projection='3d')\nax.plot([1,2,3,4],[1,2,-3,4],[1,2,-3,-4],'--o')\nfig=plt.gcf()\nfig.set_figheight(12)\n\n\n\n\n(polar 액시즈)\n\nax=plt.subplot(111,projection='polar')\nr = np.linspace(0,5,100)\ntheta = np.linspace(0,2*np.pi,100)\nax.plot(theta,r)"
  },
  {
    "objectID": "posts/2022-09-14-2wk-2.html",
    "href": "posts/2022-09-14-2wk-2.html",
    "title": "02wk-2",
    "section": "",
    "text": "Histogram equalization"
  },
  {
    "objectID": "posts/2022-09-14-2wk-2.html#오늘-배울-내용",
    "href": "posts/2022-09-14-2wk-2.html#오늘-배울-내용",
    "title": "02wk-2",
    "section": "오늘 배울 내용?",
    "text": "오늘 배울 내용?\n- 히스토그램의 활용: 정규분포인지 판단 <- 지난시간 내용\n- 히스토그램의 활용2: 이미지 보정! 히스토그램 이퀄라이제이션 <– 오늘소개할 내용"
  },
  {
    "objectID": "posts/2022-09-14-2wk-2.html#이미지자료-다운로드",
    "href": "posts/2022-09-14-2wk-2.html#이미지자료-다운로드",
    "title": "02wk-2",
    "section": "이미지자료 다운로드",
    "text": "이미지자료 다운로드\n\n!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nimg = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg')\n\n--2022-09-14 17:57:58--  https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nResolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 110895 (108K) [image/jpeg]\nSaving to: ‘Unequalized_Hawkes_Bay_NZ.jpg.5’\n\nUnequalized_Hawkes_ 100%[===================>] 108.30K   505KB/s    in 0.2s    \n\n2022-09-14 17:57:59 (505 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg.5’ saved [110895/110895]\n\n\n\n\nimg.shape\n\n(683, 1024, 3)\n\n\n\nplt.imshow(img)\n\n<matplotlib.image.AxesImage at 0x7f385c732850>"
  },
  {
    "objectID": "posts/2022-09-14-2wk-2.html#이미지자료의-이해",
    "href": "posts/2022-09-14-2wk-2.html#이미지자료의-이해",
    "title": "02wk-2",
    "section": "이미지자료의 이해",
    "text": "이미지자료의 이해"
  },
  {
    "objectID": "posts/2022-09-14-2wk-2.html#비밀1-이미지는-사실-숫자들의-집합이었음.",
    "href": "posts/2022-09-14-2wk-2.html#비밀1-이미지는-사실-숫자들의-집합이었음.",
    "title": "02wk-2",
    "section": "비밀1: 이미지는 사실 숫자들의 집합이었음.",
    "text": "비밀1: 이미지는 사실 숫자들의 집합이었음.\n- 예시1\n\n_img1 = np.array([0,30,90,120,150,180,210,240,255]).reshape(3,3)\n_img1\n\narray([[  0,  30,  90],\n       [120, 150, 180],\n       [210, 240, 255]])\n\n\n\nplt.imshow(_img1,cmap='gray')\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7f385a14c450>\n\n\n\n\n\n- 예시2\n\n_img2 = np.array([0,20,40,60,80,100,120,140,160]).reshape(3,3)\n_img2\n\narray([[  0,  20,  40],\n       [ 60,  80, 100],\n       [120, 140, 160]])\n\n\n\nplt.imshow(_img2,cmap='gray',vmin=0,vmax=255)\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7f385a04e590>\n\n\n\n\n\n- 예시3\n\n_img3 = np.concatenate([_img1,_img2],axis=1)\n_img3\n\narray([[  0,  30,  90,   0,  20,  40],\n       [120, 150, 180,  60,  80, 100],\n       [210, 240, 255, 120, 140, 160]])\n\n\n\nplt.imshow(_img3,cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7f3859fda8d0>"
  },
  {
    "objectID": "posts/2022-09-14-2wk-2.html#비밀2-칼라이미지는-red-green-blue-의-조합으로-표현가능-다른방식도-가능",
    "href": "posts/2022-09-14-2wk-2.html#비밀2-칼라이미지는-red-green-blue-의-조합으로-표현가능-다른방식도-가능",
    "title": "02wk-2",
    "section": "비밀2: 칼라이미지는 red + green + blue 의 조합으로 표현가능 (다른방식도 가능)",
    "text": "비밀2: 칼라이미지는 red + green + blue 의 조합으로 표현가능 (다른방식도 가능)\n- 예시1\n\nr = np.array([0]*25*3).reshape(5,5,3) \ng = np.array([0]*25*3).reshape(5,5,3) \nb = np.array([0]*25*3).reshape(5,5,3) \n\n\nr[:3,:3,0] = 255   \ng[:3,2:,1] = 255\nb[2:,:,2] = 255 \n\n\nplt.imshow(r)\n\n<matplotlib.image.AxesImage at 0x7f3859f00a50>\n\n\n\n\n\n\nplt.imshow(g)\n\n<matplotlib.image.AxesImage at 0x7f3859e8a4d0>\n\n\n\n\n\n\nplt.imshow(b)\n\n<matplotlib.image.AxesImage at 0x7f3859e47590>\n\n\n\n\n\n\nplt.imshow(r+g+b)\n\n<matplotlib.image.AxesImage at 0x7f3859dd67d0>\n\n\n\n\n\n- 예시2: R,G,B를 같은 비율로 섞으면 무채색이 된다.\n\nr = np.array([0]*25*3).reshape(5,5,3) \ng = np.array([0]*25*3).reshape(5,5,3) \nb = np.array([0]*25*3).reshape(5,5,3) \nr[:3,:3,0] = 80   \ng[:3,2:,1] = 80\nb[2:,:,2] = 80 \n\n\nplt.imshow(r+g+b)\n\n<matplotlib.image.AxesImage at 0x7f3859d53610>\n\n\n\n\n\n- 예시3: 우리가 관심있는 자료\n\nimg.shape\n\n(683, 1024, 3)\n\n\n\nimg_red = img * 0 \nimg_green = img * 0 \nimg_blue = img * 0 \n\n\nimg_red[...,0] = img[...,0] \nimg_green[...,1] = img[...,1] \nimg_blue[...,2] = img[...,2] \n\n\nplt.imshow(img_blue)\n\n<matplotlib.image.AxesImage at 0x7f3859ccb750>"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html",
    "href": "posts/2022-11-07-10wk-1.html",
    "title": "10wk-1",
    "section": "",
    "text": "판다스–melt,stack, tidydata, barplot, 해들리위컴의 그레프레이어"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#stack",
    "href": "posts/2022-11-07-10wk-1.html#stack",
    "title": "10wk-1",
    "section": "stack",
    "text": "stack\n- 설명:\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\\\n.groupby([\"AIRLINE\",\"WEEKDAY\"]).agg({\"CANCELLED\":[np.mean,\"count\"],\"DIVERTED\":[np.mean,\"count\"]})\ndf\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277\n      0.004699\n      1277\n    \n    \n      2\n      0.007341\n      1226\n      0.001631\n      1226\n    \n    \n      3\n      0.011949\n      1339\n      0.001494\n      1339\n    \n    \n      4\n      0.015004\n      1333\n      0.003751\n      1333\n    \n    \n      5\n      0.014151\n      1272\n      0.000786\n      1272\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275\n      0.001569\n      1275\n    \n    \n      4\n      0.007911\n      1264\n      0.003165\n      1264\n    \n    \n      5\n      0.005828\n      1201\n      0.000000\n      1201\n    \n    \n      6\n      0.010132\n      987\n      0.003040\n      987\n    \n    \n      7\n      0.006066\n      1154\n      0.002600\n      1154\n    \n  \n\n98 rows × 4 columns\n\n\n\n- 사용예시1\n\ndf.stack()\n\n\n\n\n\n  \n    \n      \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      mean\n      0.032106\n      0.004699\n    \n    \n      count\n      1277.000000\n      1277.000000\n    \n    \n      2\n      mean\n      0.007341\n      0.001631\n    \n    \n      count\n      1226.000000\n      1226.000000\n    \n    \n      3\n      mean\n      0.011949\n      0.001494\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      5\n      count\n      1201.000000\n      1201.000000\n    \n    \n      6\n      mean\n      0.010132\n      0.003040\n    \n    \n      count\n      987.000000\n      987.000000\n    \n    \n      7\n      mean\n      0.006066\n      0.002600\n    \n    \n      count\n      1154.000000\n      1154.000000\n    \n  \n\n196 rows × 2 columns\n\n\n\n- 사용예시2\n\ndf.stack().stack().reset_index().rename({0:'value'},axis=1)\n#df.stack().stack().reset_index().rename(columns={'level_2':'aggtype'})\n\n\n\n\n\n  \n    \n      \n      AIRLINE\n      WEEKDAY\n      level_2\n      level_3\n      value\n    \n  \n  \n    \n      0\n      AA\n      1\n      mean\n      CANCELLED\n      0.032106\n    \n    \n      1\n      AA\n      1\n      mean\n      DIVERTED\n      0.004699\n    \n    \n      2\n      AA\n      1\n      count\n      CANCELLED\n      1277.000000\n    \n    \n      3\n      AA\n      1\n      count\n      DIVERTED\n      1277.000000\n    \n    \n      4\n      AA\n      2\n      mean\n      CANCELLED\n      0.007341\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      387\n      WN\n      6\n      count\n      DIVERTED\n      987.000000\n    \n    \n      388\n      WN\n      7\n      mean\n      CANCELLED\n      0.006066\n    \n    \n      389\n      WN\n      7\n      mean\n      DIVERTED\n      0.002600\n    \n    \n      390\n      WN\n      7\n      count\n      CANCELLED\n      1154.000000\n    \n    \n      391\n      WN\n      7\n      count\n      DIVERTED\n      1154.000000\n    \n  \n\n392 rows × 5 columns\n\n\n\n- 사용예시3 (unstack)\n\ndf.stack().unstack()\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277.0\n      0.004699\n      1277.0\n    \n    \n      2\n      0.007341\n      1226.0\n      0.001631\n      1226.0\n    \n    \n      3\n      0.011949\n      1339.0\n      0.001494\n      1339.0\n    \n    \n      4\n      0.015004\n      1333.0\n      0.003751\n      1333.0\n    \n    \n      5\n      0.014151\n      1272.0\n      0.000786\n      1272.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275.0\n      0.001569\n      1275.0\n    \n    \n      4\n      0.007911\n      1264.0\n      0.003165\n      1264.0\n    \n    \n      5\n      0.005828\n      1201.0\n      0.000000\n      1201.0\n    \n    \n      6\n      0.010132\n      987.0\n      0.003040\n      987.0\n    \n    \n      7\n      0.006066\n      1154.0\n      0.002600\n      1154.0\n    \n  \n\n98 rows × 4 columns\n\n\n\n\nmelt, stack 을 set_index와 reset_index와 함께 사용하면 tidydata를 만들기 용이하다."
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#tidydata의-정의",
    "href": "posts/2022-11-07-10wk-1.html#tidydata의-정의",
    "title": "10wk-1",
    "section": "tidydata의 정의",
    "text": "tidydata의 정의\n- 느낌: ggplot으로 그림 그리기 좋은 데이터 + pandas로 query, group by 등을 쓰기 좋은 자료\n- 정의: https://r4ds.had.co.nz/tidy-data.html\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n예시1 (tidy data)\n\n\n\nobs\nx\ny\nshape\ncolor\n\n\n\n\n0\n0\n0\n‘star’\n‘F’\n\n\n1\n0\n1\n‘circ’\n‘F’\n\n\n2\n1\n0\n‘star’\n‘M’\n\n\n3\n1\n1\n‘circ’\n‘M’\n\n\n\n예시2 (tidy data x)\n\n\n\n\nshape=star\nshape=circ\n\n\n\n\ncolor=F\n(0,0)\n(0,1)\n\n\ncolor=M\n(1,0)\n(1,1)"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#예제1-wide-df",
    "href": "posts/2022-11-07-10wk-1.html#예제1-wide-df",
    "title": "10wk-1",
    "section": "예제1: wide df",
    "text": "예제1: wide df\n- data\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Date\n      Samsung\n      Apple\n      Huawei\n      Xiaomi\n      Oppo\n      Mobicel\n      Motorola\n      LG\n      Others\n      Realme\n      Google\n      Nokia\n      Lenovo\n      OnePlus\n      Sony\n      Asus\n    \n  \n  \n    \n      0\n      2019-10\n      461\n      324\n      136\n      109\n      76\n      81\n      43\n      37\n      135\n      28\n      39\n      14\n      22\n      17\n      20\n      17\n    \n    \n      1\n      2019-11\n      461\n      358\n      167\n      141\n      86\n      61\n      29\n      36\n      141\n      27\n      29\n      20\n      23\n      10\n      19\n      27\n    \n    \n      2\n      2019-12\n      426\n      383\n      143\n      105\n      53\n      45\n      51\n      48\n      129\n      30\n      20\n      26\n      28\n      18\n      18\n      19\n    \n    \n      3\n      2020-01\n      677\n      494\n      212\n      187\n      110\n      79\n      65\n      49\n      158\n      23\n      13\n      19\n      19\n      22\n      27\n      22\n    \n    \n      4\n      2020-02\n      593\n      520\n      217\n      195\n      112\n      67\n      62\n      71\n      157\n      25\n      18\n      16\n      24\n      18\n      23\n      20\n    \n    \n      5\n      2020-03\n      637\n      537\n      246\n      187\n      92\n      66\n      59\n      67\n      145\n      21\n      16\n      24\n      18\n      31\n      22\n      14\n    \n    \n      6\n      2020-04\n      647\n      583\n      222\n      154\n      98\n      59\n      48\n      64\n      113\n      20\n      23\n      25\n      19\n      19\n      23\n      21\n    \n    \n      7\n      2020-05\n      629\n      518\n      192\n      176\n      91\n      87\n      50\n      66\n      150\n      43\n      27\n      15\n      18\n      19\n      19\n      13\n    \n    \n      8\n      2020-06\n      663\n      552\n      209\n      185\n      93\n      69\n      54\n      60\n      140\n      39\n      16\n      16\n      17\n      29\n      25\n      16\n    \n    \n      9\n      2020-07\n      599\n      471\n      214\n      193\n      89\n      78\n      65\n      59\n      130\n      40\n      27\n      25\n      21\n      18\n      18\n      12\n    \n    \n      10\n      2020-08\n      615\n      567\n      204\n      182\n      105\n      82\n      62\n      42\n      129\n      47\n      16\n      23\n      21\n      27\n      23\n      20\n    \n    \n      11\n      2020-09\n      621\n      481\n      230\n      220\n      102\n      88\n      56\n      49\n      143\n      54\n      14\n      15\n      17\n      15\n      19\n      15\n    \n    \n      12\n      2020-10\n      637\n      555\n      232\n      203\n      90\n      52\n      63\n      49\n      140\n      33\n      17\n      20\n      22\n      9\n      22\n      21\n    \n  \n\n\n\n\n\ntidy data 아님\n정의에 의한 판단: 하나의 observation이 하나의 행을 차지하고 있지 않음.\n직관적인 판단: 회사별로 색을 다르게 하여 x:‘Date’, y:’판매량’을 하고 싶다면?\n\n- tidydata로 변환 (melt는 너무 쉬우니까 stack으로 해보자)\n\ndf.set_index('Date').stack().reset_index().rename({'level_1':'Company',0:'Sales'},axis=1)\n\n\n\n\n\n  \n    \n      \n      Date\n      Company\n      Sales\n    \n  \n  \n    \n      0\n      2019-10\n      Samsung\n      461\n    \n    \n      1\n      2019-10\n      Apple\n      324\n    \n    \n      2\n      2019-10\n      Huawei\n      136\n    \n    \n      3\n      2019-10\n      Xiaomi\n      109\n    \n    \n      4\n      2019-10\n      Oppo\n      76\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      203\n      2020-10\n      Nokia\n      20\n    \n    \n      204\n      2020-10\n      Lenovo\n      22\n    \n    \n      205\n      2020-10\n      OnePlus\n      9\n    \n    \n      206\n      2020-10\n      Sony\n      22\n    \n    \n      207\n      2020-10\n      Asus\n      21\n    \n  \n\n208 rows × 3 columns"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#예제2-multi-indexed-data",
    "href": "posts/2022-11-07-10wk-1.html#예제2-multi-indexed-data",
    "title": "10wk-1",
    "section": "예제2: multi-indexed data",
    "text": "예제2: multi-indexed data\n- 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\\\n.groupby([\"AIRLINE\",\"WEEKDAY\"]).agg({\"CANCELLED\":[np.mean,\"count\"],\"DIVERTED\":[np.mean,\"count\"]})\ndf\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      mean\n      count\n      mean\n      count\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      0.032106\n      1277\n      0.004699\n      1277\n    \n    \n      2\n      0.007341\n      1226\n      0.001631\n      1226\n    \n    \n      3\n      0.011949\n      1339\n      0.001494\n      1339\n    \n    \n      4\n      0.015004\n      1333\n      0.003751\n      1333\n    \n    \n      5\n      0.014151\n      1272\n      0.000786\n      1272\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      0.014118\n      1275\n      0.001569\n      1275\n    \n    \n      4\n      0.007911\n      1264\n      0.003165\n      1264\n    \n    \n      5\n      0.005828\n      1201\n      0.000000\n      1201\n    \n    \n      6\n      0.010132\n      987\n      0.003040\n      987\n    \n    \n      7\n      0.006066\n      1154\n      0.002600\n      1154\n    \n  \n\n98 rows × 4 columns\n\n\n\n\ntidy data 아님\n정의에 의한 판단: 하나의 셀에 여러 관측치가 있음 (표안의 표 느낌)\n직관적인 판단: WEEKDAY == 4 and mean(CANCELLED) > 0.001 인 자료를 뽑고 싶다면?\n\n- tidydata로 변환 (stack으로 풀면 너무 쉬우니까 melt로 해보자)\n\ndf.melt(ignore_index=False).reset_index()\n\n\n\n\n\n  \n    \n      \n      AIRLINE\n      WEEKDAY\n      variable_0\n      variable_1\n      value\n    \n  \n  \n    \n      0\n      AA\n      1\n      CANCELLED\n      mean\n      0.032106\n    \n    \n      1\n      AA\n      2\n      CANCELLED\n      mean\n      0.007341\n    \n    \n      2\n      AA\n      3\n      CANCELLED\n      mean\n      0.011949\n    \n    \n      3\n      AA\n      4\n      CANCELLED\n      mean\n      0.015004\n    \n    \n      4\n      AA\n      5\n      CANCELLED\n      mean\n      0.014151\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      387\n      WN\n      3\n      DIVERTED\n      count\n      1275.000000\n    \n    \n      388\n      WN\n      4\n      DIVERTED\n      count\n      1264.000000\n    \n    \n      389\n      WN\n      5\n      DIVERTED\n      count\n      1201.000000\n    \n    \n      390\n      WN\n      6\n      DIVERTED\n      count\n      987.000000\n    \n    \n      391\n      WN\n      7\n      DIVERTED\n      count\n      1154.000000\n    \n  \n\n392 rows × 5 columns"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#geom_col",
    "href": "posts/2022-11-07-10wk-1.html#geom_col",
    "title": "10wk-1",
    "section": "geom_col",
    "text": "geom_col\n- 예시1: 한국과 일본의 평균능력치 비교\n\ndata=df.groupby('Nationality').agg({'Overall':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n    \n    \n      1\n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='Nationality',y='Overall'))\n\n\n\n\n<ggplot: (8739001076625)>\n\n\n- 예시2: 한국과 일본의 평균능력치 비교 (색상변경)\n\ndata=df.groupby('Nationality').agg({'Overall':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n    \n    \n      1\n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='Nationality',y='Overall',fill='Nationality'))\n#ggplot(data)+geom_col(aes(x='Nationality',y='Overall',color='Nationality'))\n\n\n\n\n<ggplot: (8739001430581)>\n\n\n- 예시3: 한국과 일본의 평균연령 비교\n\ndata=df.groupby('Nationality').agg({'Age':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Age\n    \n  \n  \n    \n      0\n      Japan\n      26.084507\n    \n    \n      1\n      Korea Republic\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='Nationality',y='Age',fill='Nationality'))\n\n\n\n\n<ggplot: (8739000939717)>"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#geom_col-positiondodge",
    "href": "posts/2022-11-07-10wk-1.html#geom_col-positiondodge",
    "title": "10wk-1",
    "section": "geom_col + position=‘dodge’",
    "text": "geom_col + position=‘dodge’\n- 예시1: 한국과 일본의 평균연령+평균능력치 비교\n\ndata=df.groupby('Nationality').agg({'Overall':np.mean,'Age':np.mean})\\\n.stack().reset_index().rename({0:'value'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      level_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      66.478873\n    \n    \n      1\n      Japan\n      Age\n      26.084507\n    \n    \n      2\n      Korea Republic\n      Overall\n      65.457627\n    \n    \n      3\n      Korea Republic\n      Age\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\n\n\n\n\n<ggplot: (8739004389489)>"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#geom_col-coord_flip",
    "href": "posts/2022-11-07-10wk-1.html#geom_col-coord_flip",
    "title": "10wk-1",
    "section": "geom_col + coord_flip()",
    "text": "geom_col + coord_flip()\n- 예시1: 한국과 일본의 평균연령+평균능력치 비교 (90도회전)\n\ndata=df.groupby('Nationality').agg({'Overall':np.mean,'Age':np.mean})\\\n.stack().reset_index().rename({0:'value'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      level_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      66.478873\n    \n    \n      1\n      Japan\n      Age\n      26.084507\n    \n    \n      2\n      Korea Republic\n      Overall\n      65.457627\n    \n    \n      3\n      Korea Republic\n      Age\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\\\n+coord_flip()\n\n\n\n\n<ggplot: (8739001299161)>"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#geom_col-facet_wrapvar",
    "href": "posts/2022-11-07-10wk-1.html#geom_col-facet_wrapvar",
    "title": "10wk-1",
    "section": "geom_col + facet_wrap(var)",
    "text": "geom_col + facet_wrap(var)\n- 예시1: 한국과 일본의 평균연령+평균능력치 비교 (면분할)\n\ndata=df.groupby('Nationality').agg({'Overall':np.mean,'Age':np.mean})\\\n.stack().reset_index().rename({0:'value'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      level_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      66.478873\n    \n    \n      1\n      Japan\n      Age\n      26.084507\n    \n    \n      2\n      Korea Republic\n      Overall\n      65.457627\n    \n    \n      3\n      Korea Republic\n      Age\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='Nationality',fill='Nationality',y='value'),position='dodge')\\\n+facet_wrap('level_1')\n\n\n\n\n<ggplot: (8739001171105)>\n\n\n- 예시2: 한국과 일본의 평균연령+평균능력치 비교 (면분할)\n\ndata=df.groupby('Nationality').agg({'Overall':np.mean,'Age':np.mean})\\\n.stack().reset_index().rename({0:'value'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      level_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      66.478873\n    \n    \n      1\n      Japan\n      Age\n      26.084507\n    \n    \n      2\n      Korea Republic\n      Overall\n      65.457627\n    \n    \n      3\n      Korea Republic\n      Age\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='level_1',fill='Nationality',y='value'),position='dodge')\\\n+facet_wrap('Nationality')\n\n\n\n\n<ggplot: (8739005005861)>"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#geom_col-facet_gridvar_y-var_x",
    "href": "posts/2022-11-07-10wk-1.html#geom_col-facet_gridvar_y-var_x",
    "title": "10wk-1",
    "section": "geom_col + facet_grid(‘var_y ~ var_x’)",
    "text": "geom_col + facet_grid(‘var_y ~ var_x’)\n- 예시1: 한국과 일본의 평균연령+평균능력치+최대능력치 비교 (면분할)\n\ndata=df.groupby('Nationality').agg({'Overall':[np.mean,np.max],'Age':np.mean})\\\n.melt(ignore_index=False).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      variable_0\n      variable_1\n      value\n    \n  \n  \n    \n      0\n      Japan\n      Overall\n      mean\n      66.478873\n    \n    \n      1\n      Korea Republic\n      Overall\n      mean\n      65.457627\n    \n    \n      2\n      Japan\n      Overall\n      amax\n      79.000000\n    \n    \n      3\n      Korea Republic\n      Overall\n      amax\n      89.000000\n    \n    \n      4\n      Japan\n      Age\n      mean\n      26.084507\n    \n    \n      5\n      Korea Republic\n      Age\n      mean\n      27.158192\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(fill='Nationality',x='Nationality',y='value'),position='dodge')\\\n+facet_grid('variable_1~variable_0')\n\n\n\n\n<ggplot: (8739001454385)>"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#geom_bar-vs-geom_col",
    "href": "posts/2022-11-07-10wk-1.html#geom_bar-vs-geom_col",
    "title": "10wk-1",
    "section": "geom_bar vs geom_col",
    "text": "geom_bar vs geom_col\n- 예시1: 한국과 일본의 단순 선수 숫자 비교 (with goem_col)\n\ndata=df.groupby('Nationality').agg({'Age':'count'}).reset_index().rename({'Age':'count'},axis=1)\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      count\n    \n  \n  \n    \n      0\n      Japan\n      284\n    \n    \n      1\n      Korea Republic\n      177\n    \n  \n\n\n\n\n\nggplot(data)+geom_col(aes(x='Nationality',fill='Nationality',y='count'))\n\n\n\n\n<ggplot: (8739001309845)>\n\n\n- 예시2: 한국과 일본의 단순 선수 숫자 비교 (with goem_bar)\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'))\n\n\n\n\n<ggplot: (8739003315533)>\n\n\n\n특징1: 원래 데이터프레임 그대로 하는게 아니라 뭔가 변형된 값이 출력 (정확하게는 groupby + count가 변형요소)\n특징2: y는 당연히 count이므로 y를 명시할 필요가 없음. (잘 생각해보면 명시하고 싶어도 명시할 수 없음, y는 groupby + count 에 의해서 계산된 값이고 df자체에는 존재하지 않음)\n\n- 이렇게 약속된 변형은 stat='count' 옵션 때문에 가능함\n\nstat=’count’는 그룹바이이후에 count를 하라는 의미\n\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'),stat='count')\n\n\n\n\n<ggplot: (8739005443049)>\n\n\n- stat='identity' 로 옵션을 바꾸면 약속된 변환이 수행되지 않음\n\nstat=’identity’는 아무 변환도 하지말라는 의미\n\n\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'),stat='identity')\n\nKeyError: 'y'\n\n\n\n에러가난다.\n\n(참고) 사실 아래의 3개의 코드가 모두 같다. <– 수업시간에 설명 X\n\nggplot(df)+geom_bar(aes(x='Nationality',y='..count..',fill='Nationality'),stat='count')\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality'),stat='count') # y='..count..' 생략,\nggplot(df)+geom_bar(aes(x='Nationality',fill='Nationality')) # y='..count..' 생략, stat='count' 생략\n\n\n\n\n<ggplot: (8739004080929)>"
  },
  {
    "objectID": "posts/2022-11-07-10wk-1.html#geom_bar의-불편한점",
    "href": "posts/2022-11-07-10wk-1.html#geom_bar의-불편한점",
    "title": "10wk-1",
    "section": "geom_bar()의 불편한점",
    "text": "geom_bar()의 불편한점\n- 사실 편하라고 만든것 같은데, 그닥 편하지 않음.\n\n편하라고 만든 점1: groupby를 자동으로 해줘서 groupby를 못하는 유저들이 사용하기 편리하게 함 -> 그런데 우리는 groupby 잘함\n편하라고 만든 점2: groupby이후 count연산을 알아서 해줌 -> 그런데 count연산만 알아서해주고 그 이외의 연산은 잘 지원안됨\n\n- 결론: groupby + count 조합에서만 편리하고 나머지는 편하지 않다.\n- 불편한 예시: 나라별 overall의 평균을 geom_bar()로 플랏해보라.\n\ndata= df.groupby('Nationality').agg({'Overall':np.mean}).reset_index()\ndata\n\n\n\n\n\n  \n    \n      \n      Nationality\n      Overall\n    \n  \n  \n    \n      0\n      Japan\n      66.478873\n    \n    \n      1\n      Korea Republic\n      65.457627\n    \n  \n\n\n\n\n\nggplot(data)+geom_bar(aes(x='Nationality',y='Overall',fill='Nationality'),stat='identity')\nggplot(data)+geom_col(aes(x='Nationality',y='Overall',fill='Nationality'))\n\n\n\n\n<ggplot: (8738999896737)>"
  },
  {
    "objectID": "posts/2022-09-10-1wk-1.html",
    "href": "posts/2022-09-10-1wk-1.html",
    "title": "01wk-1",
    "section": "",
    "text": "박스플랏, 히스토그램"
  },
  {
    "objectID": "posts/2022-09-10-1wk-1.html#motivating-example",
    "href": "posts/2022-09-10-1wk-1.html#motivating-example",
    "title": "01wk-1",
    "section": "motivating example",
    "text": "motivating example\n(예제1) 전북고등학교: 평균은 좋은 측정값인가?\n- 전북고등학교에서 통계학을 수업하는 A선생님과 B선생님의 있다. A선생님에게서 수업을 들을 학생들의 평균은 79.1이고 B선생님에게서 수업을 들은 학생들의 평균은 78.3이다.\n\ny1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들\ny2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 \n\n\nnp.mean(y1),np.mean(y2)\n\n(79.1, 78.3)\n\n\n- 의사결정: A선생님에게 배운 학생들의 실력이 평균적으로 더 좋을 것이다.\n- 평균은 A반(=A선생님에게 통계학을 배운 반)이 더 높다. 그런데 98점을 받은 학생이 A반에 포함되어서 A반이 전체평균이 높게 나온것이고 나머지 학생들은 전체적으로 B반 학생들이 더 시험을 잘 보았다고 해석할 수 있다.\n- 교훈: 단순한 평균비교보다 학생들이 받은 점수의 분포를 비교해보는 것이 중요하다. 분포를 살펴보는 방법 중 유용한 방법이 박스플랏이다."
  },
  {
    "objectID": "posts/2022-09-10-1wk-1.html#matplotlib으로-boxplot-그리기",
    "href": "posts/2022-09-10-1wk-1.html#matplotlib으로-boxplot-그리기",
    "title": "01wk-1",
    "section": "matplotlib으로 boxplot 그리기",
    "text": "matplotlib으로 boxplot 그리기\n- A반 학생들의 박스플랏 그리기\n\nplt.boxplot(y1);\n\n\n\n\n- B반 학생들의 박스플랏 그리기\n\nplt.boxplot(y2);\n\n\n\n\n- A반 학생들의 점수와 B반 학생들의 점수를 나란히 박스플랏으로 그리자.\n\nplt.boxplot([y1,y2]);"
  },
  {
    "objectID": "posts/2022-09-10-1wk-1.html#boxplot이란",
    "href": "posts/2022-09-10-1wk-1.html#boxplot이란",
    "title": "01wk-1",
    "section": "boxplot이란?",
    "text": "boxplot이란?\n- ref: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Statistics/boxplot/box_plot.ipynb\n\n\nCode\nnp.random.seed(916170)\n\n# connection path is here: https://stackoverflow.com/questions/6146290/plotting-a-line-over-several-graphs\nmu, sigma = 0, 1 # mean and standard deviation\ns = np.random.normal(mu, sigma, 1000)\n\nfig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(10, 5))\n\n# rectangular box plot\nbplot = axes.boxplot(s,\n                vert=False,\n                patch_artist=True, \n                showfliers=True, # This would show outliers (the remaining .7% of the data)\n                positions = [0],\n                boxprops = dict(linestyle='--', linewidth=2, color='Black', facecolor = 'red', alpha = .4),\n                medianprops = dict(linestyle='-', linewidth=2, color='Yellow'),\n                whiskerprops = dict(linestyle='-', linewidth=2, color='Blue', alpha = .4),\n                capprops = dict(linestyle='-', linewidth=2, color='Black'),\n                flierprops = dict(marker='o', markerfacecolor='green', markersize=10,\n                  linestyle='none', alpha = .4),\n                widths = .3,\n                zorder = 1)   \n\naxes.set_xlim(-4, 4)\nplt.xticks(fontsize = 14)\n\naxes.set_yticks([])\naxes.annotate(r'',\n            xy=(-.73, .205), xycoords='data',\n            xytext=(.66, .205), textcoords='data',\n            arrowprops=dict(arrowstyle=\"|-|\",\n                            connectionstyle=\"arc3\")\n            );\n\naxes.text(0, .25, \"Interquartile Range \\n(IQR)\",  horizontalalignment='center', fontsize=18)\naxes.text(0, -.21, r\"Median\", horizontalalignment='center', fontsize=16);\naxes.text(2.65, -.15, \"\\\"Maximum\\\"\", horizontalalignment='center', fontsize=18);\naxes.text(-2.65, -.15, \"\\\"Minimum\\\"\", horizontalalignment='center', fontsize=18);\naxes.text(-.68, -.24, r\"Q1\", horizontalalignment='center', fontsize=18);\naxes.text(-2.65, -.21, r\"(Q1 - 1.5*IQR)\", horizontalalignment='center', fontsize=16);\naxes.text(.6745, -.24, r\"Q3\", horizontalalignment='center', fontsize=18);\naxes.text(.6745, -.30, r\"(75th Percentile)\", horizontalalignment='center', fontsize=12);\naxes.text(-.68, -.30, r\"(25th Percentile)\", horizontalalignment='center', fontsize=12);\naxes.text(2.65, -.21, r\"(Q3 + 1.5*IQR)\", horizontalalignment='center', fontsize=16);\n\naxes.annotate('Outliers', xy=(2.93,0.015), xytext=(2.52,0.20), fontsize = 18,\n            arrowprops={'arrowstyle': '->', 'color': 'black', 'lw': 2},\n            va='center');\n\naxes.annotate('Outliers', xy=(-3.01,0.015), xytext=(-3.41,0.20), fontsize = 18,\n            arrowprops={'arrowstyle': '->', 'color': 'black', 'lw': 2},\n            va='center');"
  },
  {
    "objectID": "posts/2022-09-10-1wk-1.html#plotly로-boxplot-그리기",
    "href": "posts/2022-09-10-1wk-1.html#plotly로-boxplot-그리기",
    "title": "01wk-1",
    "section": "plotly로 boxplot 그리기",
    "text": "plotly로 boxplot 그리기\n- 로컬에서 하기 위해서는 아래를 설치 (코랩은 필요없음)\n!pip install plotly \n!pip install ipywidgets\n!pip install jupyter-dash\n!pip install dash \n!pip install pandas \n\nimport plotly.express as px \nimport pandas as pd\n\n\ndf= pd.DataFrame({'score':y1+y2,'class':['A']*len(y1) + ['B']*len(y2)})\ndf\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      75\n      A\n    \n    \n      1\n      75\n      A\n    \n    \n      2\n      76\n      A\n    \n    \n      3\n      76\n      A\n    \n    \n      4\n      77\n      A\n    \n    \n      5\n      77\n      A\n    \n    \n      6\n      79\n      A\n    \n    \n      7\n      79\n      A\n    \n    \n      8\n      79\n      A\n    \n    \n      9\n      98\n      A\n    \n    \n      10\n      76\n      B\n    \n    \n      11\n      76\n      B\n    \n    \n      12\n      77\n      B\n    \n    \n      13\n      77\n      B\n    \n    \n      14\n      78\n      B\n    \n    \n      15\n      78\n      B\n    \n    \n      16\n      80\n      B\n    \n    \n      17\n      80\n      B\n    \n    \n      18\n      80\n      B\n    \n    \n      19\n      81\n      B\n    \n  \n\n\n\n\n\npx.box(df,x='class',y='score')"
  },
  {
    "objectID": "posts/2022-09-10-1wk-1.html#motivating-example-1",
    "href": "posts/2022-09-10-1wk-1.html#motivating-example-1",
    "title": "01wk-1",
    "section": "motivating example",
    "text": "motivating example\n- 전북고예제에서 우리의 소망: 그냥 A반 B반 중에 어떤 반이 공부를 더 잘하냐?\n\n보통 이러한 질문은 중심경향값 중 하나를 골라서 비교하면 되었다.\n여기에서 중심경향값이란 데이터 분포의 중심을 보여주는 값으로 자료 전체를 대표할 수 있는 값을 말함. 평균, 중앙값등이 대표적인 중심경향값이다.\n\n- 전북고예제에서는 “A반 B반 중에서 어떤 반이 공부를 더 잘하냐?” 라는 질문의 대답으로 단순평균비교로는 의미가 없었다. 오히려 결과론적으로 보면 중앙값이 더 타당해 보인다.\n- 그런데 사실 생각해보면 중앙값을 기준으로 B반이 공부를 더 잘했다고 주장하는 것도 애매하다. 어쨌든 가장 공부잘한 학생은 A반에 있으니까! (에이 한명 뿐이잖아요? 라고 생각할 수 있는데 그 한명이 2명 3명으로 점점 늘어난다고 생각해보자, 합리적인 기준을 제시할 수 있는가?)\n- 사실 “A반 B반중에 누가 더 공부를 잘하냐?” 라는 질문은 굉장히 대답하기 곤란한 질문이다. 왜냐하면\n\n이슈1: 단순 평균비교로 이러한 질문에 답을 하기 어렵다.\n이슈2: 박스플랏으로 전체분포를 파악해도 어떠한 반이 더 공부를 잘한다는 기준을 잡는게 애매하다.\n\n그런데 특수한 경우에는 “A반 B반중에 누가 더 공부를 잘하냐?” 라는 질문에 대한 대답을 깔끔하게 할 수 있다.\n(예제2) 정규분포 전북고등학교: 평균은 좋은 측정값인가?\n- A반과 B반의 통계학 성적이 아래와 같다고 하자.\n\nnp.random.seed(43052)\ny1 = np.random.randn(10000)\ny2 = np.random.randn(10000) + 0.5 \n\n\nnp.mean(y1),np.mean(y2)\n\n(-0.011790879905079434, 0.4979147460611458)\n\n\n\nnp.mean(y2) - np.mean(y1)\n\n0.5097056259662253\n\n\ny2의 값이 y1의 값보다 전체적으로 0.5097056259662253 정도 높다고 볼 수 있다?\n\nplt.boxplot([y1,y2]);\n\n\n\n\n\n분포의 모양이 거의 비슷, 왼쪽그림을 컨트롤+C 하여 오른쪽에 붙인다음 0.5정도 y축으로 올린느낌이다!\n\n- 이러한 상황에서는 “B반의 성적 \\(\\approx\\) A반의 성적 + 0.5” 라고 주장해도 큰 무리가 없어보인다. 따라서 이 경우에는 “A반 B반 중에 어떤반이 더 공부를 잘하냐?” 라는 질문에 대하여 “B반이 평균적으로 0.5점정도 더 공부를 잘합니다” 라고 대답해도 괜찮다.\n- 결론: 정규분포 분포가정을 한다면 이슈1,2에 대한 문제를 한번에 해결가능함\n- 정규분포가정은 어떻게 할 수 있나? (= 데이터를 보고 어떻게 정규분포라고 알 수 있는가?): 데이터의 히스토그램을 그려서 종 모양이 되는지 확인해본다. (아직 초보단걔라서 이것밖에 모를 수 있어요)\n\nhistogram 이란?\n- 히스토그램: X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림\n\n\nmatplotlib으로 histogram 그리기\n- 히스토그램의 예시1\n\ny=[10,11,12,15,16,20,21,22,23,24,25]\n\n\nplt.hist(y)\n\n(array([2., 1., 0., 1., 1., 0., 1., 1., 2., 2.]),\n array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n\nplt.hist(y,bins=10)\n\n(array([2., 1., 0., 1., 1., 0., 1., 1., 2., 2.]),\n array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- 히스토그램 예시2\n\nplt.hist(y,bins=2)\n#plt.hist(y,bins=1)\n\n(array([5., 6.]),\n array([10. , 17.5, 25. ]),\n <BarContainer object of 2 artists>)\n\n\n\n\n\n- 히스토그램 예시3\n\nplt.hist(y,bins=3)\n\n(array([3., 2., 6.]),\n array([10., 15., 20., 25.]),\n <BarContainer object of 3 artists>)\n\n\n\n\n\n\n가장 큰 값은 25, 가장 작은 값은 10이므로 range는 15이다.\nrange / bins = 15 / 3 = 5 이므로 각 구간의 간격은 5이다.\n구간은 [10,15), [15,20), [20,25] 로 나눈다.\n각 구간에 포함된 자료의 수는 3,2,6 이다.\n\n- 히스토그램 예시4\n\nplt.hist(y,bins=7) \n\n(array([3., 0., 2., 0., 1., 2., 3.]),\n array([10.        , 12.14285714, 14.28571429, 16.42857143, 18.57142857,\n        20.71428571, 22.85714286, 25.        ]),\n <BarContainer object of 7 artists>)\n\n\n\n\n\n\n가장 큰 값은 25, 가장 작은 값은 10이므로 range는 15이다.\nrange / bins = 15 / 7 = 2.142857142857143 이므로 각 구간의 간격은 2.142857142857143이다.\n구간은 [10,12.14285714), [12.14285714,14.28571429,), [22.85714286,25] 로 나눈다.\n각 구간에 포함된 자료의 수는 3,0,2,0,1,2,3 이다.\n\n- 히스토그램 예시5\n\n# np.random.seed(43052)\n# y1 = np.random.randn(10000)\n# y2 = np.random.randn(10000) + 0.5 \nplt.hist([y1,y2],bins=50);\n\n\n\n\n\n\nseaborn으로 histogram 그리기\n\nimport seaborn as sns \n\n\ndf=pd.DataFrame({'score':np.concatenate([y1,y2]), 'class':['A']*len(y1)+['B']*len(y2)})\ndf\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      0.383420\n      A\n    \n    \n      1\n      1.084175\n      A\n    \n    \n      2\n      1.142778\n      A\n    \n    \n      3\n      0.307894\n      A\n    \n    \n      4\n      0.237787\n      A\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      19995\n      0.493276\n      B\n    \n    \n      19996\n      0.619512\n      B\n    \n    \n      19997\n      -0.500529\n      B\n    \n    \n      19998\n      1.267551\n      B\n    \n    \n      19999\n      1.004863\n      B\n    \n  \n\n20000 rows × 2 columns\n\n\n\n\nsns.histplot(df,x='score',hue='class')\n\n<AxesSubplot:xlabel='score', ylabel='Count'>\n\n\n\n\n\n\n\nplotnine으로 histogram 그리기\n\nfrom plotnine import *\n\n\nggplot(df) + geom_histogram(aes(x='score',fill='class'),position='identity',alpha=0.5)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 84'. Pick better value with 'binwidth'.\n\n\n\n\n\n<ggplot: (8787216362017)>\n\n\n\nggplot(df) + geom_histogram(aes(x='score',fill='class'),alpha=0.5) ## 비교를 위해서 관찰만 할것\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 84'. Pick better value with 'binwidth'.\n\n\n\n\n\n<ggplot: (8787219120217)>\n\n\n\n\nplotly로 histogram 그리기\n\nimport plotly.figure_factory as ff\n\nhist_data = [y1, y2]\n\ngroup_labels = ['A', 'B']\n\n# Create distplot with curve_type set to 'normal'\nff.create_distplot(hist_data, group_labels,bin_size=.2, show_rug=False)"
  },
  {
    "objectID": "posts/2022-09-10-1wk-1.html#숙제",
    "href": "posts/2022-09-10-1wk-1.html#숙제",
    "title": "01wk-1",
    "section": "숙제",
    "text": "숙제\n(1) 자기학번으로 np.random.seed(202043052)를 만들고\n(2) y1, y2 // 10만개의 정규분포를 생성해서 저장\n\ny1: 평균 0, 표준편차=1\ny2: 평균 1, 표준편차=1\n\n(3) plotly 를 활용하여 히스토그램을 겹쳐서 그려보는것."
  },
  {
    "objectID": "posts/2022-11-09-10wk-2.html",
    "href": "posts/2022-11-09-10wk-2.html",
    "title": "10wk-2",
    "section": "",
    "text": "심슨의 역설"
  },
  {
    "objectID": "posts/2022-11-09-10wk-2.html#시각화1-전체합격률",
    "href": "posts/2022-11-09-10wk-2.html#시각화1-전체합격률",
    "title": "10wk-2",
    "section": "시각화1: 전체합격률",
    "text": "시각화1: 전체합격률\n- df1\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n    \n    \n      1\n      female\n      pass\n      772\n    \n    \n      2\n      male\n      fail\n      1291\n    \n    \n      3\n      male\n      pass\n      1400\n    \n  \n\n\n\n\n- df2\n\ndf.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n    \n  \n  \n    \n      0\n      female\n      1835\n    \n    \n      1\n      male\n      2691\n    \n  \n\n\n\n\n- merge: 두개의 데이터프레임을 합친다\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n    \n  \n\n\n\n\n- 비율계산\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n      0.579292\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n      0.420708\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n      0.479747\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n      0.520253\n    \n  \n\n\n\n\n- 시각화\n\ndata1= df.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(data1.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\n\n\n\n\n<ggplot: (8789343060161)>\n\n\n- 결론: 남자의 합격률이 더 높다. \\(\\to\\) 성차별이 있어보인다(?)"
  },
  {
    "objectID": "posts/2022-11-09-10wk-2.html#시각화2-학과별-합격률",
    "href": "posts/2022-11-09-10wk-2.html#시각화2-학과별-합격률",
    "title": "10wk-2",
    "section": "시각화2: 학과별 합격률",
    "text": "시각화2: 학과별 합격률\n- df2\n\ndf.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      department\n      gender\n      count2\n    \n  \n  \n    \n      0\n      A\n      female\n      108\n    \n    \n      1\n      A\n      male\n      825\n    \n    \n      2\n      B\n      female\n      25\n    \n    \n      3\n      B\n      male\n      560\n    \n    \n      4\n      C\n      female\n      593\n    \n    \n      5\n      C\n      male\n      325\n    \n    \n      6\n      D\n      female\n      375\n    \n    \n      7\n      D\n      male\n      417\n    \n    \n      8\n      E\n      female\n      393\n    \n    \n      9\n      E\n      male\n      191\n    \n    \n      10\n      F\n      female\n      341\n    \n    \n      11\n      F\n      male\n      373\n    \n  \n\n\n\n\n- merge\n\ndf.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\n\n\n\n\n\n  \n    \n      \n      department\n      result\n      gender\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n      108\n      0.175926\n    \n    \n      1\n      A\n      pass\n      female\n      89\n      108\n      0.824074\n    \n    \n      2\n      A\n      fail\n      male\n      314\n      825\n      0.380606\n    \n    \n      3\n      A\n      pass\n      male\n      511\n      825\n      0.619394\n    \n    \n      4\n      B\n      fail\n      female\n      7\n      25\n      0.280000\n    \n    \n      5\n      B\n      pass\n      female\n      18\n      25\n      0.720000\n    \n    \n      6\n      B\n      fail\n      male\n      208\n      560\n      0.371429\n    \n    \n      7\n      B\n      pass\n      male\n      352\n      560\n      0.628571\n    \n    \n      8\n      C\n      fail\n      female\n      391\n      593\n      0.659359\n    \n    \n      9\n      C\n      pass\n      female\n      202\n      593\n      0.340641\n    \n    \n      10\n      C\n      fail\n      male\n      204\n      325\n      0.627692\n    \n    \n      11\n      C\n      pass\n      male\n      121\n      325\n      0.372308\n    \n    \n      12\n      D\n      fail\n      female\n      244\n      375\n      0.650667\n    \n    \n      13\n      D\n      pass\n      female\n      131\n      375\n      0.349333\n    \n    \n      14\n      D\n      fail\n      male\n      279\n      417\n      0.669065\n    \n    \n      15\n      D\n      pass\n      male\n      138\n      417\n      0.330935\n    \n    \n      16\n      E\n      fail\n      female\n      299\n      393\n      0.760814\n    \n    \n      17\n      E\n      pass\n      female\n      94\n      393\n      0.239186\n    \n    \n      18\n      E\n      fail\n      male\n      137\n      191\n      0.717277\n    \n    \n      19\n      E\n      pass\n      male\n      54\n      191\n      0.282723\n    \n    \n      20\n      F\n      fail\n      female\n      103\n      341\n      0.302053\n    \n    \n      21\n      F\n      pass\n      female\n      238\n      341\n      0.697947\n    \n    \n      22\n      F\n      fail\n      male\n      149\n      373\n      0.399464\n    \n    \n      23\n      F\n      pass\n      male\n      224\n      373\n      0.600536\n    \n  \n\n\n\n\n- 시각화\n\ndata2=df.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\\\n+facet_wrap('department')\n\n\n\n\n<ggplot: (8789343111249)>\n\n\n\n학과별로 살펴보니 오히려 A,B,F,D의 경우 여성의 합격률이 높다.\n\n- 교재에서 설명한 이유: 여성이 합격률이 낮은 학과에만 많이 지원하였기 때문\n\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='department',y='count2',fill='gender'),position='dodge')\n\n\n\n\n<ggplot: (8789343070225)>\n\n\n\n살펴보니 합격률이 높은 A,B학과의 경우 상대적으로 남성이 많이 지원하였음. 합격률이 낮은 C,D학과는 상대적으로 여성이 많이 지원함. D,F의 지원수는 비슷"
  },
  {
    "objectID": "posts/2022-11-23-12wk-2.html",
    "href": "posts/2022-11-23-12wk-2.html",
    "title": "12wk-2",
    "section": "",
    "text": "px.scatter_geo, animation"
  },
  {
    "objectID": "posts/2022-11-23-12wk-2.html#세계지도-그리기",
    "href": "posts/2022-11-23-12wk-2.html#세계지도-그리기",
    "title": "12wk-2",
    "section": "세계지도 그리기",
    "text": "세계지도 그리기\n- 기본그리기1\n\npx.scatter_geo()\n\n\n                                                \n\n\n- 기본그리기2\n\npx.scatter_geo(projection='natural earth')"
  },
  {
    "objectID": "posts/2022-11-23-12wk-2.html#세계지도-버블",
    "href": "posts/2022-11-23-12wk-2.html#세계지도-버블",
    "title": "12wk-2",
    "section": "세계지도 + 버블",
    "text": "세계지도 + 버블\n- 좌표에 점을 찍어보기1\n\ndf=pd.DataFrame({'lat':[0,38],'lon':[0,127],'size':[5,20]})\ndf\n\n\n\n\n\n  \n    \n      \n      lat\n      lon\n      size\n    \n  \n  \n    \n      0\n      0\n      0\n      5\n    \n    \n      1\n      38\n      127\n      20\n    \n  \n\n\n\n\n\npx.scatter_geo(df,lat='lat',lon='lon',size='size')\n\n\n                                                \n\n\n- 좌표에 점을 찍어보기2\n\ndf=pd.DataFrame({'iso_alpha':['KOR','JPN'],'size':[10,2]})\ndf\n\n\n\n\n\n  \n    \n      \n      iso_alpha\n      size\n    \n  \n  \n    \n      0\n      KOR\n      10\n    \n    \n      1\n      JPN\n      2\n    \n  \n\n\n\n\n\npx.scatter_geo(df,locations='iso_alpha',size='size')"
  },
  {
    "objectID": "posts/2022-11-23-12wk-2.html#gapminder-data-시각화",
    "href": "posts/2022-11-23-12wk-2.html#gapminder-data-시각화",
    "title": "12wk-2",
    "section": "Gapminder data 시각화",
    "text": "Gapminder data 시각화\n- Gapminder\n\n스웨덴 스톡홀름에 등록된 비영리 벤처 기업\nTrendalyzer 소프트웨어를 개발하여 애니메이션 거품 그래프를 생성 \\(\\to\\) 소프트웨어는 2006년, Gapminder의 개발자는 2007년에 글고..\n\n\nhttps://www.youtube.com/watch?v=N91kkT-vC6w\n\n- Gapminder data: 국가별 기대수명, 1인당 GDP, 인구에 대한 데이터 - 특징: 연도별로 정리가 되어있다.\n\ndf = px.data.gapminder()\ndf\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n      iso_alpha\n      iso_num\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n      AFG\n      4\n    \n    \n      1\n      Afghanistan\n      Asia\n      1957\n      30.332\n      9240934\n      820.853030\n      AFG\n      4\n    \n    \n      2\n      Afghanistan\n      Asia\n      1962\n      31.997\n      10267083\n      853.100710\n      AFG\n      4\n    \n    \n      3\n      Afghanistan\n      Asia\n      1967\n      34.020\n      11537966\n      836.197138\n      AFG\n      4\n    \n    \n      4\n      Afghanistan\n      Asia\n      1972\n      36.088\n      13079460\n      739.981106\n      AFG\n      4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1699\n      Zimbabwe\n      Africa\n      1987\n      62.351\n      9216418\n      706.157306\n      ZWE\n      716\n    \n    \n      1700\n      Zimbabwe\n      Africa\n      1992\n      60.377\n      10704340\n      693.420786\n      ZWE\n      716\n    \n    \n      1701\n      Zimbabwe\n      Africa\n      1997\n      46.809\n      11404948\n      792.449960\n      ZWE\n      716\n    \n    \n      1702\n      Zimbabwe\n      Africa\n      2002\n      39.989\n      11926563\n      672.038623\n      ZWE\n      716\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n      ZWE\n      716\n    \n  \n\n1704 rows × 8 columns\n\n\n\n- 2007년만 추출\n\ndf.query('year==2007')\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n      iso_alpha\n      iso_num\n    \n  \n  \n    \n      11\n      Afghanistan\n      Asia\n      2007\n      43.828\n      31889923\n      974.580338\n      AFG\n      4\n    \n    \n      23\n      Albania\n      Europe\n      2007\n      76.423\n      3600523\n      5937.029526\n      ALB\n      8\n    \n    \n      35\n      Algeria\n      Africa\n      2007\n      72.301\n      33333216\n      6223.367465\n      DZA\n      12\n    \n    \n      47\n      Angola\n      Africa\n      2007\n      42.731\n      12420476\n      4797.231267\n      AGO\n      24\n    \n    \n      59\n      Argentina\n      Americas\n      2007\n      75.320\n      40301927\n      12779.379640\n      ARG\n      32\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1655\n      Vietnam\n      Asia\n      2007\n      74.249\n      85262356\n      2441.576404\n      VNM\n      704\n    \n    \n      1667\n      West Bank and Gaza\n      Asia\n      2007\n      73.422\n      4018332\n      3025.349798\n      PSE\n      275\n    \n    \n      1679\n      Yemen, Rep.\n      Asia\n      2007\n      62.698\n      22211743\n      2280.769906\n      YEM\n      887\n    \n    \n      1691\n      Zambia\n      Africa\n      2007\n      42.384\n      11746035\n      1271.211593\n      ZMB\n      894\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n      ZWE\n      716\n    \n  \n\n142 rows × 8 columns\n\n\n\n- 시각화예시1: (x,y) = (lon,lat) = locations\n\npx.scatter_geo(\n    data_frame = df.query('year==2007'),\n    locations= 'iso_alpha'\n)\n\n\n                                                \n\n\n- 시각화예시2: (x,y) = (lon,lat) = locations, size= pop\n\npx.scatter_geo(\n    data_frame = df.query('year==2007'),\n    locations= 'iso_alpha',\n    size='pop'\n)\n\n\n                                                \n\n\n- 시각화예시3: (x,y) = (lon,lat) = locations, size= pop, color= continent\n\npx.scatter_geo(\n    data_frame = df.query('year==2007'),\n    locations= 'iso_alpha',\n    size='pop',\n    color='continent'\n)"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html",
    "href": "posts/2022-10-06-5wk-2.html",
    "title": "05wk-2",
    "section": "",
    "text": "훌륭한 시각화, mpg 데이터 소개, plotnine(p9)을 이용한 고차원 산점도"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#애드워드-터프티",
    "href": "posts/2022-10-06-5wk-2.html#애드워드-터프티",
    "title": "05wk-2",
    "section": "애드워드 터프티",
    "text": "애드워드 터프티\n- 데이터 시각화계의 거장\n- 터프티의 이론중 백미: 엄격한 미니멀리즘\n\n최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다.\n작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다.\n\n- 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량\n- 차트정크 (나이젤홈즈의 그래프)\n\n\n“Lurking behind chartjunk is contempt both for information and for the audience. Chartjunk promoters imagine that numbers and details are boring, dull, and tedious, requiring ornament to enliven. Cosmetic decoration, which frequently distorts the data, will never salvage an underlying lack of content. If the numbers are boring, then you’ve got the wrong numbers (…) Worse is contempt for our audience, designing as if readers were obtuse and uncaring. In fact, consumers of graphics are often more intelligent about the information at hand than those who fabricate the data decoration (…) The operating moral premise of information design should be that our readers are alert and caring; they may be busy, eager to get on with it, but they are not stupid.”\n\n\n차트정크 = 대중을 멸시 + 데이터에 대한 모독\n차트정크 옹호가는 숫자와 데이터가 지루하여 활기가 필요하다고 생각하는 모양이다..\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 제 생각: 글쎄…"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#찰스미나드의-도표",
    "href": "posts/2022-10-06-5wk-2.html#찰스미나드의-도표",
    "title": "05wk-2",
    "section": "찰스미나드의 도표",
    "text": "찰스미나드의 도표\n\n인류역사상 가장 훌륭한 시각화\n\n\n- 터프티의 평\n\n지금까지 그려진 최고의 통계 그래픽일지도 모른다.\n여기에서는 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 \\(\\to\\) 6차원의 변수\n백만번에 한번 이런 그림을 그릴수는 있겠지만 이러한 멋진 그래픽을 만드는 방법에 대한 원칙은 없다. \\(\\to\\) 미니멀리즘..\n\n- 왜 우수한 그래프일까?\n\n자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존\n이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임\n미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함."
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#미나드처럼-그리는게-왜-어려운가",
    "href": "posts/2022-10-06-5wk-2.html#미나드처럼-그리는게-왜-어려운가",
    "title": "05wk-2",
    "section": "미나드처럼 그리는게 왜 어려운가?",
    "text": "미나드처럼 그리는게 왜 어려운가?\n- 몸무게, 키, 성별, 국적\n\ndf1=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male1.csv')\ndf2=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male2.csv')  \ndf3=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/female.csv') \ndf4=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/foreign.csv')\n\n- 미나드의 접근방법\n\n_df = pd.concat([pd.concat([df1,df2],axis=1).assign(g='m'),df3.assign(g='f')])\ndf = pd.concat([_df.assign(g2='korea'),df4.assign(g2='foreign')]).reset_index(drop=True)\ndf\n\n\n\n\n\n  \n    \n      \n      w\n      h\n      g\n      g2\n    \n  \n  \n    \n      0\n      72.788217\n      183.486773\n      m\n      korea\n    \n    \n      1\n      66.606430\n      173.599877\n      m\n      korea\n    \n    \n      2\n      69.806324\n      173.237903\n      m\n      korea\n    \n    \n      3\n      67.449439\n      173.223805\n      m\n      korea\n    \n    \n      4\n      70.463183\n      174.931946\n      m\n      korea\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1525\n      78.154632\n      188.324350\n      m\n      foreign\n    \n    \n      1526\n      74.754308\n      183.017979\n      f\n      foreign\n    \n    \n      1527\n      91.196208\n      190.100456\n      m\n      foreign\n    \n    \n      1528\n      87.770394\n      187.987255\n      m\n      foreign\n    \n    \n      1529\n      88.021995\n      193.456798\n      m\n      foreign\n    \n  \n\n1530 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df,x='w',y='h',hue='g',style='g2')\n\n<AxesSubplot:xlabel='w', ylabel='h'>\n\n\n\n\n\n- 어려운점: (1) 센스가 없어서 hue/style을 이용하여 그룹을 구분할 생각을 못함 (2) long df (=tidy data) 형태로 데이터를 정리할 생각을 못함 (3) long df 형태로 데이터를 변형하는 코드를 모름\n\n\n기획력부족 -> 훌륭한 시각화를 많이 볼 것\n\n\n데이터프레임에 대한 이해부족 -> tidydata에 대한 개념\n\n\n프로그래밍 능력 -> 코딩공부열심히 (pandas를 엄청 잘해야함)"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#방법1-rpy2-코랩-아닌경우-실습금지",
    "href": "posts/2022-10-06-5wk-2.html#방법1-rpy2-코랩-아닌경우-실습금지",
    "title": "05wk-2",
    "section": "방법1: rpy2 (코랩 아닌경우 실습금지)",
    "text": "방법1: rpy2 (코랩 아닌경우 실습금지)\n\nimport rpy2\n%load_ext rpy2.ipython\n\n\n%%R \n### 여기는 R처럼 쓸 수 있다. \na <- c(1,2,3) \na+1\n\n[1] 2 3 4\n\n\n\na\n\nNameError: name 'a' is not defined\n\n\n\n%%R \nlibrary(tidyverse)\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# … with 224 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nmpg\n\nNameError: name 'mpg' is not defined\n\n\n\n%R -o mpg # R에 있는 자료가 파이썬으로 넘어옴\n\n\nmpg\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      5\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      234\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "href": "posts/2022-10-06-5wk-2.html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "title": "05wk-2",
    "section": "방법2: 저장된 csv파일을 통하여 데이터를 확보",
    "text": "방법2: 저장된 csv파일을 통하여 데이터를 확보\n\nmpg.to_csv(\"mpg.csv\",index=False)\n\n\npd.read_csv(\"mpg.csv\")\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#방법3-github등에-공개된-csv를-읽어오기",
    "href": "posts/2022-10-06-5wk-2.html#방법3-github등에-공개된-csv를-읽어오기",
    "title": "05wk-2",
    "section": "방법3: github등에 공개된 csv를 읽어오기",
    "text": "방법3: github등에 공개된 csv를 읽어오기\n\npd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/mpg.csv')\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns\n\n\n\n- 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다."
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#data-설명",
    "href": "posts/2022-10-06-5wk-2.html#data-설명",
    "title": "05wk-2",
    "section": "data 설명",
    "text": "data 설명\n- displ: 자동차의 엔진크기\n- hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐?\n- 자세한 설명은 R에서 ?mpg를 이용해 스스로 찾아볼 것"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#python에서-plotnine을-이용한-산점도",
    "href": "posts/2022-10-06-5wk-2.html#python에서-plotnine을-이용한-산점도",
    "title": "05wk-2",
    "section": "python에서: plotnine을 이용한 산점도",
    "text": "python에서: plotnine을 이용한 산점도\n\nggplot(data=mpg) + geom_point(mapping=aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726736046009)>\n\n\n\n산점도 해석: 엔진크기가 클수록 효율이 낮음.\n\n- 빠르게 그리기: data=와 mapping=은 생략가능함\n\nggplot(mpg) + geom_point(aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726735544581)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#r에서-ggplot2를-이용한-산점도",
    "href": "posts/2022-10-06-5wk-2.html#r에서-ggplot2를-이용한-산점도",
    "title": "05wk-2",
    "section": "R에서: ggplot2를 이용한 산점도",
    "text": "R에서: ggplot2를 이용한 산점도\n- R에서도 거의 똑같은 문법으로 그릴 수 있음 (데이터프레임 혹은 티블에 저장된 column 이름을 사용할때 따옴표만 제거하면 된다!)\n\n%%R -w 800\nggplot(mpg) + geom_point(aes(x=displ,y=hwy)) ## plotnine"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "href": "posts/2022-10-06-5wk-2.html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "title": "05wk-2",
    "section": "python에서: 객체지향적인 느낌으로 산점도 그리기",
    "text": "python에서: 객체지향적인 느낌으로 산점도 그리기\nstep1: 도화지를 준비한다.\n\nfig = ggplot(data=mpg)\nfig\n\n\n\n\n<ggplot: (8726735085529)>\n\n\nstep2 변수와 에스테틱사이의 맵핑을 설정한다.\n\na1= aes(x='displ',y='hwy')\na1\n\n{'x': 'displ', 'y': 'hwy'}\n\n\nstep3 점들의 집합을 만든다. 즉 포인트 지옴을 만든다.\n\npoint1=geom_point(mapping=a1)\n\n\ngeom_point(): 점들을 그려! 어떻게?\na1에서 설정된 표를 보고\n\nstep4 도화지와 지옴을 합친다.\n\nfig+point1\n\n\n\n\n<ggplot: (8726775447877)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-점크기변경",
    "href": "posts/2022-10-06-5wk-2.html#산점도-점크기변경",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경",
    "text": "산점도 + 점크기변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734563561)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-투명도변경",
    "href": "posts/2022-10-06-5wk-2.html#산점도-투명도변경",
    "title": "05wk-2",
    "section": "산점도 + 투명도변경",
    "text": "산점도 + 투명도변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734989121)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-투명도점크기를-동시에-적용",
    "href": "posts/2022-10-06-5wk-2.html#산점도-투명도점크기를-동시에-적용",
    "title": "05wk-2",
    "section": "산점도 + 투명도/점크기를 동시에 적용",
    "text": "산점도 + 투명도/점크기를 동시에 적용\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734522405)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-형태",
    "href": "posts/2022-10-06-5wk-2.html#산점도-형태",
    "title": "05wk-2",
    "section": "산점도 + 형태",
    "text": "산점도 + 형태\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',shape='class'))\n\n\n\n\n<ggplot: (8726734265229)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-색깔",
    "href": "posts/2022-10-06-5wk-2.html#산점도-색깔",
    "title": "05wk-2",
    "section": "산점도 + 색깔",
    "text": "산점도 + 색깔\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',color='class'))\n\n\n\n\n<ggplot: (8726734017473)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#객체지향적-느낌으로",
    "href": "posts/2022-10-06-5wk-2.html#객체지향적-느낌으로",
    "title": "05wk-2",
    "section": "객체지향적 느낌으로?",
    "text": "객체지향적 느낌으로?\n\na2 = aes(x='displ', y='hwy', color='class') \n\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\npoint2=geom_point(a2)\n\n\nfig+point2\n\n\n\n\n<ggplot: (8726733712885)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-색깔-적합선",
    "href": "posts/2022-10-06-5wk-2.html#산점도-색깔-적합선",
    "title": "05wk-2",
    "section": "산점도 + 색깔 + 적합선",
    "text": "산점도 + 색깔 + 적합선\n- 일단 색깔이 없는 포인트 지옴부터 연습\n\nfig+point1\n\n\n\n\n<ggplot: (8726733452617)>\n\n\n\nline1 = geom_smooth(a1)\n\n\nfig+point1+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732994973)>\n\n\n- point1(색깔없는 포인트 지옴)을 point2(색깔있는 포인트 지옴)으로 언제든지 바꿔치기 가능!\n\nfig+point2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732661565)>\n\n\n- 명령어로 한번에 그리기\n\nggplot(data=mpg) + \\\ngeom_point(mapping=aes(x='displ',y='hwy',color='class')) + \\\ngeom_smooth(mapping=aes(x='displ',y='hwy'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732727485)>\n\n\n- 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함)\n\nggplot(data=mpg,mapping=aes(x='displ',y='hwy')) + \\\ngeom_point(mapping=aes(color='class')) + \\\ngeom_smooth()\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733489953)>\n\n\n- R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다.\n\n%%R -w 800\nggplot(data=mpg,mapping=aes(x=displ,y=hwy)) + geom_point(mapping=aes(color=class)) + geom_smooth()\n\nR[write to console]: `geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-점크기변경-색깔",
    "href": "posts/2022-10-06-5wk-2.html#산점도-점크기변경-색깔",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔",
    "text": "산점도 + 점크기변경 + 색깔\n- drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다.\n\nggplot(data=mpg, mapping=aes(x='displ',y='hwy')) + geom_point(mapping=aes(size='class',color='drv'),alpha=0.3)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731152845)>\n\n\n\n모든 \\(x\\)에 대하여 붉은색 점들이 대부분 초록색과 보라색 점들에 비하여 아래쪽에 있음 \\(\\to\\) 4륜구동방식이 연비가 좋지 않음"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-객체지향버전",
    "href": "posts/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-객체지향버전",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 (객체지향버전)",
    "text": "산점도 + 점크기변경 + 색깔 (객체지향버전)\n- 맵핑규칙\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\na3 = a2.copy() \n\n\na3['color'] = 'drv'\na3['size'] = 'class'\na3\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'}\n\n\n\n아래와 같이 선언해도 괜찮음\n\na3= aes(x='displ',y='hwy',color='drv',size='class')\n\npoint3=geom_point(a3)\n\n\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731065581)>\n\n\n\n그림의 전체적인 투명도를 조절하면 좋겠음\n\n\npoint3=geom_point(a3,alpha=0.2)\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726730819657)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-선추가",
    "href": "posts/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-선추가",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 + 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + 선추가\n\nfig+point3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726730575253)>"
  },
  {
    "objectID": "posts/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-drv별로-선추가",
    "href": "posts/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-drv별로-선추가",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 + drv별로 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + drv별로 선추가\n- 맵핑규칙\n\na1,a2,a3\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'})\n\n\n\na4 = a2.copy() \na4['color']='drv'\na4\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv'}\n\n\n\nline2 = geom_smooth(a4)\n\n\nfig + point3 +line2\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726729919385)>\n\n\n- 선의 색깔을 동일하게 하고 선의 타입을 변경하여 drv를 표시하고 싶다면?\n\na1,a2,a3,a4\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv'})\n\n\n\na5=a1.copy()\na5['linetype']='drv' \na5\n\n{'x': 'displ', 'y': 'hwy', 'linetype': 'drv'}\n\n\n\nline3 = geom_smooth(a5,size=0.5,color='gray')\n\n\nfig+point3+line3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732637457)>\n\n\n- 전체적인 추세선도 추가하고 싶다면?\n\nfig+point3+line3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732939513)>\n\n\n- 그려보니까 역시 drv별로 그려지는 추세선은 색깔별로 구분하는게 좋겠음.\n\nline2 = geom_smooth(a4,size=0.5,linetype='dashed')\nfig+point3+line2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733678229)>\n\n\n- 고차원을 변수를 표현할 수 있는 무기는 다양하다.\n\n산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도\n라인플랏(스무스지옴,라인지옴): 선의형태, 선의색깔, 선의굵기"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html",
    "href": "posts/2022-10-24-8wk-12.html",
    "title": "08wk-1,2",
    "section": "",
    "text": "판다스– 새로운 열의 할당(2), 자료분석–FIFA23 데이터분석, 판다스– Groupby"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#모티브",
    "href": "posts/2022-10-24-8wk-12.html#모티브",
    "title": "08wk-1,2",
    "section": "모티브",
    "text": "모티브\n- 원본데이터를 가급적 손상시키지 않으면서 데이터를 변형하고 싶음.\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n복사본 생성\n\ndf2 = df \ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n\ndf2['C'] = (df2.A+ df2.B)/2\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n    \n  \n\n\n\n\n\ndf2['D']= (df2.C - np.mean(df2.C))/np.std(df2.C) \ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\ndf # 니가 왜 거기서 나와??\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#해결책1-df.copy이용-.eval이용",
    "href": "posts/2022-10-24-8wk-12.html#해결책1-df.copy이용-.eval이용",
    "title": "08wk-1,2",
    "section": "해결책1: df.copy()이용, .eval()이용",
    "text": "해결책1: df.copy()이용, .eval()이용\n- 올바른코드1\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf2 = df.copy() \ndf2['C'] = (df2.A+ df2.B)/2\ndf2['D']= (df2.C - np.mean(df2.C))/np.std(df2.C) \n\n\ndf2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      0\n      1\n    \n    \n      1\n      1\n      2\n    \n    \n      2\n      2\n      3\n    \n    \n      3\n      3\n      4\n    \n    \n      4\n      4\n      5\n    \n  \n\n\n\n\n- 올바른코드2\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\nmean = np.mean \nstd = np.std \ndf.eval('C=(A+B)/2').eval('D=(C-@mean(C))/@std(C)')\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\n어디까지 eval expression 안에서 지원되는지 명확하지 않고\n외부에 함수를 선언하고 eval expression 안에 @를 붙이는게 좀 귀찮음\n\n- 올바른코드3 (assign) –> 실패\n\ndf = pd.DataFrame({'A':range(0,5),'B':range(1,6)})\ndf.assign(C= (df.A+df.B)/2) \n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n    \n  \n\n\n\n\n\ndf.assign(C= (df.A+df.B)/2).assign(D= (df.C- np.mean(df.C))/np.std(df.C))\n\nAttributeError: 'DataFrame' object has no attribute 'C'\n\n\n아래와 같이 고쳐야함\n\n_df = df.assign(C= (df.A+df.B)/2)\n_df.assign(D= (_df.C- np.mean(_df.C))/np.std(_df.C))\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n\n이건 우리의 철학이랑 안맞음.."
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#해결책2-assign을-이용한-연쇄할당",
    "href": "posts/2022-10-24-8wk-12.html#해결책2-assign을-이용한-연쇄할당",
    "title": "08wk-1,2",
    "section": "해결책2: assign을 이용한 연쇄할당",
    "text": "해결책2: assign을 이용한 연쇄할당\n실패한코드는 아래와 같다.\n\ndf.assign(C= (df.A+df.B)/2).assign(D= (df.C- np.mean(df.C))/np.std(df.C))\n\nAttributeError: 'DataFrame' object has no attribute 'C'\n\n\n두번째 assign에서 표현된 df.C 에서, df가 current df (= df.assign(C= (df.A+df.B)/2) 까지 연산된 상태) 를 의미하도록 만들고 싶다. \\(\\to\\) 아래와 같이 lambda df: 를 추가하면 된다.\n\ndf.assign(C= (df.A+df.B)/2).assign(D= lambda df: (df.C- np.mean(df.C))/np.std(df.C))\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      -1.414214\n    \n    \n      1\n      1\n      2\n      1.5\n      -0.707107\n    \n    \n      2\n      2\n      3\n      2.5\n      0.000000\n    \n    \n      3\n      3\n      4\n      3.5\n      0.707107\n    \n    \n      4\n      4\n      5\n      4.5\n      1.414214\n    \n  \n\n\n\n\n- 연쇄할당\n\ndf.assign(C = (df.A+df.B)/2).assign(D = lambda df: df.C +2).assign(E = lambda df: df.D - 2)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      0\n      1\n      0.5\n      2.5\n      0.5\n    \n    \n      1\n      1\n      2\n      1.5\n      3.5\n      1.5\n    \n    \n      2\n      2\n      3\n      2.5\n      4.5\n      2.5\n    \n    \n      3\n      3\n      4\n      3.5\n      5.5\n      3.5\n    \n    \n      4\n      4\n      5\n      4.5\n      6.5\n      4.5"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#fifa23-data",
    "href": "posts/2022-10-24-8wk-12.html#fifa23-data",
    "title": "08wk-1,2",
    "section": "FIFA23 data",
    "text": "FIFA23 data\n- FIFA23라는 축구게임이 있음\n- 게임에 실제 선수들이 나오면서 선수들의 능력치가 세밀하게 구현되어 있음\n- 선수들 능력치에 대한 데이터셋은 캐글에 공개되어 있음 - https://www.kaggle.com/datasets/bryanb/fifa-player-stats-database?select=FIFA23_official_data.csv"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#데이터살펴보기",
    "href": "posts/2022-10-24-8wk-12.html#데이터살펴보기",
    "title": "08wk-1,2",
    "section": "데이터살펴보기",
    "text": "데이터살펴보기\n- 일단 살펴보기\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n    \n  \n\n5 rows × 29 columns\n\n\n\n트랜스포즈하여 보는 것이 편할때도 있음\n\ndf.T\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      ...\n      17650\n      17651\n      17652\n      17653\n      17654\n      17655\n      17656\n      17657\n      17658\n      17659\n    \n  \n  \n    \n      ID\n      209658\n      212198\n      224334\n      192985\n      224232\n      212622\n      197445\n      187961\n      208333\n      210514\n      ...\n      256879\n      269546\n      267647\n      253186\n      267461\n      269526\n      267946\n      270567\n      256624\n      256376\n    \n    \n      Name\n      L. Goretzka\n      Bruno Fernandes\n      M. Acuña\n      K. De Bruyne\n      N. Barella\n      J. Kimmich\n      D. Alaba\n      22 Paulinho\n      E. Can\n      João Cancelo\n      ...\n      22 G. Leijon\n      Wu Fei\n      22 E. Grosz\n      22 S. Booth\n      22 L. Grimpe\n      Deng Xiongtao\n      22 Lim Jun Sub\n      A. Demir\n      21 S. Czajor\n      21 F. Jakobsson\n    \n    \n      Age\n      27\n      27\n      30\n      31\n      25\n      27\n      30\n      32\n      28\n      28\n      ...\n      19\n      32\n      18\n      20\n      17\n      19\n      17\n      25\n      18\n      20\n    \n    \n      Photo\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      https://cdn.sofifa.net/players/212/622/23_60.png\n      https://cdn.sofifa.net/players/197/445/23_60.png\n      https://cdn.sofifa.net/players/187/961/22_60.png\n      https://cdn.sofifa.net/players/208/333/23_60.png\n      https://cdn.sofifa.net/players/210/514/23_60.png\n      ...\n      https://cdn.sofifa.net/players/256/879/22_60.png\n      https://cdn.sofifa.net/players/269/546/23_60.png\n      https://cdn.sofifa.net/players/267/647/22_60.png\n      https://cdn.sofifa.net/players/253/186/22_60.png\n      https://cdn.sofifa.net/players/267/461/22_60.png\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      https://cdn.sofifa.net/players/256/376/21_60.png\n    \n    \n      Nationality\n      Germany\n      Portugal\n      Argentina\n      Belgium\n      Italy\n      Germany\n      Austria\n      Brazil\n      Germany\n      Portugal\n      ...\n      Sweden\n      China PR\n      Romania\n      England\n      Germany\n      China PR\n      Korea Republic\n      Turkey\n      Poland\n      Sweden\n    \n    \n      Flag\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/pt.png\n      https://cdn.sofifa.net/flags/ar.png\n      https://cdn.sofifa.net/flags/be.png\n      https://cdn.sofifa.net/flags/it.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/at.png\n      https://cdn.sofifa.net/flags/br.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/pt.png\n      ...\n      https://cdn.sofifa.net/flags/se.png\n      https://cdn.sofifa.net/flags/cn.png\n      https://cdn.sofifa.net/flags/ro.png\n      https://cdn.sofifa.net/flags/gb-eng.png\n      https://cdn.sofifa.net/flags/de.png\n      https://cdn.sofifa.net/flags/cn.png\n      https://cdn.sofifa.net/flags/kr.png\n      https://cdn.sofifa.net/flags/tr.png\n      https://cdn.sofifa.net/flags/pl.png\n      https://cdn.sofifa.net/flags/se.png\n    \n    \n      Overall\n      87\n      86\n      85\n      91\n      86\n      89\n      86\n      83\n      82\n      88\n      ...\n      52\n      51\n      52\n      51\n      54\n      48\n      48\n      51\n      50\n      50\n    \n    \n      Potential\n      88\n      87\n      85\n      91\n      89\n      90\n      86\n      83\n      82\n      88\n      ...\n      62\n      51\n      70\n      60\n      68\n      61\n      64\n      56\n      65\n      61\n    \n    \n      Club\n      FC Bayern München\n      Manchester United\n      Sevilla FC\n      Manchester City\n      Inter\n      FC Bayern München\n      Real Madrid CF\n      Al Ahli\n      Borussia Dortmund\n      Manchester City\n      ...\n      Örebro SK\n      Wuhan Three Towns\n      Gaz Metan Mediaş\n      Crewe Alexandra\n      RB Leipzig\n      Meizhou Hakka\n      Jeju United FC\n      Ümraniyespor\n      Fleetwood Town\n      IFK Norrköping\n    \n    \n      Club Logo\n      https://cdn.sofifa.net/teams/21/30.png\n      https://cdn.sofifa.net/teams/11/30.png\n      https://cdn.sofifa.net/teams/481/30.png\n      https://cdn.sofifa.net/teams/10/30.png\n      https://cdn.sofifa.net/teams/44/30.png\n      https://cdn.sofifa.net/teams/21/30.png\n      https://cdn.sofifa.net/teams/243/30.png\n      https://cdn.sofifa.net/teams/112387/30.png\n      https://cdn.sofifa.net/teams/22/30.png\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      https://cdn.sofifa.net/teams/705/30.png\n      https://cdn.sofifa.net/teams/116361/30.png\n      https://cdn.sofifa.net/teams/112637/30.png\n      https://cdn.sofifa.net/teams/121/30.png\n      https://cdn.sofifa.net/teams/112172/30.png\n      https://cdn.sofifa.net/teams/114628/30.png\n      https://cdn.sofifa.net/teams/1478/30.png\n      https://cdn.sofifa.net/teams/113796/30.png\n      https://cdn.sofifa.net/teams/112260/30.png\n      https://cdn.sofifa.net/teams/702/30.png\n    \n    \n      Value\n      €91M\n      €78.5M\n      €46.5M\n      €107.5M\n      €89.5M\n      €105.5M\n      €55.5M\n      €28.5M\n      €30.5M\n      €82.5M\n      ...\n      €150K\n      €30K\n      €180K\n      €110K\n      €210K\n      €100K\n      €100K\n      €70K\n      €90K\n      €90K\n    \n    \n      Wage\n      €115K\n      €190K\n      €46K\n      €350K\n      €110K\n      €130K\n      €220K\n      €61K\n      €63K\n      €250K\n      ...\n      €500\n      €2K\n      €500\n      €850\n      €500\n      €500\n      €500\n      €2K\n      €500\n      €500\n    \n    \n      Special\n      2312\n      2305\n      2303\n      2303\n      2296\n      2283\n      2277\n      2273\n      2271\n      2262\n      ...\n      779\n      777\n      775\n      768\n      767\n      762\n      761\n      759\n      758\n      749\n    \n    \n      Preferred Foot\n      Right\n      Right\n      Left\n      Right\n      Right\n      Right\n      Left\n      Right\n      Right\n      Right\n      ...\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Right\n      Left\n    \n    \n      International Reputation\n      4.0\n      3.0\n      2.0\n      4.0\n      3.0\n      4.0\n      4.0\n      3.0\n      3.0\n      3.0\n      ...\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n    \n    \n      Weak Foot\n      4.0\n      3.0\n      3.0\n      5.0\n      3.0\n      4.0\n      4.0\n      4.0\n      4.0\n      4.0\n      ...\n      3.0\n      2.0\n      2.0\n      2.0\n      3.0\n      3.0\n      2.0\n      2.0\n      2.0\n      2.0\n    \n    \n      Skill Moves\n      3.0\n      4.0\n      3.0\n      4.0\n      3.0\n      3.0\n      3.0\n      4.0\n      3.0\n      4.0\n      ...\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n      1.0\n    \n    \n      Work Rate\n      High/ Medium\n      High/ High\n      High/ High\n      High/ High\n      High/ High\n      High/ Medium\n      Medium/ Medium\n      High/ High\n      Medium/ High\n      High/ Medium\n      ...\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n      Medium/ Medium\n    \n    \n      Body Type\n      Unique\n      Unique\n      Stocky (170-185)\n      Unique\n      Normal (170-)\n      Normal (170-185)\n      Normal (170-185)\n      Normal (170-185)\n      Stocky (185+)\n      Unique\n      ...\n      Normal (185+)\n      Normal (185+)\n      Lean (185+)\n      Lean (185+)\n      Lean (185+)\n      Normal (185+)\n      Lean (185+)\n      Lean (185+)\n      Normal (185+)\n      Normal (185+)\n    \n    \n      Real Face\n      Yes\n      Yes\n      No\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      Yes\n      ...\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n      No\n    \n    \n      Position\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos15\">LCM\n      <span class=\"pos pos7\">LB\n      <span class=\"pos pos13\">RCM\n      <span class=\"pos pos13\">RCM\n      <span class=\"pos pos9\">RDM\n      <span class=\"pos pos6\">LCB\n      <span class=\"pos pos15\">LCM\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos7\">LB\n      ...\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos28\">SUB\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n      <span class=\"pos pos29\">RES\n    \n    \n      Joined\n      Jul 1, 2018\n      Jan 30, 2020\n      Sep 14, 2020\n      Aug 30, 2015\n      Sep 1, 2020\n      Jul 1, 2015\n      Jul 1, 2021\n      Jul 22, 2021\n      Feb 18, 2020\n      Aug 7, 2019\n      ...\n      Jun 14, 2020\n      Feb 15, 2019\n      Jul 1, 2020\n      Jul 1, 2019\n      Feb 7, 2022\n      Apr 11, 2022\n      Jan 1, 2022\n      Jun 6, 2021\n      Jan 1, 2020\n      Jan 8, 2020\n    \n    \n      Loaned From\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      Contract Valid Until\n      2026\n      2026\n      2024\n      2025\n      2026\n      2025\n      2026\n      2024\n      2024\n      2027\n      ...\n      2022\n      2022\n      2022\n      2022\n      2023\n      2027\n      2026\n      2023\n      2021\n      2021\n    \n    \n      Height\n      189cm\n      179cm\n      172cm\n      181cm\n      172cm\n      177cm\n      180cm\n      183cm\n      186cm\n      182cm\n      ...\n      188cm\n      186cm\n      190cm\n      195cm\n      186cm\n      190cm\n      195cm\n      190cm\n      187cm\n      186cm\n    \n    \n      Weight\n      82kg\n      69kg\n      69kg\n      70kg\n      68kg\n      75kg\n      78kg\n      80kg\n      86kg\n      74kg\n      ...\n      81kg\n      78kg\n      70kg\n      80kg\n      78kg\n      78kg\n      84kg\n      82kg\n      79kg\n      78kg\n    \n    \n      Release Clause\n      €157M\n      €155M\n      €97.7M\n      €198.9M\n      €154.4M\n      €182M\n      €113.8M\n      €48.5M\n      €51.9M\n      €152.6M\n      ...\n      €218K\n      €47K\n      €356K\n      €215K\n      €488K\n      €218K\n      €188K\n      €142K\n      €214K\n      €131K\n    \n    \n      Kit Number\n      8.0\n      8.0\n      19.0\n      17.0\n      23.0\n      6.0\n      4.0\n      15.0\n      23.0\n      7.0\n      ...\n      33.0\n      1.0\n      99.0\n      27.0\n      43.0\n      35.0\n      21.0\n      12.0\n      40.0\n      30.0\n    \n    \n      Best Overall Rating\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n29 rows × 17660 columns\n\n\n\n- column이름조사\n\ndf.keys()\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Joined', 'Loaned From', 'Contract Valid Until', 'Height', 'Weight',\n       'Release Clause', 'Kit Number', 'Best Overall Rating'],\n      dtype='object')\n\n\n\n이름에 space가 있어서 좀 거슬림\n\n- 각 column 별로 자료형조사\n\npd.DataFrame({'colname':df.keys(), 'dtype':[df[key].dtype for key in df.keys()]})\n\n\n\n\n\n  \n    \n      \n      colname\n      dtype\n    \n  \n  \n    \n      0\n      ID\n      int64\n    \n    \n      1\n      Name\n      object\n    \n    \n      2\n      Age\n      int64\n    \n    \n      3\n      Photo\n      object\n    \n    \n      4\n      Nationality\n      object\n    \n    \n      5\n      Flag\n      object\n    \n    \n      6\n      Overall\n      int64\n    \n    \n      7\n      Potential\n      int64\n    \n    \n      8\n      Club\n      object\n    \n    \n      9\n      Club Logo\n      object\n    \n    \n      10\n      Value\n      object\n    \n    \n      11\n      Wage\n      object\n    \n    \n      12\n      Special\n      int64\n    \n    \n      13\n      Preferred Foot\n      object\n    \n    \n      14\n      International Reputation\n      float64\n    \n    \n      15\n      Weak Foot\n      float64\n    \n    \n      16\n      Skill Moves\n      float64\n    \n    \n      17\n      Work Rate\n      object\n    \n    \n      18\n      Body Type\n      object\n    \n    \n      19\n      Real Face\n      object\n    \n    \n      20\n      Position\n      object\n    \n    \n      21\n      Joined\n      object\n    \n    \n      22\n      Loaned From\n      object\n    \n    \n      23\n      Contract Valid Until\n      object\n    \n    \n      24\n      Height\n      object\n    \n    \n      25\n      Weight\n      object\n    \n    \n      26\n      Release Clause\n      object\n    \n    \n      27\n      Kit Number\n      float64\n    \n    \n      28\n      Best Overall Rating\n      object\n    \n  \n\n\n\n\n- 결측치조사\n\npd.DataFrame({'colname':df.keys(), \n              'dtype':[df[key].dtype for key in df.keys()],\n              'na':[df[key].isna().sum() for key in df.keys()]\n             })\n\n\n\n\n\n  \n    \n      \n      colname\n      dtype\n      na\n    \n  \n  \n    \n      0\n      ID\n      int64\n      0\n    \n    \n      1\n      Name\n      object\n      0\n    \n    \n      2\n      Age\n      int64\n      0\n    \n    \n      3\n      Photo\n      object\n      0\n    \n    \n      4\n      Nationality\n      object\n      0\n    \n    \n      5\n      Flag\n      object\n      0\n    \n    \n      6\n      Overall\n      int64\n      0\n    \n    \n      7\n      Potential\n      int64\n      0\n    \n    \n      8\n      Club\n      object\n      211\n    \n    \n      9\n      Club Logo\n      object\n      0\n    \n    \n      10\n      Value\n      object\n      0\n    \n    \n      11\n      Wage\n      object\n      0\n    \n    \n      12\n      Special\n      int64\n      0\n    \n    \n      13\n      Preferred Foot\n      object\n      0\n    \n    \n      14\n      International Reputation\n      float64\n      0\n    \n    \n      15\n      Weak Foot\n      float64\n      0\n    \n    \n      16\n      Skill Moves\n      float64\n      0\n    \n    \n      17\n      Work Rate\n      object\n      0\n    \n    \n      18\n      Body Type\n      object\n      38\n    \n    \n      19\n      Real Face\n      object\n      38\n    \n    \n      20\n      Position\n      object\n      35\n    \n    \n      21\n      Joined\n      object\n      1098\n    \n    \n      22\n      Loaned From\n      object\n      16966\n    \n    \n      23\n      Contract Valid Until\n      object\n      361\n    \n    \n      24\n      Height\n      object\n      0\n    \n    \n      25\n      Weight\n      object\n      0\n    \n    \n      26\n      Release Clause\n      object\n      1151\n    \n    \n      27\n      Kit Number\n      float64\n      35\n    \n    \n      28\n      Best Overall Rating\n      object\n      17639\n    \n  \n\n\n\n\n(퀴즈) 열의선택: 결측치가 10000개 이상인 열을 보고싶다면?\n\ndf.loc[:,[df[key].isna().sum()>10000 for key in df.keys()]]\n\n\n\n\n\n  \n    \n      \n      Loaned From\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      NaN\n      NaN\n    \n    \n      1\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      NaN\n    \n    \n      4\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      17655\n      NaN\n      NaN\n    \n    \n      17656\n      NaN\n      NaN\n    \n    \n      17657\n      NaN\n      NaN\n    \n    \n      17658\n      NaN\n      NaN\n    \n    \n      17659\n      NaN\n      NaN\n    \n  \n\n17660 rows × 2 columns\n\n\n\n- .info()\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17660 entries, 0 to 17659\nData columns (total 29 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        17660 non-null  int64  \n 1   Name                      17660 non-null  object \n 2   Age                       17660 non-null  int64  \n 3   Photo                     17660 non-null  object \n 4   Nationality               17660 non-null  object \n 5   Flag                      17660 non-null  object \n 6   Overall                   17660 non-null  int64  \n 7   Potential                 17660 non-null  int64  \n 8   Club                      17449 non-null  object \n 9   Club Logo                 17660 non-null  object \n 10  Value                     17660 non-null  object \n 11  Wage                      17660 non-null  object \n 12  Special                   17660 non-null  int64  \n 13  Preferred Foot            17660 non-null  object \n 14  International Reputation  17660 non-null  float64\n 15  Weak Foot                 17660 non-null  float64\n 16  Skill Moves               17660 non-null  float64\n 17  Work Rate                 17660 non-null  object \n 18  Body Type                 17622 non-null  object \n 19  Real Face                 17622 non-null  object \n 20  Position                  17625 non-null  object \n 21  Joined                    16562 non-null  object \n 22  Loaned From               694 non-null    object \n 23  Contract Valid Until      17299 non-null  object \n 24  Height                    17660 non-null  object \n 25  Weight                    17660 non-null  object \n 26  Release Clause            16509 non-null  object \n 27  Kit Number                17625 non-null  float64\n 28  Best Overall Rating       21 non-null     object \ndtypes: float64(4), int64(5), object(20)\nmemory usage: 3.9+ MB\n\n\n- .describe(): 숫자들이 저장된 column에 대하여 기본통계량 조사\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      ID\n      Age\n      Overall\n      Potential\n      Special\n      International Reputation\n      Weak Foot\n      Skill Moves\n      Kit Number\n    \n  \n  \n    \n      count\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17660.000000\n      17625.000000\n    \n    \n      mean\n      246319.424462\n      23.127746\n      63.369592\n      70.981200\n      1537.915855\n      1.106285\n      2.900340\n      2.297169\n      25.037957\n    \n    \n      std\n      31487.892861\n      4.639821\n      8.036268\n      6.529836\n      285.893809\n      0.407021\n      0.663523\n      0.754264\n      19.154116\n    \n    \n      min\n      16.000000\n      15.000000\n      43.000000\n      42.000000\n      749.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000\n    \n    \n      25%\n      240732.500000\n      20.000000\n      58.000000\n      67.000000\n      1387.000000\n      1.000000\n      3.000000\n      2.000000\n      11.000000\n    \n    \n      50%\n      257041.000000\n      22.000000\n      63.000000\n      71.000000\n      1548.000000\n      1.000000\n      3.000000\n      2.000000\n      22.000000\n    \n    \n      75%\n      263027.500000\n      26.000000\n      69.000000\n      75.000000\n      1727.000000\n      1.000000\n      3.000000\n      3.000000\n      32.000000\n    \n    \n      max\n      271340.000000\n      54.000000\n      91.000000\n      95.000000\n      2312.000000\n      5.000000\n      5.000000\n      5.000000\n      99.000000\n    \n  \n\n\n\n\n- pandas_profiling.ProfileReport()을 이용한 전체적인 조사\n\n# pandas_profiling.ProfileReport(df).to_file('fifa2023_reprot.html')\n\n- 특정열을 중심으로 정렬하여 보기\n\ndf.sort_values(by='Overall',ascending=False).reset_index()\n\n\n\n\n\n  \n    \n      \n      index\n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      41\n      188545\n      R. Lewandowski\n      33\n      https://cdn.sofifa.net/players/188/545/23_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      91\n      91\n      FC Barcelona\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 18, 2022\n      NaN\n      2025\n      185cm\n      81kg\n      €172.2M\n      9.0\n      NaN\n    \n    \n      1\n      124\n      165153\n      K. Benzema\n      34\n      https://cdn.sofifa.net/players/165/153/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      91\n      Real Madrid CF\n      ...\n      Yes\n      <span class=\"pos pos21\">CF\n      Jul 9, 2009\n      NaN\n      2023\n      185cm\n      81kg\n      €131.2M\n      9.0\n      NaN\n    \n    \n      2\n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      3\n      56\n      158023\n      L. Messi\n      35\n      https://cdn.sofifa.net/players/158/023/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      91\n      91\n      Paris Saint-Germain\n      ...\n      Yes\n      <span class=\"pos pos23\">RW\n      Aug 10, 2021\n      NaN\n      2023\n      169cm\n      67kg\n      €99.9M\n      30.0\n      NaN\n    \n    \n      4\n      75\n      231747\n      K. Mbappé\n      23\n      https://cdn.sofifa.net/players/231/747/23_60.png\n      France\n      https://cdn.sofifa.net/flags/fr.png\n      91\n      95\n      Paris Saint-Germain\n      ...\n      Yes\n      <span class=\"pos pos25\">ST\n      Jul 1, 2018\n      NaN\n      2025\n      182cm\n      73kg\n      €366.7M\n      7.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      15513\n      266751\n      22 Jung Ho Yeon\n      20\n      https://cdn.sofifa.net/players/266/751/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      45\n      53\n      GwangJu FC\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 20, 2022\n      NaN\n      2026\n      180cm\n      73kg\n      €145K\n      23.0\n      NaN\n    \n    \n      17656\n      16215\n      268279\n      22 J. Looschen\n      24\n      https://cdn.sofifa.net/players/268/279/22_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      44\n      47\n      SV Meppen\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Mar 19, 2022\n      NaN\n      2026\n      178cm\n      78kg\n      €92K\n      42.0\n      NaN\n    \n    \n      17657\n      16042\n      255283\n      20 Kim Yeong Geun\n      22\n      https://cdn.sofifa.net/players/255/283/20_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      44\n      49\n      Gyeongnam FC\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 9, 2020\n      NaN\n      2020\n      174cm\n      71kg\n      €53K\n      43.0\n      NaN\n    \n    \n      17658\n      14634\n      269038\n      22 Zhang Wenxuan\n      16\n      https://cdn.sofifa.net/players/269/038/22_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      44\n      59\n      Guangzhou FC\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      May 1, 2022\n      NaN\n      2022\n      175cm\n      70kg\n      €239K\n      29.0\n      NaN\n    \n    \n      17659\n      17618\n      168933\n      07 I. Paskov\n      33\n      https://cdn.sofifa.net/players/168/933/07_60.png\n      Bulgaria\n      https://cdn.sofifa.net/flags/bg.png\n      43\n      42\n      NaN\n      ...\n      NaN\n      <span class=\"pos pos28\">SUB\n      NaN\n      NaN\n      NaN\n      184cm\n      79kg\n      NaN\n      24.0\n      NaN\n    \n  \n\n17660 rows × 30 columns\n\n\n\n- 특정열을 중심으로 그룹화하여 보기 (\\(\\star\\))\n\ndf.Nationality.unique() # 데이터셋에 포함된 나라들 출력\n\narray(['Germany', 'Portugal', 'Argentina', 'Belgium', 'Italy', 'Austria',\n       'Brazil', 'Croatia', 'Serbia', 'Spain', 'Netherlands', 'France',\n       'Colombia', 'England', 'Uruguay', 'Morocco', 'Egypt', 'Algeria',\n       'Ukraine', 'United States', \"Côte d'Ivoire\", 'Poland', 'Chile',\n       'Senegal', 'Central African Republic', 'Denmark', 'Nigeria',\n       'Mexico', 'Turkey', 'Canada', 'Wales', 'Scotland', 'Romania',\n       'Czech Republic', 'Ghana', 'Korea Republic',\n       'Bosnia and Herzegovina', 'Mali', 'Slovakia', 'Armenia', 'Norway',\n       'Switzerland', 'Cameroon', 'Peru', 'Jamaica', 'Zambia', 'Guinea',\n       'Sweden', 'North Macedonia', 'Russia', 'Tunisia', 'Malta',\n       'Angola', 'Republic of Ireland', 'Ecuador', 'Benin', 'Paraguay',\n       'Montenegro', 'Australia', 'Comoros', 'Gabon', 'Iceland',\n       'Slovenia', 'Japan', 'Israel', 'China PR', 'Venezuela', 'Liberia',\n       'Greece', 'Bulgaria', 'Honduras', 'Saudi Arabia', 'Curacao',\n       'Northern Ireland', 'Guinea Bissau', 'Kosovo', 'Hungary',\n       'Finland', 'Costa Rica', 'Albania', 'Congo DR', 'Iran',\n       'Mozambique', 'Suriname', 'Cape Verde Islands', 'Bolivia',\n       'Madagascar', 'New Zealand', 'Burkina Faso', 'Dominican Republic',\n       'Kazakhstan', 'Syria', 'Luxembourg', 'Kenya', 'Zimbabwe', 'Haiti',\n       'Uzbekistan', 'South Africa', 'Cyprus', 'Qatar',\n       'Equatorial Guinea', 'Libya', 'Thailand', 'Togo',\n       'Trinidad and Tobago', 'Liechtenstein', 'Gambia', 'Georgia',\n       'Philippines', 'Burundi', 'United Arab Emirates', 'Grenada',\n       'Iraq', 'Panama', 'Malaysia', 'Moldova', 'Congo', 'India',\n       'Jordan', 'Kuwait', 'Antigua and Barbuda', 'Cuba', 'Vietnam',\n       'Korea DPR', 'Uganda', 'Lithuania', 'Estonia', 'Montserrat',\n       'Sierra Leone', 'Afghanistan', 'New Caledonia', 'Belarus', 'Laos',\n       'Saint Lucia', 'Bhutan', 'Guyana', 'Mauritania', 'Faroe Islands',\n       'Namibia', 'Niger', 'Palestine', 'Sudan', 'Azerbaijan',\n       'Hong Kong', 'Gibraltar', 'Tanzania', 'Latvia', 'Chinese Taipei',\n       'Singapore', 'Lebanon', 'El Salvador', 'Indonesia', 'Guatemala',\n       'Papua New Guinea', 'Puerto Rico', 'Malawi', 'South Sudan',\n       'Ethiopia', 'San Marino', 'Andorra', 'Saint Kitts and Nevis'],\n      dtype=object)\n\n\n\ndf.groupby(by='Nationality')[['Overall']].agg({np.mean,len}).sort_values(('Overall', 'mean'),ascending=False)\n\n\n\n\n\n  \n    \n      \n      Overall\n    \n    \n      \n      mean\n      len\n    \n    \n      Nationality\n      \n      \n    \n  \n  \n    \n      Philippines\n      74.000000\n      1\n    \n    \n      Namibia\n      72.000000\n      1\n    \n    \n      Mozambique\n      72.000000\n      2\n    \n    \n      Kuwait\n      71.000000\n      1\n    \n    \n      Brazil\n      70.556586\n      539\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      San Marino\n      53.000000\n      1\n    \n    \n      China PR\n      52.230769\n      325\n    \n    \n      South Sudan\n      52.000000\n      5\n    \n    \n      India\n      51.994681\n      188\n    \n    \n      Saint Kitts and Nevis\n      51.000000\n      1\n    \n  \n\n161 rows × 2 columns\n\n\n\n\ngroupby는 나중에 다시 설명 합니다."
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#데이터정리하기",
    "href": "posts/2022-10-24-8wk-12.html#데이터정리하기",
    "title": "08wk-1,2",
    "section": "데이터정리하기",
    "text": "데이터정리하기\n- 칼럼이름변경\n\ndf.set_axis(pd.Index(map(lambda x: x.replace(' ','_'), df.columns)), axis=1)\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club_Logo\n      ...\n      Real_Face\n      Position\n      Joined\n      Loaned_From\n      Contract_Valid_Until\n      Height\n      Weight\n      Release_Clause\n      Kit_Number\n      Best_Overall_Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n- 결측치제거\n\ndf.drop(columns=['Loaned From', 'Best Overall Rating']).dropna()\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Work Rate\n      Body Type\n      Real Face\n      Position\n      Joined\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      High/ Medium\n      Unique\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      High/ High\n      Stocky (170-185)\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      High/ High\n      Normal (170-)\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n    \n  \n\n16364 rows × 27 columns\n\n\n\n- Height, Weight의 자료형을 float형으로 수정하기\n\ndf.assign(\n    Height= list(map(lambda x: float(x[:-2]), df.Height)),\n    Weight= list(map(lambda x: float(x[:-2]), df.Weight))\n)\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189.0\n      82.0\n      €157M\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179.0\n      69.0\n      €155M\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172.0\n      69.0\n      €97.7M\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181.0\n      70.0\n      €198.9M\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172.0\n      68.0\n      €154.4M\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190.0\n      78.0\n      €218K\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195.0\n      84.0\n      €188K\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190.0\n      82.0\n      €142K\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187.0\n      79.0\n      €214K\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186.0\n      78.0\n      €131K\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n- Release Clause의 자료형을 float으로 수정하기\n\ndf['Release Clause']\n\n0          €157M\n1          €155M\n2         €97.7M\n3        €198.9M\n4        €154.4M\n          ...   \n17655      €218K\n17656      €188K\n17657      €142K\n17658      €214K\n17659      €131K\nName: Release Clause, Length: 17660, dtype: object\n\n\n\n_f = lambda x: float(x[1:-1])*1000 if x[-1]=='K' else float(x[1:-1])*1000000\n\n\n_f('€157M')\n\n157000000.0\n\n\n\n_f('€131K')\n\n131000.0\n\n\n(시도1–실패)\n\nlist(map(_f,df['Release Clause']))\n\nTypeError: 'float' object is not subscriptable\n\n\n(시도1이 실패한 이유)\n\ndf['Release Clause'].isna().sum() # 이 column에는 1151개의 결측치가 존재\n\n1151\n\n\n(nan에 대한 예비학습)\n\ndf.loc[df['Release Clause'].isna(), 'Release Clause']\n\n18       NaN\n34       NaN\n38       NaN\n49       NaN\n50       NaN\n        ... \n17378    NaN\n17386    NaN\n17535    NaN\n17590    NaN\n17618    NaN\nName: Release Clause, Length: 1151, dtype: object\n\n\n\ndf.loc[18, 'Release Clause']\n\nnan\n\n\n\npd.isna(df.loc[18, 'Release Clause'])\n\nTrue\n\n\n\ntype(df.loc[18, 'Release Clause'])\n\nfloat\n\n\n\ndf.loc[18, 'Release Clause'][-1]\n\nTypeError: 'float' object is not subscriptable\n\n\n(시도2–성공)\n\ndf.rename(columns={'Release Clause':'ReleaseClause'})\\\n.assign(ReleaseClause = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df['Release Clause'])))\\\n.rename(columns={'ReleaseClause':'Release Clause'})\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Real Face\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      157000000.0\n      8.0\n      NaN\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      155000000.0\n      8.0\n      NaN\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      97700000.0\n      19.0\n      NaN\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      198900000.0\n      17.0\n      NaN\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      154400000.0\n      23.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      218000.0\n      35.0\n      NaN\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      188000.0\n      21.0\n      NaN\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      142000.0\n      12.0\n      NaN\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      214000.0\n      40.0\n      NaN\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      131000.0\n      30.0\n      NaN\n    \n  \n\n17660 rows × 29 columns\n\n\n\n(시도3–성공) 그냥 결측치를 제거하고 변형해도 무방..\n\ndf2 = df.drop(columns=['Loaned From', 'Best Overall Rating']).dropna()\ndf2['Release Clause'] = list(map(lambda x: _f(x) if pd.isna(x)==False else x , df2['Release Clause']))\ndf2\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Work Rate\n      Body Type\n      Real Face\n      Position\n      Joined\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      High/ Medium\n      Unique\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      2026\n      189cm\n      82kg\n      157000000.0\n      8.0\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      2026\n      179cm\n      69kg\n      155000000.0\n      8.0\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      High/ High\n      Stocky (170-185)\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      2024\n      172cm\n      69kg\n      97700000.0\n      19.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      2025\n      181cm\n      70kg\n      198900000.0\n      17.0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      High/ High\n      Normal (170-)\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      2026\n      172cm\n      68kg\n      154400000.0\n      23.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      2027\n      190cm\n      78kg\n      218000.0\n      35.0\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      2026\n      195cm\n      84kg\n      188000.0\n      21.0\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      Medium/ Medium\n      Lean (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      2023\n      190cm\n      82kg\n      142000.0\n      12.0\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      2021\n      187cm\n      79kg\n      214000.0\n      40.0\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      Medium/ Medium\n      Normal (185+)\n      No\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      2021\n      186cm\n      78kg\n      131000.0\n      30.0\n    \n  \n\n16364 rows × 27 columns\n\n\n\n\n분석의 편의를 위하여 (1) colnames를 변경하고 (2) 결측치를 제거하고 (3) 몇 가지 전 처리를 추가로 진행한 뒤 df2를 만들어서 분석하는게 좋음"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#데이터분석시각화",
    "href": "posts/2022-10-24-8wk-12.html#데이터분석시각화",
    "title": "08wk-1,2",
    "section": "데이터분석+시각화",
    "text": "데이터분석+시각화\n- Overall vs Potential\n\nggplot(data=df) + geom_point(aes(x='Overall',y='Potential'))\n\n\n\n\n<ggplot: (8772275859669)>\n\n\n\n뭔가 Potential > Overall 인 관계가 성립하는 듯 하다. \\(\\to\\) 우리가 생각하는 포텐셜의 의미는 사실 Potential2 = Potential - Overall 에 더 가깝다. \\(\\to\\) Potential2 = Potential - Overall 인 변수를 새로 만들고 시각화 해보자.\n\n- Potential2 = Potential - Overall 를 계산하여 새로운 열을 추가하자.\n\ndf.eval('Potential2 = Potential - Overall')\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Position\n      Joined\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      NaN\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n      NaN\n      1\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      NaN\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n      NaN\n      1\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      NaN\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n      NaN\n      0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      NaN\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n      NaN\n      0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Apr 11, 2022\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n      13\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 1, 2022\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n      16\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jun 6, 2021\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n      5\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 1, 2020\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n      15\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      <span class=\"pos pos29\">RES\n      Jan 8, 2020\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n      11\n    \n  \n\n17660 rows × 30 columns\n\n\n\n- 수정된 데이터프레임으로 다시 시각화를 하자.\n\nggplot(data=df.eval('Potential2 = Potential - Overall'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.01)\n\n\n\n\n<ggplot: (8772307230189)>\n\n\n- 일부점들이 겹치므로 position = ’jitter’를 사용하여 점들을 흩뿌리자.\n\nggplot(data=df.eval('Potential2 = Potential - Overall'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.05,position='jitter')\n\n\n\n\n<ggplot: (8772275596573)>\n\n\n- 해석 - 해석1: Overall, Potential2는 음의 상관관계가 있다. - 해석2: 0근처에 데이터가 많음 \\(\\to\\) 이미 은퇴한 선수들이 아닐까? - 해석3: Overall의 값이 작을수록 Potential2의 분산이 크다.\n- 은퇴한 선수들은 제외하고 시각화하자.\n\nggplot(data=df.eval('Potential2 = Potential - Overall').query('Potential2 > 1'))\\\n+ geom_point(aes(x='Overall',y='Potential2'),alpha=0.05,position='jitter')\n\n\n\n\n<ggplot: (8772275556513)>\n\n\n- Overall에 따라서 구간을 나누고 그 구간에 대응하는 boxplot을 그리자.\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.Overall.describe()\n\ncount    13644.000000\nmean        61.415347\nstd          7.247821\nmin         44.000000\n25%         56.000000\n50%         61.000000\n75%         66.000000\nmax         91.000000\nName: Overall, dtype: float64\n\n\n\ndef f(x):\n    if x>66: \n        y='66<'\n    elif x>61:\n        y='61~66'\n    elif x>56:\n        y='56~61'\n    else:\n        y='<56' \n    return y\n\n\nggplot(data=df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall))))\\\n    + geom_boxplot(aes(x='Overall_grouped',y='Potential2',color='Overall_grouped'))\n\n\n\n\n<ggplot: (8772275730901)>\n\n\n\nOverall_grouped = “<56” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “<56” 에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “56~61” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “56~61” 에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “61~66” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “61~66” 에 대응하는 박스플랏의 x축위치로 설정\nOverall_grouped = “66<” 에 대응하는 점들을 모두 뽑아서 mean(Overall)를 계산하고 그 값을 Overall_grouped = “66<” 에 대응하는 박스플랏의 x축위치로 설정\n\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.query(\"Overall_grouped == '66<'\").Overall.mean()\n\n71.8127687727423\n\n\n(방법1)\n\ndef g(x):\n    if x=='66<': \n        y= 71.8127687727423\n    elif x=='61~66':\n        y= 63.773918342474104\n    elif x=='56~61':\n        y= 59.155840684309005\n    else:\n        y= 52.87743190661479\n    return y\n\n\ndf.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.assign(Overall_x= lambda df: list(map(g,df.Overall_grouped)))\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n      Overall_grouped\n      Overall_x\n    \n  \n  \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      10\n      228251\n      L. Pellegrini\n      26\n      https://cdn.sofifa.net/players/228/251/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      84\n      87\n      Roma\n      https://cdn.sofifa.net/teams/52/30.png\n      ...\n      NaN\n      2026\n      186cm\n      77kg\n      €97.6M\n      7.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      13\n      225193\n      Merino\n      26\n      https://cdn.sofifa.net/players/225/193/23_60.png\n      Spain\n      https://cdn.sofifa.net/flags/es.png\n      83\n      86\n      Real Sociedad\n      https://cdn.sofifa.net/teams/457/30.png\n      ...\n      NaN\n      2025\n      189cm\n      83kg\n      €102.2M\n      8.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      17\n      228702\n      F. de Jong\n      25\n      https://cdn.sofifa.net/players/228/702/23_60.png\n      Netherlands\n      https://cdn.sofifa.net/flags/nl.png\n      87\n      92\n      FC Barcelona\n      https://cdn.sofifa.net/teams/241/30.png\n      ...\n      NaN\n      2026\n      180cm\n      74kg\n      €247.6M\n      21.0\n      NaN\n      5\n      66<\n      71.812769\n    \n    \n      21\n      231281\n      T. Alexander-Arnold\n      23\n      https://cdn.sofifa.net/players/231/281/23_60.png\n      England\n      https://cdn.sofifa.net/flags/gb-eng.png\n      87\n      90\n      Liverpool\n      https://cdn.sofifa.net/teams/9/30.png\n      ...\n      NaN\n      2025\n      180cm\n      69kg\n      €193.5M\n      66.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n      13\n      <56\n      52.877432\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n      16\n      <56\n      52.877432\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n      5\n      <56\n      52.877432\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n      15\n      <56\n      52.877432\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n      11\n      <56\n      52.877432\n    \n  \n\n13644 rows × 32 columns\n\n\n\n\ndf2= df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\\\n.assign(Overall_x= lambda df: list(map(g,df.Overall_grouped)))\ndf2\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Loaned From\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n      Best Overall Rating\n      Potential2\n      Overall_grouped\n      Overall_x\n    \n  \n  \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      NaN\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      10\n      228251\n      L. Pellegrini\n      26\n      https://cdn.sofifa.net/players/228/251/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      84\n      87\n      Roma\n      https://cdn.sofifa.net/teams/52/30.png\n      ...\n      NaN\n      2026\n      186cm\n      77kg\n      €97.6M\n      7.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      13\n      225193\n      Merino\n      26\n      https://cdn.sofifa.net/players/225/193/23_60.png\n      Spain\n      https://cdn.sofifa.net/flags/es.png\n      83\n      86\n      Real Sociedad\n      https://cdn.sofifa.net/teams/457/30.png\n      ...\n      NaN\n      2025\n      189cm\n      83kg\n      €102.2M\n      8.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      17\n      228702\n      F. de Jong\n      25\n      https://cdn.sofifa.net/players/228/702/23_60.png\n      Netherlands\n      https://cdn.sofifa.net/flags/nl.png\n      87\n      92\n      FC Barcelona\n      https://cdn.sofifa.net/teams/241/30.png\n      ...\n      NaN\n      2026\n      180cm\n      74kg\n      €247.6M\n      21.0\n      NaN\n      5\n      66<\n      71.812769\n    \n    \n      21\n      231281\n      T. Alexander-Arnold\n      23\n      https://cdn.sofifa.net/players/231/281/23_60.png\n      England\n      https://cdn.sofifa.net/flags/gb-eng.png\n      87\n      90\n      Liverpool\n      https://cdn.sofifa.net/teams/9/30.png\n      ...\n      NaN\n      2025\n      180cm\n      69kg\n      €193.5M\n      66.0\n      NaN\n      3\n      66<\n      71.812769\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17655\n      269526\n      Deng Xiongtao\n      19\n      https://cdn.sofifa.net/players/269/526/23_60.png\n      China PR\n      https://cdn.sofifa.net/flags/cn.png\n      48\n      61\n      Meizhou Hakka\n      https://cdn.sofifa.net/teams/114628/30.png\n      ...\n      NaN\n      2027\n      190cm\n      78kg\n      €218K\n      35.0\n      NaN\n      13\n      <56\n      52.877432\n    \n    \n      17656\n      267946\n      22 Lim Jun Sub\n      17\n      https://cdn.sofifa.net/players/267/946/22_60.png\n      Korea Republic\n      https://cdn.sofifa.net/flags/kr.png\n      48\n      64\n      Jeju United FC\n      https://cdn.sofifa.net/teams/1478/30.png\n      ...\n      NaN\n      2026\n      195cm\n      84kg\n      €188K\n      21.0\n      NaN\n      16\n      <56\n      52.877432\n    \n    \n      17657\n      270567\n      A. Demir\n      25\n      https://cdn.sofifa.net/players/270/567/23_60.png\n      Turkey\n      https://cdn.sofifa.net/flags/tr.png\n      51\n      56\n      Ümraniyespor\n      https://cdn.sofifa.net/teams/113796/30.png\n      ...\n      NaN\n      2023\n      190cm\n      82kg\n      €142K\n      12.0\n      NaN\n      5\n      <56\n      52.877432\n    \n    \n      17658\n      256624\n      21 S. Czajor\n      18\n      https://cdn.sofifa.net/players/256/624/21_60.png\n      Poland\n      https://cdn.sofifa.net/flags/pl.png\n      50\n      65\n      Fleetwood Town\n      https://cdn.sofifa.net/teams/112260/30.png\n      ...\n      NaN\n      2021\n      187cm\n      79kg\n      €214K\n      40.0\n      NaN\n      15\n      <56\n      52.877432\n    \n    \n      17659\n      256376\n      21 F. Jakobsson\n      20\n      https://cdn.sofifa.net/players/256/376/21_60.png\n      Sweden\n      https://cdn.sofifa.net/flags/se.png\n      50\n      61\n      IFK Norrköping\n      https://cdn.sofifa.net/teams/702/30.png\n      ...\n      NaN\n      2021\n      186cm\n      78kg\n      €131K\n      30.0\n      NaN\n      11\n      <56\n      52.877432\n    \n  \n\n13644 rows × 32 columns\n\n\n\n\nggplot(data=df2)\\\n+geom_point(aes(x='Overall',y='Potential2',color='Overall_grouped'),position='jitter',alpha=0.05)\\\n+geom_boxplot(aes(x='Overall_x',y='Potential2',color='Overall_grouped'))\n\n\n\n\n<ggplot: (8772275710537)>\n\n\n(방법2)\n\n_df = df.eval('Potential2 = Potential - Overall').query('Potential2 > 1')\\\n.assign(Overall_grouped= lambda df: list(map(f,df.Overall)))\n\n\ndf3=_df.groupby(by=\"Overall_grouped\").agg({'Overall':np.mean}).reset_index()\\\n.rename(columns={'Overall':'Overall_x'}).merge(_df)\n\n\nggplot(data=df3)\\\n+geom_point(aes(x='Overall',y='Potential2',color='Overall_grouped'),position='jitter',alpha=0.05)\\\n+geom_boxplot(aes(x='Overall_x',y='Potential2',color='Overall_grouped'))\n\n\n\n\n<ggplot: (8772275671993)>"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#flights-data",
    "href": "posts/2022-10-24-8wk-12.html#flights-data",
    "title": "08wk-1,2",
    "section": "flights data",
    "text": "flights data\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 58492 entries, 0 to 58491\nData columns (total 14 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   MONTH      58492 non-null  int64  \n 1   DAY        58492 non-null  int64  \n 2   WEEKDAY    58492 non-null  int64  \n 3   AIRLINE    58492 non-null  object \n 4   ORG_AIR    58492 non-null  object \n 5   DEST_AIR   58492 non-null  object \n 6   SCHED_DEP  58492 non-null  int64  \n 7   DEP_DELAY  57659 non-null  float64\n 8   AIR_TIME   57474 non-null  float64\n 9   DIST       58492 non-null  int64  \n 10  SCHED_ARR  58492 non-null  int64  \n 11  ARR_DELAY  57474 non-null  float64\n 12  DIVERTED   58492 non-null  int64  \n 13  CANCELLED  58492 non-null  int64  \ndtypes: float64(3), int64(8), object(3)\nmemory usage: 6.2+ MB"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#get_groups",
    "href": "posts/2022-10-24-8wk-12.html#get_groups",
    "title": "08wk-1,2",
    "section": "get_groups",
    "text": "get_groups\n- groupby - 데이터프레임을 여러개의 서브데이터프레임으로 나누는 기슨 - 단독으로 쓸 이유는 별로 없다. \\(\\to\\) 그룹을 나누고 each 그룹마다 어떠한 “변수”에 “연산”을 하기 위함.\n\ndf.groupby(by=\"AIRLINE\")\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fa7462529d0>\n\n\n\n지금 이것이 항공사별로 데이터프레임이 나누어진 상태임\n\n- 진짜 sub dataframe 으로 나누어져 있는지 확인\n\ngrouped = df.groupby(by=\"AIRLINE\")\ngrouped.groups.keys()\n\ndict_keys(['AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'HA', 'MQ', 'NK', 'OO', 'UA', 'US', 'VX', 'WN'])\n\n\n\ndisplay(grouped.get_group('AS'))\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      38\n      1\n      1\n      4\n      AS\n      PHX\n      SEA\n      1505\n      -2.0\n      155.0\n      1107\n      1702\n      -3.0\n      0\n      0\n    \n    \n      198\n      1\n      2\n      5\n      AS\n      LAX\n      SEA\n      2110\n      5.0\n      145.0\n      954\n      2352\n      8.0\n      0\n      0\n    \n    \n      241\n      1\n      2\n      5\n      AS\n      LAS\n      PDX\n      650\n      -5.0\n      117.0\n      763\n      906\n      -3.0\n      0\n      0\n    \n    \n      277\n      1\n      2\n      5\n      AS\n      ORD\n      ANC\n      935\n      -1.0\n      402.0\n      2846\n      1339\n      -6.0\n      0\n      0\n    \n    \n      397\n      1\n      3\n      6\n      AS\n      LAS\n      SEA\n      1300\n      48.0\n      137.0\n      867\n      1535\n      47.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58305\n      12\n      30\n      3\n      AS\n      LAX\n      SEA\n      1325\n      -2.0\n      134.0\n      954\n      1608\n      -7.0\n      0\n      0\n    \n    \n      58355\n      12\n      31\n      4\n      AS\n      PHX\n      SEA\n      1200\n      -5.0\n      145.0\n      1107\n      1407\n      -24.0\n      0\n      0\n    \n    \n      58404\n      12\n      31\n      4\n      AS\n      SFO\n      SLC\n      2110\n      -2.0\n      80.0\n      599\n      2358\n      -4.0\n      0\n      0\n    \n    \n      58407\n      12\n      31\n      4\n      AS\n      SFO\n      PDX\n      645\n      -2.0\n      81.0\n      550\n      832\n      -3.0\n      0\n      0\n    \n    \n      58428\n      12\n      31\n      4\n      AS\n      LAX\n      SEA\n      1420\n      -8.0\n      127.0\n      954\n      1709\n      -25.0\n      0\n      0\n    \n  \n\n768 rows × 14 columns\n\n\n\n\n#collapse_output\nfor key in grouped.groups.keys():\n    display(grouped.get_group(key))\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      3\n      1\n      1\n      4\n      AA\n      DFW\n      DCA\n      1555\n      7.0\n      126.0\n      1192\n      1935\n      -7.0\n      0\n      0\n    \n    \n      6\n      1\n      1\n      4\n      AA\n      DFW\n      MSY\n      1250\n      84.0\n      64.0\n      447\n      1410\n      83.0\n      0\n      0\n    \n    \n      8\n      1\n      1\n      4\n      AA\n      ORD\n      STL\n      1845\n      -5.0\n      44.0\n      258\n      1950\n      -5.0\n      0\n      0\n    \n    \n      15\n      1\n      1\n      4\n      AA\n      DEN\n      DFW\n      1445\n      -6.0\n      93.0\n      641\n      1745\n      4.0\n      0\n      0\n    \n    \n      26\n      1\n      1\n      4\n      AA\n      LAX\n      AUS\n      1430\n      33.0\n      157.0\n      1242\n      1925\n      41.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58470\n      12\n      31\n      4\n      AA\n      DFW\n      FAT\n      1020\n      -3.0\n      196.0\n      1313\n      1156\n      -2.0\n      0\n      0\n    \n    \n      58475\n      12\n      31\n      4\n      AA\n      IAH\n      CLT\n      710\n      1.0\n      113.0\n      912\n      1037\n      -12.0\n      0\n      0\n    \n    \n      58476\n      12\n      31\n      4\n      AA\n      DFW\n      TPA\n      1020\n      -3.0\n      121.0\n      929\n      1340\n      -6.0\n      0\n      0\n    \n    \n      58479\n      12\n      31\n      4\n      AA\n      DFW\n      ELP\n      1200\n      3.0\n      94.0\n      551\n      1250\n      13.0\n      0\n      0\n    \n    \n      58487\n      12\n      31\n      4\n      AA\n      SFO\n      DFW\n      515\n      5.0\n      166.0\n      1464\n      1045\n      -19.0\n      0\n      0\n    \n  \n\n8900 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      38\n      1\n      1\n      4\n      AS\n      PHX\n      SEA\n      1505\n      -2.0\n      155.0\n      1107\n      1702\n      -3.0\n      0\n      0\n    \n    \n      198\n      1\n      2\n      5\n      AS\n      LAX\n      SEA\n      2110\n      5.0\n      145.0\n      954\n      2352\n      8.0\n      0\n      0\n    \n    \n      241\n      1\n      2\n      5\n      AS\n      LAS\n      PDX\n      650\n      -5.0\n      117.0\n      763\n      906\n      -3.0\n      0\n      0\n    \n    \n      277\n      1\n      2\n      5\n      AS\n      ORD\n      ANC\n      935\n      -1.0\n      402.0\n      2846\n      1339\n      -6.0\n      0\n      0\n    \n    \n      397\n      1\n      3\n      6\n      AS\n      LAS\n      SEA\n      1300\n      48.0\n      137.0\n      867\n      1535\n      47.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58305\n      12\n      30\n      3\n      AS\n      LAX\n      SEA\n      1325\n      -2.0\n      134.0\n      954\n      1608\n      -7.0\n      0\n      0\n    \n    \n      58355\n      12\n      31\n      4\n      AS\n      PHX\n      SEA\n      1200\n      -5.0\n      145.0\n      1107\n      1407\n      -24.0\n      0\n      0\n    \n    \n      58404\n      12\n      31\n      4\n      AS\n      SFO\n      SLC\n      2110\n      -2.0\n      80.0\n      599\n      2358\n      -4.0\n      0\n      0\n    \n    \n      58407\n      12\n      31\n      4\n      AS\n      SFO\n      PDX\n      645\n      -2.0\n      81.0\n      550\n      832\n      -3.0\n      0\n      0\n    \n    \n      58428\n      12\n      31\n      4\n      AS\n      LAX\n      SEA\n      1420\n      -8.0\n      127.0\n      954\n      1709\n      -25.0\n      0\n      0\n    \n  \n\n768 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      123\n      1\n      1\n      4\n      B6\n      LAS\n      BOS\n      1230\n      0.0\n      246.0\n      2381\n      2026\n      -27.0\n      0\n      0\n    \n    \n      127\n      1\n      1\n      4\n      B6\n      LAS\n      BOS\n      2359\n      68.0\n      247.0\n      2381\n      749\n      46.0\n      0\n      0\n    \n    \n      239\n      1\n      2\n      5\n      B6\n      ORD\n      BOS\n      540\n      -8.0\n      96.0\n      867\n      856\n      -22.0\n      0\n      0\n    \n    \n      333\n      1\n      3\n      6\n      B6\n      LAX\n      FLL\n      2237\n      32.0\n      270.0\n      2342\n      619\n      42.0\n      0\n      0\n    \n    \n      548\n      1\n      4\n      7\n      B6\n      SFO\n      FLL\n      2307\n      -4.0\n      298.0\n      2583\n      724\n      -1.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58262\n      12\n      30\n      3\n      B6\n      SFO\n      LGB\n      1921\n      -6.0\n      57.0\n      354\n      2038\n      -14.0\n      0\n      0\n    \n    \n      58301\n      12\n      30\n      3\n      B6\n      LAX\n      JFK\n      630\n      4.0\n      285.0\n      2475\n      1445\n      -6.0\n      0\n      0\n    \n    \n      58425\n      12\n      31\n      4\n      B6\n      ORD\n      SJU\n      700\n      239.0\n      250.0\n      2072\n      1335\n      239.0\n      0\n      0\n    \n    \n      58477\n      12\n      31\n      4\n      B6\n      DFW\n      BOS\n      1145\n      12.0\n      161.0\n      1562\n      1608\n      -14.0\n      0\n      0\n    \n    \n      58483\n      12\n      31\n      4\n      B6\n      PHX\n      BOS\n      2236\n      -12.0\n      231.0\n      2300\n      515\n      -45.0\n      0\n      0\n    \n  \n\n543 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      53\n      1\n      1\n      4\n      DL\n      LAS\n      MSP\n      713\n      -5.0\n      156.0\n      1299\n      1220\n      -18.0\n      0\n      0\n    \n    \n      57\n      1\n      1\n      4\n      DL\n      MSP\n      RSW\n      700\n      -1.0\n      169.0\n      1416\n      1130\n      -20.0\n      0\n      0\n    \n    \n      77\n      1\n      1\n      4\n      DL\n      LAX\n      ATL\n      1130\n      24.0\n      217.0\n      1947\n      1840\n      16.0\n      0\n      0\n    \n    \n      79\n      1\n      1\n      4\n      DL\n      LAX\n      CMH\n      2146\n      -3.0\n      223.0\n      1995\n      459\n      -13.0\n      0\n      0\n    \n    \n      85\n      1\n      1\n      4\n      DL\n      ATL\n      OKC\n      2059\n      -4.0\n      116.0\n      761\n      2227\n      -12.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58440\n      12\n      31\n      4\n      DL\n      ATL\n      CVG\n      1611\n      -4.0\n      61.0\n      373\n      1736\n      -6.0\n      0\n      0\n    \n    \n      58448\n      12\n      31\n      4\n      DL\n      ATL\n      SRQ\n      1610\n      0.0\n      61.0\n      444\n      1740\n      -13.0\n      0\n      0\n    \n    \n      58464\n      12\n      31\n      4\n      DL\n      LAX\n      SFO\n      700\n      108.0\n      54.0\n      337\n      825\n      105.0\n      0\n      0\n    \n    \n      58467\n      12\n      31\n      4\n      DL\n      ATL\n      IND\n      1235\n      -3.0\n      63.0\n      432\n      1407\n      -13.0\n      0\n      0\n    \n    \n      58485\n      12\n      31\n      4\n      DL\n      ATL\n      CMH\n      2206\n      2.0\n      64.0\n      447\n      2338\n      -8.0\n      0\n      0\n    \n  \n\n10601 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      11\n      1\n      1\n      4\n      EV\n      ORD\n      JAN\n      1155\n      6.0\n      113.0\n      677\n      1403\n      5.0\n      0\n      0\n    \n    \n      13\n      1\n      1\n      4\n      EV\n      ORD\n      CMH\n      1010\n      -2.0\n      46.0\n      296\n      1228\n      -9.0\n      0\n      0\n    \n    \n      29\n      1\n      1\n      4\n      EV\n      ORD\n      IND\n      1025\n      -6.0\n      29.0\n      177\n      1228\n      -19.0\n      0\n      0\n    \n    \n      40\n      1\n      1\n      4\n      EV\n      IAH\n      CLE\n      1038\n      -3.0\n      126.0\n      1091\n      1425\n      -18.0\n      0\n      0\n    \n    \n      69\n      1\n      1\n      4\n      EV\n      ATL\n      RAP\n      1930\n      -5.0\n      181.0\n      1230\n      2104\n      -15.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58445\n      12\n      31\n      4\n      EV\n      DFW\n      TXK\n      850\n      -5.0\n      30.0\n      181\n      948\n      -17.0\n      0\n      0\n    \n    \n      58452\n      12\n      31\n      4\n      EV\n      DFW\n      SHV\n      1650\n      -4.0\n      32.0\n      190\n      1746\n      -12.0\n      0\n      0\n    \n    \n      58459\n      12\n      31\n      4\n      EV\n      MSP\n      ORD\n      1435\n      18.0\n      61.0\n      334\n      1609\n      3.0\n      0\n      0\n    \n    \n      58463\n      12\n      31\n      4\n      EV\n      ORD\n      MSN\n      1220\n      18.0\n      32.0\n      108\n      1319\n      27.0\n      0\n      0\n    \n    \n      58486\n      12\n      31\n      4\n      EV\n      DFW\n      LFT\n      850\n      21.0\n      52.0\n      351\n      1012\n      14.0\n      0\n      0\n    \n  \n\n5858 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      7\n      1\n      1\n      4\n      F9\n      SFO\n      PHX\n      1020\n      -7.0\n      91.0\n      651\n      1315\n      -6.0\n      0\n      0\n    \n    \n      93\n      1\n      1\n      4\n      F9\n      ATL\n      DEN\n      859\n      16.0\n      181.0\n      1199\n      1026\n      10.0\n      0\n      0\n    \n    \n      209\n      1\n      2\n      5\n      F9\n      MSP\n      DEN\n      1025\n      -6.0\n      97.0\n      680\n      1134\n      -13.0\n      0\n      0\n    \n    \n      232\n      1\n      2\n      5\n      F9\n      DEN\n      PHX\n      2040\n      -7.0\n      83.0\n      602\n      2228\n      -18.0\n      0\n      0\n    \n    \n      247\n      1\n      2\n      5\n      F9\n      ORD\n      ATL\n      730\n      10.0\n      86.0\n      606\n      1020\n      23.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58288\n      12\n      30\n      3\n      F9\n      DEN\n      ORD\n      625\n      -4.0\n      136.0\n      888\n      1000\n      14.0\n      0\n      0\n    \n    \n      58331\n      12\n      30\n      3\n      F9\n      ORD\n      PHX\n      825\n      18.0\n      207.0\n      1440\n      1127\n      14.0\n      0\n      0\n    \n    \n      58447\n      12\n      31\n      4\n      F9\n      DEN\n      LAS\n      1245\n      13.0\n      94.0\n      628\n      1340\n      13.0\n      0\n      0\n    \n    \n      58449\n      12\n      31\n      4\n      F9\n      DEN\n      MCO\n      645\n      11.0\n      169.0\n      1546\n      1224\n      -11.0\n      0\n      0\n    \n    \n      58488\n      12\n      31\n      4\n      F9\n      LAS\n      SFO\n      1910\n      13.0\n      71.0\n      414\n      2050\n      4.0\n      0\n      0\n    \n  \n\n1317 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      582\n      1\n      4\n      7\n      HA\n      LAX\n      OGG\n      1115\n      -11.0\n      310.0\n      2486\n      1500\n      -27.0\n      0\n      0\n    \n    \n      712\n      1\n      5\n      1\n      HA\n      LAS\n      HNL\n      900\n      -5.0\n      357.0\n      2762\n      1315\n      5.0\n      0\n      0\n    \n    \n      878\n      1\n      6\n      2\n      HA\n      PHX\n      HNL\n      800\n      1.0\n      374.0\n      2917\n      1140\n      3.0\n      0\n      0\n    \n    \n      1053\n      1\n      7\n      3\n      HA\n      LAX\n      HNL\n      1705\n      0.0\n      332.0\n      2556\n      2055\n      -2.0\n      0\n      0\n    \n    \n      1269\n      1\n      8\n      4\n      HA\n      LAX\n      HNL\n      1000\n      -1.0\n      335.0\n      2556\n      1350\n      0.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      55883\n      12\n      16\n      3\n      HA\n      LAX\n      HNL\n      835\n      1.0\n      314.0\n      2556\n      1235\n      -18.0\n      0\n      0\n    \n    \n      56174\n      12\n      18\n      5\n      HA\n      LAX\n      HNL\n      835\n      -5.0\n      342.0\n      2556\n      1235\n      -4.0\n      0\n      0\n    \n    \n      56350\n      12\n      19\n      6\n      HA\n      PHX\n      HNL\n      800\n      -5.0\n      363.0\n      2917\n      1155\n      -34.0\n      0\n      0\n    \n    \n      56816\n      12\n      21\n      1\n      HA\n      LAX\n      LIH\n      740\n      20.0\n      303.0\n      2615\n      1145\n      -11.0\n      0\n      0\n    \n    \n      58391\n      12\n      31\n      4\n      HA\n      LAX\n      HNL\n      1000\n      0.0\n      324.0\n      2556\n      1350\n      -9.0\n      0\n      0\n    \n  \n\n112 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      2\n      1\n      1\n      4\n      MQ\n      DFW\n      VPS\n      1305\n      36.0\n      85.0\n      641\n      1453\n      35.0\n      0\n      0\n    \n    \n      10\n      1\n      1\n      4\n      MQ\n      DFW\n      DRO\n      1335\n      28.0\n      104.0\n      674\n      1438\n      28.0\n      0\n      0\n    \n    \n      18\n      1\n      1\n      4\n      MQ\n      ORD\n      DAY\n      2220\n      19.0\n      37.0\n      240\n      23\n      20.0\n      0\n      0\n    \n    \n      24\n      1\n      1\n      4\n      MQ\n      DFW\n      BTR\n      730\n      NaN\n      NaN\n      383\n      853\n      NaN\n      0\n      1\n    \n    \n      50\n      1\n      1\n      4\n      MQ\n      ORD\n      CID\n      1135\n      -7.0\n      37.0\n      196\n      1238\n      -15.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58415\n      12\n      31\n      4\n      MQ\n      ORD\n      FWA\n      845\n      -2.0\n      37.0\n      157\n      1045\n      -4.0\n      0\n      0\n    \n    \n      58426\n      12\n      31\n      4\n      MQ\n      DFW\n      FAR\n      1154\n      4.0\n      124.0\n      968\n      1437\n      -13.0\n      0\n      0\n    \n    \n      58468\n      12\n      31\n      4\n      MQ\n      DFW\n      OKC\n      1720\n      -3.0\n      31.0\n      175\n      1819\n      -10.0\n      0\n      0\n    \n    \n      58474\n      12\n      31\n      4\n      MQ\n      ORD\n      FNT\n      829\n      4.0\n      40.0\n      223\n      1034\n      -4.0\n      0\n      0\n    \n    \n      58484\n      12\n      31\n      4\n      MQ\n      ORD\n      DSM\n      1333\n      1.0\n      57.0\n      299\n      1455\n      -7.0\n      0\n      0\n    \n  \n\n3471 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      17\n      1\n      1\n      4\n      NK\n      DEN\n      DTW\n      1952\n      37.0\n      124.0\n      1123\n      31\n      54.0\n      0\n      0\n    \n    \n      74\n      1\n      1\n      4\n      NK\n      PHX\n      DFW\n      159\n      -1.0\n      103.0\n      868\n      502\n      1.0\n      0\n      0\n    \n    \n      95\n      1\n      1\n      4\n      NK\n      LAS\n      OAK\n      1115\n      22.0\n      62.0\n      407\n      1246\n      10.0\n      0\n      0\n    \n    \n      109\n      1\n      1\n      4\n      NK\n      MSP\n      ORD\n      616\n      2.0\n      49.0\n      334\n      745\n      -19.0\n      0\n      0\n    \n    \n      166\n      1\n      2\n      5\n      NK\n      LAS\n      PDX\n      1535\n      -8.0\n      123.0\n      763\n      1754\n      -4.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58160\n      12\n      29\n      2\n      NK\n      MSP\n      MCO\n      740\n      0.0\n      171.0\n      1310\n      1158\n      33.0\n      0\n      0\n    \n    \n      58197\n      12\n      30\n      3\n      NK\n      IAH\n      ORD\n      755\n      -8.0\n      136.0\n      925\n      1030\n      -2.0\n      0\n      0\n    \n    \n      58437\n      12\n      31\n      4\n      NK\n      ORD\n      DFW\n      1952\n      15.0\n      135.0\n      802\n      2225\n      23.0\n      0\n      0\n    \n    \n      58461\n      12\n      31\n      4\n      NK\n      ORD\n      LGA\n      1801\n      -5.0\n      84.0\n      733\n      2109\n      -26.0\n      0\n      0\n    \n    \n      58469\n      12\n      31\n      4\n      NK\n      LAS\n      MSY\n      1950\n      124.0\n      163.0\n      1500\n      112\n      101.0\n      0\n      0\n    \n  \n\n1516 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      12\n      1\n      1\n      4\n      OO\n      ORD\n      MSP\n      1510\n      2.0\n      65.0\n      334\n      1646\n      4.0\n      0\n      0\n    \n    \n      16\n      1\n      1\n      4\n      OO\n      DEN\n      SGU\n      1105\n      21.0\n      66.0\n      517\n      1249\n      20.0\n      0\n      0\n    \n    \n      22\n      1\n      1\n      4\n      OO\n      LAS\n      LAX\n      1544\n      -4.0\n      39.0\n      236\n      1655\n      -12.0\n      0\n      0\n    \n    \n      25\n      1\n      1\n      4\n      OO\n      ORD\n      SPI\n      2110\n      -4.0\n      31.0\n      174\n      2205\n      5.0\n      0\n      0\n    \n    \n      27\n      1\n      1\n      4\n      OO\n      IAH\n      JAC\n      1104\n      -1.0\n      161.0\n      1265\n      1316\n      -1.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58451\n      12\n      31\n      4\n      OO\n      ATL\n      FWA\n      1905\n      -3.0\n      72.0\n      508\n      2051\n      -14.0\n      0\n      0\n    \n    \n      58480\n      12\n      31\n      4\n      OO\n      MSP\n      BIS\n      1310\n      -2.0\n      65.0\n      386\n      1449\n      -9.0\n      0\n      0\n    \n    \n      58482\n      12\n      31\n      4\n      OO\n      DEN\n      CPR\n      1850\n      -2.0\n      38.0\n      230\n      1956\n      1.0\n      0\n      0\n    \n    \n      58489\n      12\n      31\n      4\n      OO\n      SFO\n      SBA\n      1846\n      -6.0\n      46.0\n      262\n      1956\n      -5.0\n      0\n      0\n    \n    \n      58491\n      12\n      31\n      4\n      OO\n      SFO\n      BOI\n      859\n      5.0\n      73.0\n      522\n      1146\n      -1.0\n      0\n      0\n    \n  \n\n6588 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      1\n      1\n      1\n      4\n      UA\n      DEN\n      IAD\n      823\n      7.0\n      154.0\n      1452\n      1333\n      -13.0\n      0\n      0\n    \n    \n      5\n      1\n      1\n      4\n      UA\n      IAH\n      SAN\n      1450\n      1.0\n      178.0\n      1303\n      1620\n      -14.0\n      0\n      0\n    \n    \n      9\n      1\n      1\n      4\n      UA\n      IAH\n      SJC\n      925\n      3.0\n      215.0\n      1608\n      1136\n      -14.0\n      0\n      0\n    \n    \n      14\n      1\n      1\n      4\n      UA\n      IAH\n      IND\n      1426\n      -1.0\n      102.0\n      844\n      1742\n      -20.0\n      0\n      0\n    \n    \n      21\n      1\n      1\n      4\n      UA\n      ORD\n      CLE\n      2102\n      48.0\n      47.0\n      315\n      2320\n      41.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58422\n      12\n      31\n      4\n      UA\n      DEN\n      SAN\n      1535\n      0.0\n      124.0\n      853\n      1704\n      -13.0\n      0\n      0\n    \n    \n      58432\n      12\n      31\n      4\n      UA\n      ORD\n      SAN\n      1915\n      7.0\n      238.0\n      1723\n      2143\n      -3.0\n      0\n      0\n    \n    \n      58457\n      12\n      31\n      4\n      UA\n      ORD\n      LAX\n      659\n      -1.0\n      241.0\n      1744\n      946\n      0.0\n      0\n      0\n    \n    \n      58460\n      12\n      31\n      4\n      UA\n      SFO\n      PHL\n      2235\n      -6.0\n      265.0\n      2521\n      700\n      -42.0\n      0\n      0\n    \n    \n      58481\n      12\n      31\n      4\n      UA\n      IAH\n      LAX\n      1433\n      1.0\n      197.0\n      1379\n      1625\n      -13.0\n      0\n      0\n    \n  \n\n7792 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      31\n      1\n      1\n      4\n      US\n      PHX\n      DEN\n      1810\n      29.0\n      94.0\n      602\n      1954\n      49.0\n      0\n      0\n    \n    \n      35\n      1\n      1\n      4\n      US\n      ORD\n      PHL\n      1600\n      -2.0\n      80.0\n      678\n      1857\n      -9.0\n      0\n      0\n    \n    \n      49\n      1\n      1\n      4\n      US\n      IAH\n      PHX\n      1445\n      -1.0\n      147.0\n      1009\n      1638\n      -7.0\n      0\n      0\n    \n    \n      96\n      1\n      1\n      4\n      US\n      ATL\n      PHL\n      1445\n      -4.0\n      90.0\n      666\n      1644\n      -11.0\n      0\n      0\n    \n    \n      104\n      1\n      1\n      4\n      US\n      MSP\n      PHX\n      730\n      -3.0\n      174.0\n      1276\n      1010\n      -20.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      31514\n      6\n      30\n      2\n      US\n      DEN\n      PHL\n      705\n      -4.0\n      188.0\n      1558\n      1240\n      1.0\n      0\n      0\n    \n    \n      31523\n      6\n      30\n      2\n      US\n      PHX\n      DEN\n      1451\n      6.0\n      85.0\n      602\n      1738\n      7.0\n      0\n      0\n    \n    \n      31535\n      6\n      30\n      2\n      US\n      PHX\n      AUS\n      840\n      -3.0\n      116.0\n      872\n      1304\n      -11.0\n      0\n      0\n    \n    \n      31561\n      6\n      30\n      2\n      US\n      ORD\n      PHX\n      710\n      -5.0\n      170.0\n      1440\n      901\n      -50.0\n      0\n      0\n    \n    \n      31582\n      6\n      30\n      2\n      US\n      PHX\n      OGG\n      800\n      -4.0\n      356.0\n      2845\n      1127\n      -13.0\n      0\n      0\n    \n  \n\n1615 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      56\n      1\n      1\n      4\n      VX\n      LAS\n      SFO\n      900\n      23.0\n      65.0\n      414\n      1035\n      11.0\n      0\n      0\n    \n    \n      227\n      1\n      2\n      5\n      VX\n      SFO\n      LAS\n      1220\n      -5.0\n      68.0\n      414\n      1350\n      -5.0\n      0\n      0\n    \n    \n      243\n      1\n      2\n      5\n      VX\n      SFO\n      SEA\n      700\n      -4.0\n      104.0\n      679\n      905\n      -1.0\n      0\n      0\n    \n    \n      417\n      1\n      3\n      6\n      VX\n      SFO\n      LAS\n      900\n      -2.0\n      62.0\n      414\n      1030\n      -11.0\n      0\n      0\n    \n    \n      432\n      1\n      3\n      6\n      VX\n      SFO\n      SEA\n      2035\n      -2.0\n      106.0\n      679\n      2240\n      -2.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58332\n      12\n      30\n      3\n      VX\n      SFO\n      LAS\n      1950\n      -3.0\n      58.0\n      414\n      2120\n      -4.0\n      0\n      0\n    \n    \n      58383\n      12\n      31\n      4\n      VX\n      SFO\n      PSP\n      1630\n      -7.0\n      65.0\n      421\n      1755\n      -12.0\n      0\n      0\n    \n    \n      58400\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      1125\n      -4.0\n      54.0\n      337\n      1245\n      -10.0\n      0\n      0\n    \n    \n      58471\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      700\n      6.0\n      51.0\n      337\n      820\n      3.0\n      0\n      0\n    \n    \n      58478\n      12\n      31\n      4\n      VX\n      SFO\n      LAX\n      1530\n      29.0\n      52.0\n      337\n      1650\n      22.0\n      0\n      0\n    \n  \n\n993 rows × 14 columns\n\n\n\n\n\n\n\n  \n    \n      \n      MONTH\n      DAY\n      WEEKDAY\n      AIRLINE\n      ORG_AIR\n      DEST_AIR\n      SCHED_DEP\n      DEP_DELAY\n      AIR_TIME\n      DIST\n      SCHED_ARR\n      ARR_DELAY\n      DIVERTED\n      CANCELLED\n    \n  \n  \n    \n      0\n      1\n      1\n      4\n      WN\n      LAX\n      SLC\n      1625\n      58.0\n      94.0\n      590\n      1905\n      65.0\n      0\n      0\n    \n    \n      4\n      1\n      1\n      4\n      WN\n      LAX\n      MCI\n      1720\n      48.0\n      166.0\n      1363\n      2225\n      39.0\n      0\n      0\n    \n    \n      19\n      1\n      1\n      4\n      WN\n      PHX\n      LAX\n      1640\n      51.0\n      58.0\n      370\n      1700\n      59.0\n      0\n      0\n    \n    \n      20\n      1\n      1\n      4\n      WN\n      ATL\n      BWI\n      1115\n      1.0\n      76.0\n      577\n      1305\n      -15.0\n      0\n      0\n    \n    \n      23\n      1\n      1\n      4\n      WN\n      ATL\n      HOU\n      1555\n      30.0\n      113.0\n      696\n      1720\n      18.0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      58455\n      12\n      31\n      4\n      WN\n      LAX\n      SMF\n      1420\n      -2.0\n      64.0\n      373\n      1540\n      -7.0\n      0\n      0\n    \n    \n      58458\n      12\n      31\n      4\n      WN\n      LAS\n      SFO\n      1825\n      25.0\n      67.0\n      414\n      1955\n      17.0\n      0\n      0\n    \n    \n      58472\n      12\n      31\n      4\n      WN\n      PHX\n      HOU\n      845\n      5.0\n      119.0\n      1020\n      1210\n      7.0\n      0\n      0\n    \n    \n      58473\n      12\n      31\n      4\n      WN\n      DEN\n      PDX\n      1205\n      4.0\n      130.0\n      991\n      1400\n      -13.0\n      0\n      0\n    \n    \n      58490\n      12\n      31\n      4\n      WN\n      MSP\n      ATL\n      525\n      39.0\n      124.0\n      907\n      855\n      34.0\n      0\n      0\n    \n  \n\n8418 rows × 14 columns"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#범주형변수를-기준으로-groupby---agg",
    "href": "posts/2022-10-24-8wk-12.html#범주형변수를-기준으로-groupby---agg",
    "title": "08wk-1,2",
    "section": "범주형변수를 기준으로 groupby -> agg",
    "text": "범주형변수를 기준으로 groupby -> agg\n\n# EX1: [AIRLINE] \\(\\to\\) {ARR_DELAY:mean}\n- 방법1: grouby() \\(\\to\\) .agg({colname: function})\n(예시1)\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':np.mean})\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      5.542661\n    \n    \n      AS\n      -0.833333\n    \n    \n      B6\n      8.692593\n    \n    \n      DL\n      0.339691\n    \n    \n      EV\n      7.034580\n    \n    \n      F9\n      13.630651\n    \n    \n      HA\n      4.972973\n    \n    \n      MQ\n      6.860591\n    \n    \n      NK\n      18.436070\n    \n    \n      OO\n      7.593463\n    \n    \n      UA\n      7.765755\n    \n    \n      US\n      1.681105\n    \n    \n      VX\n      5.348884\n    \n    \n      WN\n      6.397353\n    \n  \n\n\n\n\n(예시2)\n\ndf.groupby(by=\"AIRLINE\").agg({'ARR_DELAY':'mean'})\n\n\n\n\n\n  \n    \n      \n      ARR_DELAY\n    \n    \n      AIRLINE\n      \n    \n  \n  \n    \n      AA\n      5.542661\n    \n    \n      AS\n      -0.833333\n    \n    \n      B6\n      8.692593\n    \n    \n      DL\n      0.339691\n    \n    \n      EV\n      7.034580\n    \n    \n      F9\n      13.630651\n    \n    \n      HA\n      4.972973\n    \n    \n      MQ\n      6.860591\n    \n    \n      NK\n      18.436070\n    \n    \n      OO\n      7.593463\n    \n    \n      UA\n      7.765755\n    \n    \n      US\n      1.681105\n    \n    \n      VX\n      5.348884\n    \n    \n      WN\n      6.397353\n    \n  \n\n\n\n\n- 방법2: grouby() \\(\\to\\) key로 column선택 \\(\\to\\) .agg(f) or .f()\n(예시1)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].agg(np.mean)\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n(예시2)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].agg(\"mean\")\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n(예시3)\n\ndf.groupby(by='AIRLINE')['ARR_DELAY'].mean()\n\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nF9    13.630651\nHA     4.972973\nMQ     6.860591\nNK    18.436070\nOO     7.593463\nUA     7.765755\nUS     1.681105\nVX     5.348884\nWN     6.397353\nName: ARR_DELAY, dtype: float64\n\n\n\n\n# EX2: [AIRLINE,WEEKDAY] \\(\\to\\) {CANCELLED:sum}\n- 방법1\n(예시1)\n\ndf.groupby(by=[\"AIRLINE\",\"WEEKDAY\"]).agg({\"CANCELLED\":np.sum})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n(예시2)\n\ndf.groupby(by=[\"AIRLINE\",\"WEEKDAY\"]).agg({\"CANCELLED\":\"sum\"})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n- 방법2\n(예시1)\n\ndf.groupby(by=[\"AIRLINE\",\"WEEKDAY\"])[[\"CANCELLED\"]].agg(np.sum)\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n    \n  \n  \n    \n      AA\n      1\n      41\n    \n    \n      2\n      9\n    \n    \n      3\n      16\n    \n    \n      4\n      20\n    \n    \n      5\n      18\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n    \n    \n      4\n      10\n    \n    \n      5\n      7\n    \n    \n      6\n      10\n    \n    \n      7\n      7\n    \n  \n\n98 rows × 1 columns\n\n\n\n(예시2)\n\ndf.groupby(by=[\"AIRLINE\",\"WEEKDAY\"])[\"CANCELLED\"].agg(\"sum\")\n\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n                    ..\nWN       3          18\n         4          10\n         5           7\n         6          10\n         7           7\nName: CANCELLED, Length: 98, dtype: int64\n\n\n(예시3)\n\ndf.groupby(by=[\"AIRLINE\",\"WEEKDAY\"])[\"CANCELLED\"].sum()\n\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n                    ..\nWN       3          18\n         4          10\n         5           7\n         6          10\n         7           7\nName: CANCELLED, Length: 98, dtype: int64\n\n\n\ndf.DIVERTED\n\n0        0\n1        0\n2        0\n3        0\n4        0\n        ..\n58487    0\n58488    0\n58489    0\n58490    0\n58491    0\nName: DIVERTED, Length: 58492, dtype: int64\n\n\n\n\n# EX3: [AIRLINE,WEEKDAY] \\(\\to\\) {CANCELLED:sum,mean}, {DIVERTED: sum,mean}\n- 방법1\n(예시1)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({\"CANCELLED\":[np.sum,np.mean],\"DIVERTED\":[np.sum,np.mean]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시2)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({\"CANCELLED\":[\"sum\",\"mean\"],\"DIVERTED\":[\"sum\",\"mean\"]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n- 방법2\n(예시1)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])[[\"CANCELLED\",\"DIVERTED\"]]\\\n.agg([np.sum,np.mean])\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시2)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])[[\"CANCELLED\",\"DIVERTED\"]]\\\n.agg([\"sum\",\"mean\"])\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      DIVERTED\n    \n    \n      \n      \n      sum\n      mean\n      sum\n      mean\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      6\n      0.004699\n    \n    \n      2\n      9\n      0.007341\n      2\n      0.001631\n    \n    \n      3\n      16\n      0.011949\n      2\n      0.001494\n    \n    \n      4\n      20\n      0.015004\n      5\n      0.003751\n    \n    \n      5\n      18\n      0.014151\n      1\n      0.000786\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      2\n      0.001569\n    \n    \n      4\n      10\n      0.007911\n      4\n      0.003165\n    \n    \n      5\n      7\n      0.005828\n      0\n      0.000000\n    \n    \n      6\n      10\n      0.010132\n      3\n      0.003040\n    \n    \n      7\n      7\n      0.006066\n      3\n      0.002600\n    \n  \n\n98 rows × 4 columns\n\n\n\n(예시3) – 사용불가능\n\n\n# EX4: [AIRLINE,WEEKDAY] \\(\\to\\) {CANCELLED:sum,mean,count}, {AIR_TIME: mean,var}\n- 방법1\n(예시1)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({'CANCELLED':[np.sum,np.mean,len],'AIR_TIME':[np.mean,np.var]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      len\n      mean\n      var\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns\n\n\n\n(예시2)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({'CANCELLED':[\"sum\",\"mean\",\"count\"],'AIR_TIME':[\"mean\",\"var\"]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      count\n      mean\n      var\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns\n\n\n\n(사용자정의함수)\n\ndf.groupby([\"AIRLINE\",\"WEEKDAY\"])\\\n.agg({'CANCELLED':[np.sum,np.mean,len],\n      'AIR_TIME':[np.mean,lambda x: np.std(x,ddof=1)**2]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n      AIR_TIME\n    \n    \n      \n      \n      sum\n      mean\n      len\n      mean\n      <lambda_0>\n    \n    \n      AIRLINE\n      WEEKDAY\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AA\n      1\n      41\n      0.032106\n      1277\n      147.610569\n      5393.806723\n    \n    \n      2\n      9\n      0.007341\n      1226\n      143.851852\n      5359.890719\n    \n    \n      3\n      16\n      0.011949\n      1339\n      144.514005\n      5378.854539\n    \n    \n      4\n      20\n      0.015004\n      1333\n      141.124618\n      4791.524627\n    \n    \n      5\n      18\n      0.014151\n      1272\n      145.430966\n      5884.592076\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      WN\n      3\n      18\n      0.014118\n      1275\n      104.219920\n      2901.873447\n    \n    \n      4\n      10\n      0.007911\n      1264\n      107.200800\n      2966.568935\n    \n    \n      5\n      7\n      0.005828\n      1201\n      107.893635\n      3268.717093\n    \n    \n      6\n      10\n      0.010132\n      987\n      109.247433\n      3152.753719\n    \n    \n      7\n      7\n      0.006066\n      1154\n      107.602273\n      3183.126889\n    \n  \n\n98 rows × 5 columns"
  },
  {
    "objectID": "posts/2022-10-24-8wk-12.html#연속형변수를-기준으로-groupby---agg",
    "href": "posts/2022-10-24-8wk-12.html#연속형변수를-기준으로-groupby---agg",
    "title": "08wk-1,2",
    "section": "연속형변수를 기준으로 groupby -> agg",
    "text": "연속형변수를 기준으로 groupby -> agg\n\ndf.T\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      ...\n      58482\n      58483\n      58484\n      58485\n      58486\n      58487\n      58488\n      58489\n      58490\n      58491\n    \n  \n  \n    \n      MONTH\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      ...\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n      12\n    \n    \n      DAY\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      1\n      ...\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n      31\n    \n    \n      WEEKDAY\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      ...\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n      4\n    \n    \n      AIRLINE\n      WN\n      UA\n      MQ\n      AA\n      WN\n      UA\n      AA\n      F9\n      AA\n      UA\n      ...\n      OO\n      B6\n      MQ\n      DL\n      EV\n      AA\n      F9\n      OO\n      WN\n      OO\n    \n    \n      ORG_AIR\n      LAX\n      DEN\n      DFW\n      DFW\n      LAX\n      IAH\n      DFW\n      SFO\n      ORD\n      IAH\n      ...\n      DEN\n      PHX\n      ORD\n      ATL\n      DFW\n      SFO\n      LAS\n      SFO\n      MSP\n      SFO\n    \n    \n      DEST_AIR\n      SLC\n      IAD\n      VPS\n      DCA\n      MCI\n      SAN\n      MSY\n      PHX\n      STL\n      SJC\n      ...\n      CPR\n      BOS\n      DSM\n      CMH\n      LFT\n      DFW\n      SFO\n      SBA\n      ATL\n      BOI\n    \n    \n      SCHED_DEP\n      1625\n      823\n      1305\n      1555\n      1720\n      1450\n      1250\n      1020\n      1845\n      925\n      ...\n      1850\n      2236\n      1333\n      2206\n      850\n      515\n      1910\n      1846\n      525\n      859\n    \n    \n      DEP_DELAY\n      58.0\n      7.0\n      36.0\n      7.0\n      48.0\n      1.0\n      84.0\n      -7.0\n      -5.0\n      3.0\n      ...\n      -2.0\n      -12.0\n      1.0\n      2.0\n      21.0\n      5.0\n      13.0\n      -6.0\n      39.0\n      5.0\n    \n    \n      AIR_TIME\n      94.0\n      154.0\n      85.0\n      126.0\n      166.0\n      178.0\n      64.0\n      91.0\n      44.0\n      215.0\n      ...\n      38.0\n      231.0\n      57.0\n      64.0\n      52.0\n      166.0\n      71.0\n      46.0\n      124.0\n      73.0\n    \n    \n      DIST\n      590\n      1452\n      641\n      1192\n      1363\n      1303\n      447\n      651\n      258\n      1608\n      ...\n      230\n      2300\n      299\n      447\n      351\n      1464\n      414\n      262\n      907\n      522\n    \n    \n      SCHED_ARR\n      1905\n      1333\n      1453\n      1935\n      2225\n      1620\n      1410\n      1315\n      1950\n      1136\n      ...\n      1956\n      515\n      1455\n      2338\n      1012\n      1045\n      2050\n      1956\n      855\n      1146\n    \n    \n      ARR_DELAY\n      65.0\n      -13.0\n      35.0\n      -7.0\n      39.0\n      -14.0\n      83.0\n      -6.0\n      -5.0\n      -14.0\n      ...\n      1.0\n      -45.0\n      -7.0\n      -8.0\n      14.0\n      -19.0\n      4.0\n      -5.0\n      34.0\n      -1.0\n    \n    \n      DIVERTED\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      CANCELLED\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n14 rows × 58492 columns\n\n\n\n\ndf.DIST.describe()\n\ncount    58492.000000\nmean       872.900072\nstd        624.996805\nmin         67.000000\n25%        391.000000\n50%        690.000000\n75%       1199.000000\nmax       4502.000000\nName: DIST, dtype: float64\n\n\n\ndf.assign(DIST2 = pd.cut(df.DIST,[-np.inf,391,690,1199,np.inf]))\\\n.groupby([\"AIRLINE\",\"DIST2\"]).agg({'CANCELLED':[\"sum\",\"mean\",\"count\"]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      \n      \n      sum\n      mean\n      count\n    \n    \n      AIRLINE\n      DIST2\n      \n      \n      \n    \n  \n  \n    \n      AA\n      (-inf, 391.0]\n      18\n      0.015986\n      1126\n    \n    \n      (391.0, 690.0]\n      17\n      0.013589\n      1251\n    \n    \n      (690.0, 1199.0]\n      69\n      0.022066\n      3127\n    \n    \n      (1199.0, inf]\n      50\n      0.014723\n      3396\n    \n    \n      AS\n      (-inf, 391.0]\n      0\n      NaN\n      0\n    \n    \n      (391.0, 690.0]\n      0\n      0.000000\n      145\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      462\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      161\n    \n    \n      B6\n      (-inf, 391.0]\n      0\n      0.000000\n      71\n    \n    \n      (391.0, 690.0]\n      0\n      0.000000\n      38\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      61\n    \n    \n      (1199.0, inf]\n      1\n      0.002681\n      373\n    \n    \n      DL\n      (-inf, 391.0]\n      7\n      0.003086\n      2268\n    \n    \n      (391.0, 690.0]\n      8\n      0.002421\n      3304\n    \n    \n      (690.0, 1199.0]\n      16\n      0.006405\n      2498\n    \n    \n      (1199.0, inf]\n      7\n      0.002766\n      2531\n    \n    \n      EV\n      (-inf, 391.0]\n      77\n      0.028785\n      2675\n    \n    \n      (391.0, 690.0]\n      47\n      0.022793\n      2062\n    \n    \n      (690.0, 1199.0]\n      22\n      0.019982\n      1101\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      20\n    \n    \n      F9\n      (-inf, 391.0]\n      0\n      0.000000\n      27\n    \n    \n      (391.0, 690.0]\n      6\n      0.013825\n      434\n    \n    \n      (690.0, 1199.0]\n      4\n      0.007105\n      563\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      293\n    \n    \n      HA\n      (-inf, 391.0]\n      0\n      NaN\n      0\n    \n    \n      (391.0, 690.0]\n      0\n      NaN\n      0\n    \n    \n      (690.0, 1199.0]\n      0\n      NaN\n      0\n    \n    \n      (1199.0, inf]\n      0\n      0.000000\n      112\n    \n    \n      MQ\n      (-inf, 391.0]\n      90\n      0.047120\n      1910\n    \n    \n      (391.0, 690.0]\n      39\n      0.037356\n      1044\n    \n    \n      (690.0, 1199.0]\n      22\n      0.044266\n      497\n    \n    \n      (1199.0, inf]\n      1\n      0.050000\n      20\n    \n    \n      NK\n      (-inf, 391.0]\n      5\n      0.036496\n      137\n    \n    \n      (391.0, 690.0]\n      4\n      0.013201\n      303\n    \n    \n      (690.0, 1199.0]\n      6\n      0.011029\n      544\n    \n    \n      (1199.0, inf]\n      10\n      0.018797\n      532\n    \n    \n      OO\n      (-inf, 391.0]\n      75\n      0.024826\n      3021\n    \n    \n      (391.0, 690.0]\n      39\n      0.019364\n      2014\n    \n    \n      (690.0, 1199.0]\n      19\n      0.016351\n      1162\n    \n    \n      (1199.0, inf]\n      9\n      0.023018\n      391\n    \n    \n      UA\n      (-inf, 391.0]\n      5\n      0.007143\n      700\n    \n    \n      (391.0, 690.0]\n      14\n      0.011824\n      1184\n    \n    \n      (690.0, 1199.0]\n      26\n      0.010924\n      2380\n    \n    \n      (1199.0, inf]\n      48\n      0.013605\n      3528\n    \n    \n      US\n      (-inf, 391.0]\n      0\n      0.000000\n      254\n    \n    \n      (391.0, 690.0]\n      7\n      0.021944\n      319\n    \n    \n      (690.0, 1199.0]\n      2\n      0.006329\n      316\n    \n    \n      (1199.0, inf]\n      12\n      0.016529\n      726\n    \n    \n      VX\n      (-inf, 391.0]\n      2\n      0.008299\n      241\n    \n    \n      (391.0, 690.0]\n      1\n      0.003861\n      259\n    \n    \n      (690.0, 1199.0]\n      0\n      0.000000\n      22\n    \n    \n      (1199.0, inf]\n      3\n      0.006369\n      471\n    \n    \n      WN\n      (-inf, 391.0]\n      55\n      0.023810\n      2310\n    \n    \n      (391.0, 690.0]\n      14\n      0.006487\n      2158\n    \n    \n      (690.0, 1199.0]\n      17\n      0.007896\n      2153\n    \n    \n      (1199.0, inf]\n      7\n      0.003895\n      1797\n    \n  \n\n\n\n\n\npd.cut(df.DIST,[-np.inf,400,700,1200,np.inf],labels=['~400','400~700','700~1200','1200~'])\n\n0         400~700\n1           1200~\n2         400~700\n3        700~1200\n4           1200~\n           ...   \n58487       1200~\n58488     400~700\n58489        ~400\n58490    700~1200\n58491     400~700\nName: DIST, Length: 58492, dtype: category\nCategories (4, object): ['~400' < '400~700' < '700~1200' < '1200~']\n\n\n\ndf.assign(DIST2 = pd.cut(df.DIST,[-np.inf,400,700,1200,np.inf],labels=['~400','400~700','700~1200','1200~']))\\\n.groupby([\"AIRLINE\",\"DIST2\"]).agg({'CANCELLED':[\"sum\",\"mean\",\"count\"]})\n\n\n\n\n\n  \n    \n      \n      \n      CANCELLED\n    \n    \n      \n      \n      sum\n      mean\n      count\n    \n    \n      AIRLINE\n      DIST2\n      \n      \n      \n    \n  \n  \n    \n      AA\n      ~400\n      18\n      0.015986\n      1126\n    \n    \n      400~700\n      17\n      0.013589\n      1251\n    \n    \n      700~1200\n      69\n      0.022066\n      3127\n    \n    \n      1200~\n      50\n      0.014723\n      3396\n    \n    \n      AS\n      ~400\n      0\n      NaN\n      0\n    \n    \n      400~700\n      0\n      0.000000\n      145\n    \n    \n      700~1200\n      0\n      0.000000\n      462\n    \n    \n      1200~\n      0\n      0.000000\n      161\n    \n    \n      B6\n      ~400\n      0\n      0.000000\n      71\n    \n    \n      400~700\n      0\n      0.000000\n      38\n    \n    \n      700~1200\n      0\n      0.000000\n      61\n    \n    \n      1200~\n      1\n      0.002681\n      373\n    \n    \n      DL\n      ~400\n      7\n      0.003040\n      2303\n    \n    \n      400~700\n      8\n      0.002352\n      3402\n    \n    \n      700~1200\n      16\n      0.006765\n      2365\n    \n    \n      1200~\n      7\n      0.002766\n      2531\n    \n    \n      EV\n      ~400\n      77\n      0.027838\n      2766\n    \n    \n      400~700\n      48\n      0.023312\n      2059\n    \n    \n      700~1200\n      21\n      0.020731\n      1013\n    \n    \n      1200~\n      0\n      0.000000\n      20\n    \n    \n      F9\n      ~400\n      0\n      0.000000\n      27\n    \n    \n      400~700\n      7\n      0.015837\n      442\n    \n    \n      700~1200\n      3\n      0.005405\n      555\n    \n    \n      1200~\n      0\n      0.000000\n      293\n    \n    \n      HA\n      ~400\n      0\n      NaN\n      0\n    \n    \n      400~700\n      0\n      NaN\n      0\n    \n    \n      700~1200\n      0\n      NaN\n      0\n    \n    \n      1200~\n      0\n      0.000000\n      112\n    \n    \n      MQ\n      ~400\n      92\n      0.047472\n      1938\n    \n    \n      400~700\n      39\n      0.035682\n      1093\n    \n    \n      700~1200\n      20\n      0.047619\n      420\n    \n    \n      1200~\n      1\n      0.050000\n      20\n    \n    \n      NK\n      ~400\n      5\n      0.036496\n      137\n    \n    \n      400~700\n      4\n      0.013201\n      303\n    \n    \n      700~1200\n      6\n      0.011029\n      544\n    \n    \n      1200~\n      10\n      0.018797\n      532\n    \n    \n      OO\n      ~400\n      76\n      0.024837\n      3060\n    \n    \n      400~700\n      38\n      0.018673\n      2035\n    \n    \n      700~1200\n      19\n      0.017241\n      1102\n    \n    \n      1200~\n      9\n      0.023018\n      391\n    \n    \n      UA\n      ~400\n      5\n      0.006993\n      715\n    \n    \n      400~700\n      14\n      0.011966\n      1170\n    \n    \n      700~1200\n      26\n      0.010929\n      2379\n    \n    \n      1200~\n      48\n      0.013605\n      3528\n    \n    \n      US\n      ~400\n      0\n      0.000000\n      254\n    \n    \n      400~700\n      7\n      0.021944\n      319\n    \n    \n      700~1200\n      2\n      0.006329\n      316\n    \n    \n      1200~\n      12\n      0.016529\n      726\n    \n    \n      VX\n      ~400\n      2\n      0.008299\n      241\n    \n    \n      400~700\n      1\n      0.003861\n      259\n    \n    \n      700~1200\n      0\n      0.000000\n      22\n    \n    \n      1200~\n      3\n      0.006369\n      471\n    \n    \n      WN\n      ~400\n      55\n      0.023022\n      2389\n    \n    \n      400~700\n      17\n      0.007795\n      2181\n    \n    \n      700~1200\n      14\n      0.006826\n      2051\n    \n    \n      1200~\n      7\n      0.003895\n      1797"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html",
    "href": "posts/2022-09-28-4wk-2.html",
    "title": "04wk-2",
    "section": "",
    "text": "seaborn(1)–seaborn특징,boxplot,lineplot"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#plt-복습",
    "href": "posts/2022-09-28-4wk-2.html#plt-복습",
    "title": "04wk-2",
    "section": "plt 복습",
    "text": "plt 복습\n\nplt.boxplot([y1,y2]);"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-wide-df",
    "href": "posts/2022-09-28-4wk-2.html#sns-wide-df",
    "title": "04wk-2",
    "section": "sns wide df",
    "text": "sns wide df\n\ndf1=pd.DataFrame({1:y1,2:y2})\ndf1\n\n\n\n\n\n  \n    \n      \n      1\n      2\n    \n  \n  \n    \n      0\n      75\n      76\n    \n    \n      1\n      75\n      76\n    \n    \n      2\n      76\n      77\n    \n    \n      3\n      76\n      77\n    \n    \n      4\n      77\n      78\n    \n    \n      5\n      77\n      78\n    \n    \n      6\n      79\n      80\n    \n    \n      7\n      79\n      80\n    \n    \n      8\n      79\n      80\n    \n    \n      9\n      98\n      81\n    \n  \n\n\n\n\n- 예시1\n\nsns.boxplot(data=df1) \n#sns.boxplot(data=np.stack([y1,y2],axis=1))  # <- 잘 쓰진 않아요, 그냥 심심해서 해봤는데 되더라고요..?\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-long-df",
    "href": "posts/2022-09-28-4wk-2.html#sns-long-df",
    "title": "04wk-2",
    "section": "sns long df",
    "text": "sns long df\n\ndf2=pd.DataFrame({'score':y1+y2,'class':['A']*len(y1)+['B']*len(y2)})\ndf2\n\n\n\n\n\n  \n    \n      \n      score\n      class\n    \n  \n  \n    \n      0\n      75\n      A\n    \n    \n      1\n      75\n      A\n    \n    \n      2\n      76\n      A\n    \n    \n      3\n      76\n      A\n    \n    \n      4\n      77\n      A\n    \n    \n      5\n      77\n      A\n    \n    \n      6\n      79\n      A\n    \n    \n      7\n      79\n      A\n    \n    \n      8\n      79\n      A\n    \n    \n      9\n      98\n      A\n    \n    \n      10\n      76\n      B\n    \n    \n      11\n      76\n      B\n    \n    \n      12\n      77\n      B\n    \n    \n      13\n      77\n      B\n    \n    \n      14\n      78\n      B\n    \n    \n      15\n      78\n      B\n    \n    \n      16\n      80\n      B\n    \n    \n      17\n      80\n      B\n    \n    \n      18\n      80\n      B\n    \n    \n      19\n      81\n      B\n    \n  \n\n\n\n\n- 예시1\n\nsns.boxplot(data=df2,x='class',y='score') \n\n<AxesSubplot:xlabel='class', ylabel='score'>"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-array",
    "href": "posts/2022-09-28-4wk-2.html#sns-array",
    "title": "04wk-2",
    "section": "sns: array",
    "text": "sns: array\n- 예시1\n\nsns.boxplot(data=y1)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시2\n\nsns.boxplot(y=y1)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시3\n\nsns.boxplot(x=y1)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#plt-복습-1",
    "href": "posts/2022-09-28-4wk-2.html#plt-복습-1",
    "title": "04wk-2",
    "section": "plt 복습",
    "text": "plt 복습\n- 예시1\n\nplt.hist(x,alpha=0.5)\nplt.hist(y,alpha=0.5);\n\n\n\n\n- 예시2\n\nplt.hist([x,y]);"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-wide-df-1",
    "href": "posts/2022-09-28-4wk-2.html#sns-wide-df-1",
    "title": "04wk-2",
    "section": "sns: wide df",
    "text": "sns: wide df\n\ndf1=pd.DataFrame({'x':x,'y':y})\ndf1\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -2.110587\n      0.712687\n    \n    \n      1\n      0.176404\n      1.587615\n    \n    \n      2\n      0.592212\n      0.362025\n    \n    \n      3\n      0.957655\n      0.485939\n    \n    \n      4\n      1.689412\n      0.582304\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      9995\n      -0.935895\n      0.047778\n    \n    \n      9996\n      1.521599\n      1.946658\n    \n    \n      9997\n      -0.595255\n      0.671715\n    \n    \n      9998\n      0.952991\n      2.263997\n    \n    \n      9999\n      0.850642\n      1.578771\n    \n  \n\n10000 rows × 2 columns\n\n\n\n- 예시1\n\nsns.histplot(data=df1)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- 예시2\n\nsns.histplot(data=df1,bins=20)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- 예시3\n\nsns.histplot(data=df1,bins=20,kde=True)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- 예시4\n\nsns.histplot(data=df1,bins=20,kde=True,element=\"step\")\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- 예시5\n\nsns.histplot(data=df1,bins=20,kde=True,element=\"step\",lw=5) # mpl에 대한 존경심 확인 \n\n<AxesSubplot:ylabel='Count'>"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-long-df-1",
    "href": "posts/2022-09-28-4wk-2.html#sns-long-df-1",
    "title": "04wk-2",
    "section": "sns: long df",
    "text": "sns: long df\n\ndf2=pd.DataFrame({'val':np.concatenate([x,y]), 'var':['x']*len(x) + ['y']*len(y)})\ndf2\n\n\n\n\n\n  \n    \n      \n      val\n      var\n    \n  \n  \n    \n      0\n      -2.110587\n      x\n    \n    \n      1\n      0.176404\n      x\n    \n    \n      2\n      0.592212\n      x\n    \n    \n      3\n      0.957655\n      x\n    \n    \n      4\n      1.689412\n      x\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      19995\n      0.047778\n      y\n    \n    \n      19996\n      1.946658\n      y\n    \n    \n      19997\n      0.671715\n      y\n    \n    \n      19998\n      2.263997\n      y\n    \n    \n      19999\n      1.578771\n      y\n    \n  \n\n20000 rows × 2 columns\n\n\n\n- 예시1\n\nsns.histplot(data=df2,x='val',hue='var',bins=20,kde=True,lw=0)\n\n<AxesSubplot:xlabel='val', ylabel='Count'>\n\n\n\n\n\n- 예시2\n\nsns.histplot(data=df2,y='val',hue='var',bins=20,lw=0,kde=True)\n\n<AxesSubplot:xlabel='Count', ylabel='val'>"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-array-1",
    "href": "posts/2022-09-28-4wk-2.html#sns-array-1",
    "title": "04wk-2",
    "section": "sns: array",
    "text": "sns: array\n- 예시1\n\nsns.histplot(data=x)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- 예시2\n\nsns.histplot(x=x)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- 예시3\n\nsns.histplot(x=x,color='C0',bins=20,lw=0)\nsns.histplot(x=y,color='C1',bins=20,lw=0)\n\n<AxesSubplot:ylabel='Count'>"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#plt-복습-2",
    "href": "posts/2022-09-28-4wk-2.html#plt-복습-2",
    "title": "04wk-2",
    "section": "plt 복습",
    "text": "plt 복습\n\nplt.plot(ϵ,'--o')\n\n\n\n\n\nplt.plot(y,'--o')"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-array-2",
    "href": "posts/2022-09-28-4wk-2.html#sns-array-2",
    "title": "04wk-2",
    "section": "sns: array",
    "text": "sns: array\n- 예시1\n\nsns.lineplot(data=ϵ)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시2\n\nsns.lineplot(data=y)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-wide-df-2",
    "href": "posts/2022-09-28-4wk-2.html#sns-wide-df-2",
    "title": "04wk-2",
    "section": "sns: wide df",
    "text": "sns: wide df\n\ndf1=pd.DataFrame({'eps':ϵ, 'y':y})\ndf1\n\n\n\n\n\n  \n    \n      \n      eps\n      y\n    \n  \n  \n    \n      0\n      0.383420\n      0.383420\n    \n    \n      1\n      1.084175\n      1.467595\n    \n    \n      2\n      1.142778\n      2.610373\n    \n    \n      3\n      0.307894\n      2.918267\n    \n    \n      4\n      0.237787\n      3.156054\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      1.308688\n      -10.598788\n    \n    \n      96\n      0.405376\n      -10.193412\n    \n    \n      97\n      -0.185070\n      -10.378481\n    \n    \n      98\n      1.055388\n      -9.323094\n    \n    \n      99\n      1.187014\n      -8.136079\n    \n  \n\n100 rows × 2 columns\n\n\n\n- 예시1\n\nsns.lineplot(data=df1)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시2\n\nsns.lineplot(data=df1,dashes=False)\n\n<AxesSubplot:>\n\n\n\n\n\n- 예시3\n\n# sns.lineplot(data=df1,dashes=[(3,1),(3,1)]) # 이코드는 최신버전의 sns에서 동작하지 않으므로 삭제합니다. (collab 에서는 정상동작)\n\n- 예시4\n\n# sns.lineplot(data=df1,dashes=[(3,1),(15,3)],markers=['o','o'])  # 이코드는 최신버전의 sns에서 동작하지 않으므로 삭제합니다. (collab 에서는 정상동작)"
  },
  {
    "objectID": "posts/2022-09-28-4wk-2.html#sns-long-df-2",
    "href": "posts/2022-09-28-4wk-2.html#sns-long-df-2",
    "title": "04wk-2",
    "section": "sns: long df",
    "text": "sns: long df\n\ndf2= pd.DataFrame({'idx':list(range(100))*2,'val':np.concatenate([ϵ,y]),'cat':['eps']*100 + ['y']*100 })\ndf2\n\n\n\n\n\n  \n    \n      \n      idx\n      val\n      cat\n    \n  \n  \n    \n      0\n      0\n      0.383420\n      eps\n    \n    \n      1\n      1\n      1.084175\n      eps\n    \n    \n      2\n      2\n      1.142778\n      eps\n    \n    \n      3\n      3\n      0.307894\n      eps\n    \n    \n      4\n      4\n      0.237787\n      eps\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      95\n      -10.598788\n      y\n    \n    \n      196\n      96\n      -10.193412\n      y\n    \n    \n      197\n      97\n      -10.378481\n      y\n    \n    \n      198\n      98\n      -9.323094\n      y\n    \n    \n      199\n      99\n      -8.136079\n      y\n    \n  \n\n200 rows × 3 columns\n\n\n\n- 예시1\n\nsns.lineplot(data=df2, x='idx',y='val',hue='cat')\n\n<AxesSubplot:xlabel='idx', ylabel='val'>\n\n\n\n\n\n- 예시2\n\nsns.lineplot(data=df2, x='idx',y='val',style='cat',hue='cat',markers=True)\n\n<AxesSubplot:xlabel='idx', ylabel='val'>\n\n\n\n\n\n- 예시3\n\nsns.lineplot(data=df2, x='idx',y='val',style='cat',hue='cat',dashes=[(3,1),(3,3)],markers=['o','o'])\n\n<AxesSubplot:xlabel='idx', ylabel='val'>"
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html",
    "href": "posts/2022-11-16-11wk-2.html",
    "title": "11wk-2",
    "section": "",
    "text": "자료분석– 저출산자료 시각화"
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html#데이터읽기-pd.read_html",
    "href": "posts/2022-11-16-11wk-2.html#데이터읽기-pd.read_html",
    "title": "11wk-2",
    "section": "데이터읽기 // pd.read_html()",
    "text": "데이터읽기 // pd.read_html()\n- 대한민국의 저출산문제\n\nref: https://ko.wikipedia.org/wiki/대한민국의_저출산\n\n- 위의 url에서 3,5번째 테이블을 읽고싶다. - 3번째 테이블: 시도별 출산율 - 5번째 테이블: 시도별 출생아 수\n\n_dflst = pd.read_html('https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%A0%80%EC%B6%9C%EC%82%B0')\n_df1 = _dflst[2] \n_df2 = _dflst[4] \n\n\n_df1\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      2005\n      2006[7]\n      2007\n      2008[8]\n      2009[9]\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n  \n  \n    \n      0\n      서울\n      0.92\n      0.97\n      1.06\n      1.01\n      0.96\n      1.02\n      1.01\n      1.06\n      0.97\n      0.98\n      1.00\n      0.94\n      0.84\n      0.76\n      0.72\n      0.64\n      0.63\n    \n    \n      1\n      부산\n      0.88\n      0.91\n      1.02\n      0.98\n      0.94\n      1.05\n      1.08\n      1.14\n      1.05\n      1.09\n      1.14\n      1.10\n      0.98\n      0.90\n      0.83\n      0.75\n      0.73\n    \n    \n      2\n      대구\n      0.99\n      1.00\n      1.13\n      1.07\n      1.03\n      1.11\n      1.15\n      1.22\n      1.13\n      1.17\n      1.22\n      1.19\n      1.07\n      0.99\n      0.93\n      0.81\n      0.78\n    \n    \n      3\n      인천\n      1.07\n      1.11\n      1.25\n      1.19\n      1.14\n      1.21\n      1.23\n      1.30\n      1.20\n      1.21\n      1.22\n      1.14\n      1.01\n      1.01\n      0.94\n      0.83\n      0.78\n    \n    \n      4\n      광주\n      1.10\n      1.14\n      1.26\n      1.20\n      1.14\n      1.22\n      1.23\n      1.30\n      1.17\n      1.20\n      1.21\n      1.17\n      1.05\n      0.97\n      0.91\n      0.81\n      0.90\n    \n    \n      5\n      대전\n      1.10\n      1.15\n      1.27\n      1.22\n      1.16\n      1.21\n      1.26\n      1.32\n      1.23\n      1.25\n      1.28\n      1.19\n      1.08\n      0.95\n      0.88\n      0.81\n      0.81\n    \n    \n      6\n      울산\n      1.18\n      1.24\n      1.40\n      1.34\n      1.31\n      1.37\n      1.39\n      1.48\n      1.39\n      1.44\n      1.49\n      1.42\n      1.26\n      1.13\n      1.08\n      0.99\n      0.94\n    \n    \n      7\n      세종\n      -\n      -\n      -\n      -\n      -\n      -\n      -\n      1.60\n      1.44\n      1.35\n      1.89\n      1.82\n      1.67\n      1.57\n      1.47\n      1.28\n      1.28\n    \n    \n      8\n      경기\n      1.17\n      1.23\n      1.35\n      1.29\n      1.23\n      1.31\n      1.31\n      1.36\n      1.23\n      1.24\n      1.27\n      1.19\n      1.07\n      1.00\n      0.94\n      0.88\n      0.85\n    \n    \n      9\n      강원\n      1.18\n      1.19\n      1.35\n      1.25\n      1.25\n      1.31\n      1.34\n      1.37\n      1.25\n      1.25\n      1.31\n      1.24\n      1.12\n      1.07\n      1.08\n      1.04\n      0.98\n    \n    \n      10\n      충북\n      1.19\n      1.22\n      1.39\n      1.32\n      1.32\n      1.40\n      1.43\n      1.49\n      1.37\n      1.36\n      1.41\n      1.36\n      1.24\n      1.17\n      1.05\n      0.98\n      0.95\n    \n    \n      11\n      충남\n      1.26\n      1.35\n      1.50\n      1.44\n      1.41\n      1.48\n      1.50\n      1.57\n      1.44\n      1.42\n      1.48\n      1.40\n      1.28\n      1.19\n      1.11\n      1.03\n      0.96\n    \n    \n      12\n      전북\n      1.17\n      1.20\n      1.37\n      1.31\n      1.28\n      1.37\n      1.41\n      1.44\n      1.32\n      1.33\n      1.35\n      1.25\n      1.15\n      1.04\n      0.97\n      0.91\n      0.85\n    \n    \n      13\n      전남\n      1.28\n      1.33\n      1.53\n      1.45\n      1.45\n      1.54\n      1.57\n      1.64\n      1.52\n      1.50\n      1.55\n      1.47\n      1.33\n      1.24\n      1.23\n      1.15\n      1.02\n    \n    \n      14\n      경북\n      1.17\n      1.20\n      1.36\n      1.31\n      1.27\n      1.38\n      1.43\n      1.49\n      1.38\n      1.41\n      1.46\n      1.40\n      1.26\n      1.17\n      1.09\n      1.00\n      0.97\n    \n    \n      15\n      경남\n      1.18\n      1.25\n      1.43\n      1.37\n      1.32\n      1.41\n      1.45\n      1.50\n      1.37\n      1.41\n      1.44\n      1.36\n      1.23\n      1.12\n      1.05\n      0.95\n      0.90\n    \n    \n      16\n      제주\n      1.30\n      1.36\n      1.48\n      1.39\n      1.38\n      1.46\n      1.49\n      1.60\n      1.43\n      1.48\n      1.48\n      1.43\n      1.31\n      1.22\n      1.15\n      1.02\n      0.95\n    \n    \n      17\n      전국\n      1.08\n      1.13\n      1.25\n      1.19\n      1.15\n      1.23\n      1.24\n      1.30\n      1.19\n      1.21\n      1.24\n      1.17\n      1.05\n      0.98\n      0.92\n      0.84\n      0.81\n    \n  \n\n\n\n\n\n_df2\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n  \n  \n    \n      0\n      서울\n      93266\n      91526\n      93914.000\n      84066.000\n      83711.000\n      83005\n      75.536\n      65389\n      58074\n      53.673\n      47400\n      45531\n    \n    \n      1\n      부산\n      27415\n      27759\n      28673.000\n      25831.000\n      26190.000\n      26645\n      24906.000\n      21480\n      19152\n      17049.000\n      15100\n      14446\n    \n    \n      2\n      대구\n      20557\n      20758\n      21472.000\n      19340.000\n      19361.000\n      19438\n      18298.000\n      15946\n      14400\n      13233.000\n      11200\n      10661\n    \n    \n      3\n      인천\n      25752\n      20758\n      21472.000\n      25560.000\n      25786.000\n      25491\n      23609.000\n      20445\n      20087\n      18522.000\n      16000\n      14947\n    \n    \n      4\n      광주\n      13979\n      13916\n      14392.000\n      12729.000\n      12729.000\n      12441\n      11580.000\n      10120\n      9105\n      8364.000\n      7300\n      7956\n    \n    \n      5\n      대전\n      14314\n      14808\n      15279.000\n      14099.000\n      13962.000\n      13774\n      12436.000\n      10851\n      9337\n      8410.000\n      7500\n      7414\n    \n    \n      6\n      울산\n      11432\n      11542\n      12160.000\n      11330.000\n      11556.000\n      11732\n      10910.000\n      9381\n      8149\n      7539.000\n      6600\n      6127\n    \n    \n      7\n      세종\n      -\n      -\n      1054.000\n      1111.000\n      1344.000\n      2708\n      3297.000\n      3504\n      3703\n      3819.000\n      3500\n      3570\n    \n    \n      8\n      경기\n      121753\n      122027\n      124746.000\n      112129.000\n      112.169\n      113495\n      105643.000\n      94088\n      83198\n      83.198\n      77800\n      76139\n    \n    \n      9\n      강원\n      12477\n      12408\n      12426.000\n      10980.000\n      10662.000\n      10929\n      10058.000\n      9958\n      8351\n      8283.000\n      7800\n      7357\n    \n    \n      10\n      충북\n      14670\n      14804\n      15139.000\n      13658.000\n      13366.000\n      13563\n      12742.000\n      11394\n      10586\n      9333.000\n      8600\n      8190\n    \n    \n      11\n      충남\n      20.242\n      20.398\n      20.448\n      18.628\n      18200.000\n      18604\n      17302.000\n      15670\n      14380\n      13228.000\n      11900\n      10984\n    \n    \n      12\n      전북\n      16100\n      16175\n      16238.000\n      14555.000\n      14231.000\n      14087\n      12698.000\n      11348\n      10001\n      8971.000\n      8200\n      7745\n    \n    \n      13\n      전남\n      16654\n      16612\n      16990.000\n      15401.000\n      14817.000\n      15061\n      13980.000\n      12354\n      11238\n      10832.000\n      9700\n      8430\n    \n    \n      14\n      경북\n      23700\n      24250\n      24635.000\n      22206.000\n      22062.000\n      22310\n      20616.000\n      17957\n      16079\n      14472.000\n      12900\n      12045\n    \n    \n      15\n      경남\n      32203\n      32536\n      33211.000\n      29504.000\n      29763.000\n      29537\n      27138.000\n      23849\n      21224\n      19250.000\n      16800\n      15562\n    \n    \n      16\n      제주\n      5657\n      5628\n      5992.000\n      5328.000\n      5526.000\n      5600\n      5494.000\n      5037\n      4781\n      4500.000\n      4000\n      3728\n    \n    \n      17\n      전국\n      470171\n      471265\n      484550.000\n      436455.000\n      435435.000\n      438420\n      406243.000\n      357771\n      326822\n      302676.000\n      272400\n      260562\n    \n  \n\n\n\n\n- 데이터정리\n\ndf1 = _df1.drop(17)\\\n.melt(id_vars='지역/연도[6]')\\\n.assign(variable = lambda df: list(map(lambda x: x[:4], df.variable)))\\\n.assign(value = lambda df: list(map(lambda x: None if x=='-' else float(x), df.value)))\\\n.set_axis(['지역','연도','출산율'],axis=1)\ndf1\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출산율\n    \n  \n  \n    \n      0\n      서울\n      2005\n      0.92\n    \n    \n      1\n      부산\n      2005\n      0.88\n    \n    \n      2\n      대구\n      2005\n      0.99\n    \n    \n      3\n      인천\n      2005\n      1.07\n    \n    \n      4\n      광주\n      2005\n      1.10\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      284\n      전북\n      2021\n      0.85\n    \n    \n      285\n      전남\n      2021\n      1.02\n    \n    \n      286\n      경북\n      2021\n      0.97\n    \n    \n      287\n      경남\n      2021\n      0.90\n    \n    \n      288\n      제주\n      2021\n      0.95\n    \n  \n\n289 rows × 3 columns\n\n\n\n\ndf2 = _df2.drop(17)\\\n.melt(id_vars='지역/연도[6]')\\\n.assign(value = lambda df: list(map(lambda x: None if x=='-' else float(x), df.value)))\\\n.set_axis(['지역','연도','출생아수'],axis=1)\ndf2\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns"
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html#시각화i-전국-출생아수-시각화",
    "href": "posts/2022-11-16-11wk-2.html#시각화i-전국-출생아수-시각화",
    "title": "11wk-2",
    "section": "시각화I: 전국 출생아수 시각화",
    "text": "시각화I: 전국 출생아수 시각화\n\ndf2.groupby(['연도'])\\\n.agg({'출생아수':np.sum})\\\n.reset_index()\\\n.plot(x='연도',y='출생아수',backend='plotly')\n\n\n                                                \n\n\n\n일괄적으로 감소하는 느낌은 없음"
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html#시각화ii-시도별-출생아수-시각화",
    "href": "posts/2022-11-16-11wk-2.html#시각화ii-시도별-출생아수-시각화",
    "title": "11wk-2",
    "section": "시각화II: 시도별 출생아수 시각화",
    "text": "시각화II: 시도별 출생아수 시각화\n- 시각화예시1\n\ndf2.plot.line(backend='plotly', x='연도',y='출생아수',color='지역')\n\n\n                                                \n\n\n\n서울과 경기가 특이함\n\n- 시각화예시2\n\ndf2.plot.area(backend='plotly',x='연도',y='출생아수',color='지역')\n\n\n                                                \n\n\n\nareaplot의 최상단의 선: 전국출생아수 시각화와 같음 (일괄적으로 감소하는 느낌은 별로 없음, 그 이유를 살펴보니 서울과 경기지역 떄문임)\nareaplot의 장점: 전국출생아수를 년도별로 시각화 하는 느낌 + 각 연도를 도시별로 분해하여 해석하는 느낌"
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html#시각화iii-시도별-출산율-시각화",
    "href": "posts/2022-11-16-11wk-2.html#시각화iii-시도별-출산율-시각화",
    "title": "11wk-2",
    "section": "시각화III: 시도별 출산율 시각화",
    "text": "시각화III: 시도별 출산율 시각화\n\ndf1.plot.line(backend='plotly',x='연도',y='출산율',color='지역')\n\n\n                                                \n\n\n\n상식과 일치하는 정상적인 플랏 (출산율이 2012년 이후로 꺽이는 느낌이 든다)\n여기서는 서울/경기가 정상인듯 보인다.\n\n\n출산율의 경우 합계출산율이 크게 의미가 없으므로 areaplot은 생략한다."
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html#해석",
    "href": "posts/2022-11-16-11wk-2.html#해석",
    "title": "11wk-2",
    "section": "해석",
    "text": "해석\n- 이상한점: 서울/경기지역에서 특정연도의 출생아수가 매우 낮음. 그런데 서울/경기지역의 출산율은 모든 년도에서 고른값을 가짐.\n- 해석: 데이터가 이상하다.. // 위키를 살펴보니 오타가 있음!!"
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html#데이터의-수정-1-df2-상태에서-수정",
    "href": "posts/2022-11-16-11wk-2.html#데이터의-수정-1-df2-상태에서-수정",
    "title": "11wk-2",
    "section": "데이터의 수정 (1): df2 상태에서 수정",
    "text": "데이터의 수정 (1): df2 상태에서 수정\n- df2의 수정\n\ndf2.sort_values(\"출생아수\")[:10]\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      62\n      충남\n      2013\n      18.628\n    \n    \n      11\n      충남\n      2010\n      20.242\n    \n    \n      28\n      충남\n      2011\n      20.398\n    \n    \n      45\n      충남\n      2012\n      20.448\n    \n    \n      153\n      서울\n      2019\n      53.673\n    \n    \n      102\n      서울\n      2016\n      75.536\n    \n    \n      161\n      경기\n      2019\n      83.198\n    \n    \n      76\n      경기\n      2014\n      112.169\n    \n    \n      41\n      세종\n      2012\n      1054.000\n    \n    \n      58\n      세종\n      2013\n      1111.000\n    \n  \n\n\n\n\n- 오타로 예상되는 서울/경기/충남 이외의 가장 작은 값은 2012년 세종시인데, 이 값이 1054로 1000보다 크다.\n\n출생아수 < 1000 이면 출생아수 * 1000 을 수행하는 함수를 구현하자.\n\n\ndf2.assign(출생아수= list(map(lambda x: x*1000 if x<1000 else x, df2.출생아수)))\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns\n\n\n\n- 잘 변환되었는지 확인하기 위한 시각화\n\ndf2.assign(출생아수= list(map(lambda x: x*1000 if x<1000 else x, df2.출생아수)))\\\n.plot.area(x='연도',y='출생아수',color='지역',backend='plotly')\n\n\n                                                \n\n\n\n상식적인 결과: 전체출산율이 점점 낮아지고 있고 항목별로 살펴보아도 모든 도시의 출생아수가 점차 낮아지고 있음"
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html#데이터의-수정-2-_df2-상태에서-수정",
    "href": "posts/2022-11-16-11wk-2.html#데이터의-수정-2-_df2-상태에서-수정",
    "title": "11wk-2",
    "section": "데이터의 수정 (2): _df2 상태에서 수정",
    "text": "데이터의 수정 (2): _df2 상태에서 수정\n- applymap\n\n_df2.set_index('지역/연도[6]') # applymap을 쓰기 위해서 임시로 지역/연도[6]을 인덱스로만듬 \n\n\n\n\n\n  \n    \n      \n      2010\n      2011\n      2012\n      2013\n      2014\n      2015\n      2016\n      2017\n      2018\n      2019\n      2020\n      2021\n    \n    \n      지역/연도[6]\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      서울\n      93266\n      91526\n      93914.000\n      84066.000\n      83711.000\n      83005\n      75.536\n      65389\n      58074\n      53.673\n      47400\n      45531\n    \n    \n      부산\n      27415\n      27759\n      28673.000\n      25831.000\n      26190.000\n      26645\n      24906.000\n      21480\n      19152\n      17049.000\n      15100\n      14446\n    \n    \n      대구\n      20557\n      20758\n      21472.000\n      19340.000\n      19361.000\n      19438\n      18298.000\n      15946\n      14400\n      13233.000\n      11200\n      10661\n    \n    \n      인천\n      25752\n      20758\n      21472.000\n      25560.000\n      25786.000\n      25491\n      23609.000\n      20445\n      20087\n      18522.000\n      16000\n      14947\n    \n    \n      광주\n      13979\n      13916\n      14392.000\n      12729.000\n      12729.000\n      12441\n      11580.000\n      10120\n      9105\n      8364.000\n      7300\n      7956\n    \n    \n      대전\n      14314\n      14808\n      15279.000\n      14099.000\n      13962.000\n      13774\n      12436.000\n      10851\n      9337\n      8410.000\n      7500\n      7414\n    \n    \n      울산\n      11432\n      11542\n      12160.000\n      11330.000\n      11556.000\n      11732\n      10910.000\n      9381\n      8149\n      7539.000\n      6600\n      6127\n    \n    \n      세종\n      -\n      -\n      1054.000\n      1111.000\n      1344.000\n      2708\n      3297.000\n      3504\n      3703\n      3819.000\n      3500\n      3570\n    \n    \n      경기\n      121753\n      122027\n      124746.000\n      112129.000\n      112.169\n      113495\n      105643.000\n      94088\n      83198\n      83.198\n      77800\n      76139\n    \n    \n      강원\n      12477\n      12408\n      12426.000\n      10980.000\n      10662.000\n      10929\n      10058.000\n      9958\n      8351\n      8283.000\n      7800\n      7357\n    \n    \n      충북\n      14670\n      14804\n      15139.000\n      13658.000\n      13366.000\n      13563\n      12742.000\n      11394\n      10586\n      9333.000\n      8600\n      8190\n    \n    \n      충남\n      20.242\n      20.398\n      20.448\n      18.628\n      18200.000\n      18604\n      17302.000\n      15670\n      14380\n      13228.000\n      11900\n      10984\n    \n    \n      전북\n      16100\n      16175\n      16238.000\n      14555.000\n      14231.000\n      14087\n      12698.000\n      11348\n      10001\n      8971.000\n      8200\n      7745\n    \n    \n      전남\n      16654\n      16612\n      16990.000\n      15401.000\n      14817.000\n      15061\n      13980.000\n      12354\n      11238\n      10832.000\n      9700\n      8430\n    \n    \n      경북\n      23700\n      24250\n      24635.000\n      22206.000\n      22062.000\n      22310\n      20616.000\n      17957\n      16079\n      14472.000\n      12900\n      12045\n    \n    \n      경남\n      32203\n      32536\n      33211.000\n      29504.000\n      29763.000\n      29537\n      27138.000\n      23849\n      21224\n      19250.000\n      16800\n      15562\n    \n    \n      제주\n      5657\n      5628\n      5992.000\n      5328.000\n      5526.000\n      5600\n      5494.000\n      5037\n      4781\n      4500.000\n      4000\n      3728\n    \n    \n      전국\n      470171\n      471265\n      484550.000\n      436455.000\n      435435.000\n      438420\n      406243.000\n      357771\n      326822\n      302676.000\n      272400\n      260562\n    \n  \n\n\n\n\n- 방법1\n\n_df2.set_index('지역/연도[6]')\\\n.applymap(lambda x: None if x == '-' else float(x))\\\n.applymap(lambda x: x*1000 if x<1000 else x)\\\n.drop('전국')\\\n.stack().reset_index()\n\n\n\n\n\n  \n    \n      \n      지역/연도[6]\n      level_1\n      0\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      서울\n      2011\n      91526.0\n    \n    \n      2\n      서울\n      2012\n      93914.0\n    \n    \n      3\n      서울\n      2013\n      84066.0\n    \n    \n      4\n      서울\n      2014\n      83711.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      197\n      제주\n      2017\n      5037.0\n    \n    \n      198\n      제주\n      2018\n      4781.0\n    \n    \n      199\n      제주\n      2019\n      4500.0\n    \n    \n      200\n      제주\n      2020\n      4000.0\n    \n    \n      201\n      제주\n      2021\n      3728.0\n    \n  \n\n202 rows × 3 columns\n\n\n\n- 방법2\n\ndf2 = _df2.set_index('지역/연도[6]')\\\n.applymap(lambda x: None if x == '-' else float(x))\\\n.applymap(lambda x: x*1000 if x<1000 else x)\\\n.drop('전국')\\\n.reset_index()\\\n.melt(id_vars='지역/연도[6]')\\\n.set_axis(['지역','연도','출생아수'],axis=1)\ndf2\n\n\n\n\n\n  \n    \n      \n      지역\n      연도\n      출생아수\n    \n  \n  \n    \n      0\n      서울\n      2010\n      93266.0\n    \n    \n      1\n      부산\n      2010\n      27415.0\n    \n    \n      2\n      대구\n      2010\n      20557.0\n    \n    \n      3\n      인천\n      2010\n      25752.0\n    \n    \n      4\n      광주\n      2010\n      13979.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      199\n      전북\n      2021\n      7745.0\n    \n    \n      200\n      전남\n      2021\n      8430.0\n    \n    \n      201\n      경북\n      2021\n      12045.0\n    \n    \n      202\n      경남\n      2021\n      15562.0\n    \n    \n      203\n      제주\n      2021\n      3728.0\n    \n  \n\n204 rows × 3 columns\n\n\n\n\ndf2.plot.area(backend='plotly',x='연도',y='출생아수',color='지역')"
  },
  {
    "objectID": "posts/2022-11-16-11wk-2.html#숙제",
    "href": "posts/2022-11-16-11wk-2.html#숙제",
    "title": "11wk-2",
    "section": "숙제",
    "text": "숙제\n아래와 같은 통계량을 구하라.\n\n\\(서울_{2010} = \\frac{\\text{2010년 서울의 출생자 수}}{\\text{2010년 출생자수}}, \\dots, 서울_{2021} = \\frac{\\text{2021년 서울의 출생자 수}}{\\text{2021년 출생자수}}\\)\n\n\n참고로 계산결과는 [0.198, 0.196, 0.196, 0.193, 0.192, 0.189, 0.186, 0.182, 0.18, 0.177, 0.174, 0.175] 와 같다.\n\nlineplot을 이용하여 아래와 같이 시각화 하라.\n(풀이)\n\ndf2.groupby('연도')[['출생아수']].sum().reset_index().rename({'출생아수':'년도별출생아수합'},axis=1).\\\nmerge(df2).eval('ratio = 출생아수/년도별출생아수합').query('지역==\"서울\"').\\\nplot.line(x='연도',y='ratio',backend='plotly')"
  },
  {
    "objectID": "posts/2022-11-30-13wk-2.html",
    "href": "posts/2022-11-30-13wk-2.html",
    "title": "13wk-2",
    "section": "",
    "text": "Choropleth– plotly 공식예제, 한국의 인구수"
  },
  {
    "objectID": "posts/2022-11-30-13wk-2.html#data",
    "href": "posts/2022-11-30-13wk-2.html#data",
    "title": "13wk-2",
    "section": "data",
    "text": "data\n\ndf = px.data.election()\ngeojson = px.data.election_geojson()\n\n- df는 어떻게 생겼을까?\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      district\n      Coderre\n      Bergeron\n      Joly\n      total\n      winner\n      result\n      district_id\n    \n  \n  \n    \n      0\n      101-Bois-de-Liesse\n      2481\n      1829\n      3024\n      7334\n      Joly\n      plurality\n      101\n    \n    \n      1\n      102-Cap-Saint-Jacques\n      2525\n      1163\n      2675\n      6363\n      Joly\n      plurality\n      102\n    \n    \n      2\n      11-Sault-au-Récollet\n      3348\n      2770\n      2532\n      8650\n      Coderre\n      plurality\n      11\n    \n    \n      3\n      111-Mile-End\n      1734\n      4782\n      2514\n      9030\n      Bergeron\n      majority\n      111\n    \n    \n      4\n      112-DeLorimier\n      1770\n      5933\n      3044\n      10747\n      Bergeron\n      majority\n      112\n    \n  \n\n\n\n\n- geojson은 어떻게 생겼을까?\n\ngeojson.keys()\n\ndict_keys(['type', 'features'])\n\n\n\ngeojson['features'][0].keys()\n\ndict_keys(['type', 'geometry', 'properties', 'id'])\n\n\n\n[geojson['features'][i]['properties'] for i in range(5)]\n\n[{'district': '11-Sault-au-Récollet'},\n {'district': '12-Saint-Sulpice'},\n {'district': '13-Ahuntsic'},\n {'district': '14-Bordeaux-Cartierville'},\n {'district': '21-Ouest'}]\n\n\n\n[geojson['features'][i]['id'] for i in range(5)]\n\n['11', '12', '13', '14', '21']"
  },
  {
    "objectID": "posts/2022-11-30-13wk-2.html#시각화예시1-공식예제-코드-그대로",
    "href": "posts/2022-11-30-13wk-2.html#시각화예시1-공식예제-코드-그대로",
    "title": "13wk-2",
    "section": "시각화예시1: 공식예제 코드 그대로",
    "text": "시각화예시1: 공식예제 코드 그대로\n\nfig = px.choropleth_mapbox(data_frame= df, \n                           geojson=geojson, \n                           color=\"Bergeron\",\n                           locations=\"district\", \n                           featureidkey=\"properties.district\",\n                           center={\"lat\": 45.5517, \"lon\": -73.7073},\n                           mapbox_style=\"carto-positron\",\n                           zoom=9)\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})"
  },
  {
    "objectID": "posts/2022-11-30-13wk-2.html#시각화예시2-key를-변경",
    "href": "posts/2022-11-30-13wk-2.html#시각화예시2-key를-변경",
    "title": "13wk-2",
    "section": "시각화예시2: key를 변경",
    "text": "시각화예시2: key를 변경\n\nfig = px.choropleth_mapbox(data_frame= df, \n                           geojson=geojson, \n                           color=\"Bergeron\",\n                           locations=\"district_id\", \n                           featureidkey=\"id\",\n                           center={\"lat\": 45.5517, \"lon\": -73.7073},\n                           mapbox_style=\"carto-positron\",\n                           zoom=9)\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})"
  },
  {
    "objectID": "posts/2022-09-21-3wk-2.html",
    "href": "posts/2022-09-21-3wk-2.html",
    "title": "03wk-2",
    "section": "",
    "text": "산점도 응용예제 1,2,3 (표본상관계수, 앤스콤플랏, 무상관)"
  },
  {
    "objectID": "posts/2022-09-21-3wk-2.html#예제소개",
    "href": "posts/2022-09-21-3wk-2.html#예제소개",
    "title": "03wk-2",
    "section": "예제소개",
    "text": "예제소개\n- 아래와 같은 자료를 수집하였다고 하자.\n\n몸무게 = [44,48,49,58,62,68,69,70,76,79]\n키 = [159,160,162,165,167,162,165,175,165,172]\n\n\nx=[44,48,49,58,62,68,69,70,76,79]\ny=[159,160,162,165,167,162,165,175,165,172]\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n키가 큰 사람일수록 몸무게도 많이 나간다. (반대도 성립)\n키와 몸무게는 관계가 있어보인다. (정비례)\n\n- 얼만큼 정비례인지?\n\n이 질문에 대답하기 위해서는 상관계수의 개념을 알아야 한다.\n상관계수는 산점도에서 가장 중요한 개념중 하나."
  },
  {
    "objectID": "posts/2022-09-21-3wk-2.html#상관계수의-정의",
    "href": "posts/2022-09-21-3wk-2.html#상관계수의-정의",
    "title": "03wk-2",
    "section": "상관계수의 정의",
    "text": "상관계수의 정의\n- (표본)상관계수\n\\[r=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}) }{\\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\sum_{i=1}^{n}(y_i-\\bar{y})^2 }}=\\sum_{i=1}^{n}\\tilde{x}_i\\tilde{y}_i \\]\n\n단, \\(\\tilde{x}_i=\\frac{(x_i-\\bar{x})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}}\\), \\(\\tilde{y}_i=\\frac{(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\)\n\n* 표본의 의미\n평균과 표본평균\n\nnp.random.seed(43052)\nx = np.random.randn(10)\nx\n\narray([ 0.38342049,  1.0841745 ,  1.14277825,  0.30789368,  0.23778744,\n        0.35595116, -1.66307542, -1.38277318, -1.92684484, -1.4862163 ])\n\n\n\nx는 의 각 원소는 모두 평균이 0인 정규분포에서 추출했다고 표현\n\n\nnp.mean(x)\n\n0.09434107867212947\n\n\n\n\\({\\tt x}=(x_1,\\dots, x_{10})\\)의 표본평균은 \\({\\bar x}=0.09434107867212947\\) 라고 표현"
  },
  {
    "objectID": "posts/2022-09-21-3wk-2.html#상관계수의-의미",
    "href": "posts/2022-09-21-3wk-2.html#상관계수의-의미",
    "title": "03wk-2",
    "section": "상관계수의 의미",
    "text": "상관계수의 의미\n- 의미?\n\nx=np.array(x)\ny=np.array(y)\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(9,4)) \n\n\n\n\n\nax1.plot(x,y,'o')\nax2.plot(x-np.mean(x),y-np.mean(y),'o')\n\n\nfig\n\n\n\n\n- \\(\\tilde{x}_i\\)와 \\(\\tilde{y}_i\\)를 계산하기 위해서 \\(a=\\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}, b=\\sqrt{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}\\)를 계산하자.\n(방법1)\n\na=np.sqrt(np.sum((x-np.mean(x))**2))\nb=np.sqrt(np.sum((y-np.mean(y))**2))\na,b\n\n(2.8842557251032446, 15.218409903797438)\n\n\n\n해석: \\(a>b\\) 이므로 \\(\\{x_i\\}\\)들이 \\(\\{y_i\\}\\)들 보다 좀 더 퍼져있다. (=평균근처에 몰려있지 않다)\n\n(방법2)\n- 사실 \\(a,b\\)는 아래와 같이 계산할 수 있다.\n\\(a=\\sqrt{n}\\times{\\tt np.std(x)}\\)\n\\(b=\\sqrt{n}\\times{\\tt np.std(y)}\\)\n\nn=len(x)\nnp.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y)\n\n(2.8842557251032446, 15.21840990379744)\n\n\n\n\\({\\tt np.std(x)}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\)\n\\({\\tt np.std(y)}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\bar{y})^2}\\)\n\n\nnote: \\({\\tt np.std(x,ddof=1)}=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\)\n\n- 이제 \\((\\tilde{x}_i,\\tilde{y}_i)\\)를 ax3에 그려보자.\n\nxx= (x-np.mean(x))/a\nyy= (y-np.mean(y))/b\nax3.plot(xx,yy,'o')\n\n\nfig\n\n\n\n\n질문: \\(r\\)의 값이 양수인가? 음수인가?\n- plotly 사용하여 \\((\\tilde{x}_i,\\tilde{y}_i)\\)를 그려보자.\n\nfig=px.scatter(x=xx, y=yy)\nHTML(fig.to_html(include_plotlyjs='cdn',include_mathjax=False))\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\\(\\tilde{x}_i\\), \\(\\tilde{y}_i\\) 를 곱한값이 양수인것과 음수인것을 체크해보자.\n양수인쪽이 많은지 음수인쪽이 많은지 생각해보자.\n\\(r=\\sum_{i=1}^{n}\\tilde{x}_i \\tilde{y}_i\\) 의 부호는?"
  },
  {
    "objectID": "posts/2022-09-21-3wk-2.html#그림을-보고-상관계수의-부호를-알아내는-방법",
    "href": "posts/2022-09-21-3wk-2.html#그림을-보고-상관계수의-부호를-알아내는-방법",
    "title": "03wk-2",
    "section": "그림을 보고 상관계수의 부호를 알아내는 방법",
    "text": "그림을 보고 상관계수의 부호를 알아내는 방법\n- \\((x_i,y_i)\\)의 산점도를 보고 \\((\\tilde{x}_i, \\tilde{y}_i)\\) 의 산점도를 상상 \\(\\to\\) 1,3 분면에 점들이 많으면 양수, 2,4 분면에 점들이 많으면 음수"
  },
  {
    "objectID": "posts/2022-09-21-3wk-2.html#그림을-보고-상관계수의-절대값을-알아내는-방법",
    "href": "posts/2022-09-21-3wk-2.html#그림을-보고-상관계수의-절대값을-알아내는-방법",
    "title": "03wk-2",
    "section": "그림을 보고 상관계수의 절대값을 알아내는 방법",
    "text": "그림을 보고 상관계수의 절대값을 알아내는 방법\n- 이해를 위한 예시\n\nx=np.arange(0,10,0.1)\ny1=x+np.random.normal(loc=0,scale=1.0,size=len(x))\ny2=x+np.random.normal(loc=0,scale=7.0,size=len(x))\n\n\nplt.plot(x,y1,'o')\nplt.plot(x,y2,'x')\n\n\n\n\n각 데이터셋의 표준상관계수를 각각 \\(r_1\\)(파란색), \\(r_2\\)(주황색)라고 하자.\n(1) \\(r_1\\), \\(r_2\\)의 부호는 양수인가? 음수인가? –> 양수\n(2) \\(r_1,r_2\\)의 값중 어떠한 값이 더 절대값이 큰가? –> 잘모르겠음. 따져보자.\n\ndef tilde(x):\n    n= len(x)\n    return (x-np.mean(x)) / (np.std(x)*np.sqrt(n))    \n\n\nxx= tilde(x)\nyy1= tilde(y1)\nyy2= tilde(y2)\n\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(x,y1,'o')\nax[0].plot(x,y2,'x')\nax[1].plot(x,yy1,'o')\nax[1].plot(x,yy2,'x')\n\n\n\n\n\nr1, r2 = sum(xx*yy1), sum(xx*yy2)\nr1, r2\n\n(0.9473089524539402, 0.4445681691326099)\n\n\n- 그림을 보고 상관계수의 절대값을 알아내는 방법!: 직선근처에 몰려있으면 절대값이 커요!"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html",
    "href": "posts/2022-10-03-5wk-1.html",
    "title": "05wk-1",
    "section": "",
    "text": "seaborn(2)–scatterplot, mpl미세먼지팁(2)"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#plt-복습",
    "href": "posts/2022-10-03-5wk-1.html#plt-복습",
    "title": "05wk-1",
    "section": "plt 복습",
    "text": "plt 복습\n\nplt.plot(x1,y1,'o')\nplt.plot(x2,y2,'o')"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#sns-array",
    "href": "posts/2022-10-03-5wk-1.html#sns-array",
    "title": "05wk-1",
    "section": "sns: array",
    "text": "sns: array\n\nsns.scatterplot(data=None,x=x1,y=y1)\nsns.scatterplot(data=None,x=x2,y=y2)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#sns-wide-df",
    "href": "posts/2022-10-03-5wk-1.html#sns-wide-df",
    "title": "05wk-1",
    "section": "sns: wide df",
    "text": "sns: wide df\n\nsns.scatterplot(data=pd.DataFrame({'x':x1,'y':y1}),x='x',y='y')\nsns.scatterplot(data=pd.DataFrame({'x':x2,'y':y2}),x='x',y='y')\n#sns.scatterplot(data=None,x=x2,y=y2)\n\n<AxesSubplot:xlabel='x', ylabel='y'>\n\n\n\n\n\n\n억지로 그리긴 했는데 이 경우는 wide하게 만든 df는 별로 경쟁력이 없음"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#sns-long-df",
    "href": "posts/2022-10-03-5wk-1.html#sns-long-df",
    "title": "05wk-1",
    "section": "sns: long df",
    "text": "sns: long df\n\nx= np.concatenate([x1,x2])\ny= np.concatenate([y1,y2])\ncat = ['x1']*len(x1) + ['x2']*len(x2)\ndf2 = pd.DataFrame({'x':x,'y':y,'cat':cat})\ndf2\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      cat\n    \n  \n  \n    \n      0\n      2.023919\n      -0.400176\n      x1\n    \n    \n      1\n      1.229622\n      -1.763752\n      x1\n    \n    \n      2\n      -0.413211\n      2.293004\n      x1\n    \n    \n      3\n      -1.343073\n      0.404232\n      x1\n    \n    \n      4\n      1.062845\n      0.030775\n      x1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      2.226805\n      3.683857\n      x2\n    \n    \n      1996\n      2.768263\n      2.678292\n      x2\n    \n    \n      1997\n      2.525295\n      2.815478\n      x2\n    \n    \n      1998\n      1.750193\n      2.289812\n      x2\n    \n    \n      1999\n      1.153290\n      2.095922\n      x2\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df2,x='x',y='y',hue='cat') \n\n<AxesSubplot:xlabel='x', ylabel='y'>"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#예제1",
    "href": "posts/2022-10-03-5wk-1.html#예제1",
    "title": "05wk-1",
    "section": "예제1",
    "text": "예제1\n\nfig,ax = plt.subplots(1,3,figsize=(12,4))\nax[0].plot([1,2,4,3],'--o')\nsns.scatterplot(x=x1,y=y1,ax=ax[1])\nsns.scatterplot(x=x1,y=y1,ax=ax[2])\nsns.scatterplot(x=x2,y=y2,ax=ax[2])\nax[2].plot([1,2,4,3],'-r',lw=5)"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#예제2",
    "href": "posts/2022-10-03-5wk-1.html#예제2",
    "title": "05wk-1",
    "section": "예제2",
    "text": "예제2\n\nimport cv2\n\n\n!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg \nimg = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg',0)\n!rm Unequalized_Hawkes_Bay_NZ.jpg \n\n--2022-10-05 16:33:56--  https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nResolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 110895 (108K) [image/jpeg]\nSaving to: ‘Unequalized_Hawkes_Bay_NZ.jpg’\n\nUnequalized_Hawkes_ 100%[===================>] 108.30K   548KB/s    in 0.2s    \n\n2022-10-05 16:33:57 (548 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg’ saved [110895/110895]\n\n\n\n\nimg2 = cv2.equalizeHist(img)\n\n\nimg.reshape(-1)\n\narray([127, 145, 149, ..., 146, 145, 144], dtype=uint8)\n\n\n\nfig,ax = plt.subplots(2,2,figsize=(10,5))\nax[0,0].imshow(img,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img.reshape(-1),ax=ax[0,1],bins=15,lw=0,kde=True,color='C1')\nax[0,1].set_xlim(0,255)\nax[1,0].imshow(img2,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img2.reshape(-1),ax=ax[1,1],bins=15,lw=0,kde=True,color='C1')\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- seaborn: figure-level vs axes-level 의 개념\nref: https://seaborn.pydata.org/tutorial/function_overview.html#figure-level-vs-axes-level-functions"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#축-간격조정",
    "href": "posts/2022-10-03-5wk-1.html#축-간격조정",
    "title": "05wk-1",
    "section": "축 간격조정",
    "text": "축 간격조정\n\nimport matplotlib as mpl\n\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(3)) # 큰 눈금간격을 3으로\nax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(1)) # 작은 눈금간격을 1로"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#축-삭제",
    "href": "posts/2022-10-03-5wk-1.html#축-삭제",
    "title": "05wk-1",
    "section": "축 삭제",
    "text": "축 삭제\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.NullLocator()) # x축 눈금삭제\nax.yaxis.set_major_locator(mpl.ticker.NullLocator()) # y축 눈금삭제"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#축-범위조정",
    "href": "posts/2022-10-03-5wk-1.html#축-범위조정",
    "title": "05wk-1",
    "section": "축 범위조정",
    "text": "축 범위조정\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.set_ylim(-1,2) \nax.set_xlim(-5,35)\n#plt.ylim(-1,2)\n#plt.xlim(-5,35)\n\n(-5.0, 35.0)"
  },
  {
    "objectID": "posts/2022-10-03-5wk-1.html#gcf-gca",
    "href": "posts/2022-10-03-5wk-1.html#gcf-gca",
    "title": "05wk-1",
    "section": "gcf, gca",
    "text": "gcf, gca\n- gcf\n\nplt.plot([1,2,3,2])\nfig = plt.gcf()\n\n\n\n\n\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')\n\n\n\nfig\n\n\n\n\n- gca\n\nfig\n\n\n\n\n\nax = fig.gca()\n\n\nax.set_title('title') \nfig"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html",
    "href": "posts/2022-09-19-3wk-1.html",
    "title": "03wk-1",
    "section": "",
    "text": "라인플랏, 산점도, 여러 그림 그리기, fig와 axes의 이해"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#기본플랏",
    "href": "posts/2022-09-19-3wk-1.html#기본플랏",
    "title": "03wk-1",
    "section": "기본플랏",
    "text": "기본플랏\n- 예시1\n\nx=[1,2,3,4]\ny=[1,2,4,3] \n\n\nplt.plot(x,y)"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#모양변경",
    "href": "posts/2022-09-19-3wk-1.html#모양변경",
    "title": "03wk-1",
    "section": "모양변경",
    "text": "모양변경\n- 예시1\n\nplt.plot(x,y,'--')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,':')\n\n\n\n\n- 예시3\n\nplt.plot(x,y,'-.')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#색상변경",
    "href": "posts/2022-09-19-3wk-1.html#색상변경",
    "title": "03wk-1",
    "section": "색상변경",
    "text": "색상변경\n- 예시1\n\nplt.plot(x,y,'r')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,'k')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#모양-색상변경",
    "href": "posts/2022-09-19-3wk-1.html#모양-색상변경",
    "title": "03wk-1",
    "section": "모양 + 색상변경",
    "text": "모양 + 색상변경\n- 예시1\n\nplt.plot(x,y,'--r')\n\n\n\n\n- 예시2: 순서변경 가능\n\nplt.plot(x,y,'r--')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#원리",
    "href": "posts/2022-09-19-3wk-1.html#원리",
    "title": "03wk-1",
    "section": "원리?",
    "text": "원리?\n- r--등의 옵션은 Markers + Line Styles + Colors 의 조합으로 표현가능\nref: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n\n--r: 점선(dashed)스타일 + 빨간색\nr--: 빨간색 + 점선(dashed)스타일\n:k: 점선(dotted)스타일 + 검은색\nk:: 검은색 + 점선(dotted)스타일\n\n- 우선 Marker를 무시하면 Line Styles + Color로 표현가능한 조합은 \\(4\\times 8=32\\) 개\n(Line Styles) 모두 4개\n\n\n\ncharacter\ndescription\n\n\n\n\n‘-’\nsolid line style\n\n\n‘–’\ndashed line style\n\n\n‘-.’\ndash-dot line style\n\n\n‘:’\ndotted line style\n\n\n\n(Color) 모두 8개\n\n\n\ncharacter\ncolor\n\n\n\n\n‘b’\nblue\n\n\n‘g’\ngreen\n\n\n‘r’\nred\n\n\n‘c’\ncyan\n\n\n‘m’\nmagenta\n\n\n‘y’\nyellow\n\n\n‘k’\nblack\n\n\n‘w’\nwhite\n\n\n\n- 예시1\n\nplt.plot(x,y,'--m')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,'-.c')\n\n\n\n\n- 예시3: line style + color 조합으로 사용하든 color + line style 조합으로 사용하든 상관없음\n\nplt.plot(x,y,'-.c')\n\n\n\n\n\nplt.plot(x,y,'c-.')\n\n\n\n\n- 예시4: line style을 중복으로 사용하거나 color를 중복으로 쓸 수 는 없다.\n\nplt.plot(x,y,'--:')\n\nValueError: Illegal format string \"--:\"; two linestyle symbols\n\n\n\n\n\n\nplt.plot(x,y,'rb')\n\nValueError: Illegal format string \"rb\"; two color symbols\n\n\n\n\n\n- 예시5: 색이 사실 8개만 있는건 아니다.\nref: https://matplotlib.org/2.0.2/examples/color/named_colors.html\n\nplt.plot(x,y,'--',color='lime')\n\n\n\n\n- 예시6: 색을 바꾸려면 Hex코드를 밖아 넣는 방법이 젤 깔끔함\nref: https://htmlcolorcodes.com/\n\nplt.plot(x,y,color='#277E41') \n\n\n\n\n- 예시7: 당연히 라인스타일도 4개만 있진 않겠지\nref: https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html\n\nplt.plot(x,y,linestyle='dashed')\n\n\n\n\n\nplt.plot(x,y,linestyle=(0, (20, 5)))"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#원리-1",
    "href": "posts/2022-09-19-3wk-1.html#원리-1",
    "title": "03wk-1",
    "section": "원리",
    "text": "원리\n- 그냥 마커를 설정하면 끝!\nref: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n\n\n\ncharacter\ndescription\n\n\n\n\n‘.’\npoint marker\n\n\n‘,’\npixel marker\n\n\n‘o’\ncircle marker\n\n\n‘v’\ntriangle_down marker\n\n\n‘^’\ntriangle_up marker\n\n\n‘<’\ntriangle_left marker\n\n\n‘>’\ntriangle_right marker\n\n\n‘1’\ntri_down marker\n\n\n‘2’\ntri_up marker\n\n\n‘3’\ntri_left marker\n\n\n‘4’\ntri_right marker\n\n\n‘8’\noctagon marker\n\n\n‘s’\nsquare marker\n\n\n‘p’\npentagon marker\n\n\n‘P’\nplus (filled) marker\n\n\n’*’\nstar marker\n\n\n‘h’\nhexagon1 marker\n\n\n‘H’\nhexagon2 marker\n\n\n‘+’\nplus marker\n\n\n‘x’\nx marker\n\n\n‘X’\nx (filled) marker\n\n\n‘D’\ndiamond marker\n\n\n‘d’\nthin_diamond marker\n\n\n‘|’\nvline marker\n\n\n’_’\nhline marker\n\n\n\n\nplt.plot(x,y,'o')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#기본플랏-1",
    "href": "posts/2022-09-19-3wk-1.html#기본플랏-1",
    "title": "03wk-1",
    "section": "기본플랏",
    "text": "기본플랏\n- 예시1\n\nplt.plot(x,y,'.')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,'x')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#색깔변경",
    "href": "posts/2022-09-19-3wk-1.html#색깔변경",
    "title": "03wk-1",
    "section": "색깔변경",
    "text": "색깔변경\n- 예시1\n\nplt.plot(x,y,'or')\n\n\n\n\n- 예시2\n\nplt.plot(x,y,'db')\n\n\n\n\n- 예시3\n\nplt.plot(x,y,'bx')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#dot-connected-plot",
    "href": "posts/2022-09-19-3wk-1.html#dot-connected-plot",
    "title": "03wk-1",
    "section": "dot-connected plot",
    "text": "dot-connected plot\n- 예시1: 마커와 라인스타일을 동시에 사용하면 dot-connected plot이 된다.\n\nplt.plot(x,y,'o-')\n\n\n\n\n- 예시2: 당연히 색도 적용가능함\n\nplt.plot(x,y,'o--r')\n\n\n\n\n- 예시3: 서로 순서를 바꿔도 상관없다.\n\nplt.plot(x,y,'ro--')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#겹쳐그리기",
    "href": "posts/2022-09-19-3wk-1.html#겹쳐그리기",
    "title": "03wk-1",
    "section": "겹쳐그리기",
    "text": "겹쳐그리기\n- 예시1\n\nx = np.arange(-5,5,0.1)\nϵ = np.random.randn(100) \ny = 2*x + ϵ\n\n\nplt.plot(x,y,'.b')\nplt.plot(x,2*x,'r')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#따로그리기-subplot-외우세요-이거",
    "href": "posts/2022-09-19-3wk-1.html#따로그리기-subplot-외우세요-이거",
    "title": "03wk-1",
    "section": "따로그리기 (subplot) // 외우세요 이거",
    "text": "따로그리기 (subplot) // 외우세요 이거\n- 예시1\n\nfig, axs = plt.subplots(2) \naxs[0].plot(x,y,'.b')\naxs[1].plot(x,2*x,'r')\n\n\n\n\n- 예시2\n\nfig, axs = plt.subplots(2,2)\naxs[0,0].plot(x,2*x,'--b')\naxs[0,1].plot(x,ϵ,'.r')\naxs[1,0].plot(x,y,'.r')\naxs[1,1].plot(x,y,'.r')\naxs[1,1].plot(x,2*x,'-b')"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#예제2-예제1의-응용",
    "href": "posts/2022-09-19-3wk-1.html#예제2-예제1의-응용",
    "title": "03wk-1",
    "section": "예제2: 예제1의 응용",
    "text": "예제2: 예제1의 응용\n- 예제1상황\n\nfig\n\n\n\n\n- 여기서 축을 하나 더 추가할거에요\n\nfig.axes\n\n[<Axes:>]\n\n\n\nfig.add_axes([1,1,1,1])\n\n<Axes:>\n\n\n\nfig.axes\n\n[<Axes:>, <Axes:>]\n\n\n\nfig\n\n\n\n\n\nax1,ax2 = fig.axes\n\n- ax2에 파란선으로 그림을 그리자.\n\nax2.plot([1,2,3,4],[1,2,4,3],'--ob')\n\n\nfig"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#예제3-더-응용-미니맵",
    "href": "posts/2022-09-19-3wk-1.html#예제3-더-응용-미니맵",
    "title": "03wk-1",
    "section": "예제3: 더 응용! (미니맵)",
    "text": "예제3: 더 응용! (미니맵)\n- 지금 상황\n\nfig\n\n\n\n\n- 액시즈를 하나 더 추가\n\nfig.add_axes([0.65,0.1,0.3,0.3])\n\n<Axes:>\n\n\n\nfig\n\n\n\n\n\nfig.axes[-1].plot([1,2,3,4],[1,2,4,3],'xr')\n\n\nfig"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#예제4-재해석1",
    "href": "posts/2022-09-19-3wk-1.html#예제4-재해석1",
    "title": "03wk-1",
    "section": "예제4: 재해석1",
    "text": "예제4: 재해석1\n(ver1)\n\nplt.plot([1,2,3,4],[1,2,4,3])\n\n\n\n\n(ver2)\nver1은 사실 아래가 연속적으로 실행된 축약구문임\nfig = plt.figure() \nfig.add_axes([?,?,?,?])\nax1 = fig.axes[0]\nax1.plot([1,2,3,4],[1,2,4,3])\nfig"
  },
  {
    "objectID": "posts/2022-09-19-3wk-1.html#예제5-재해석2",
    "href": "posts/2022-09-19-3wk-1.html#예제5-재해석2",
    "title": "03wk-1",
    "section": "예제5: 재해석2",
    "text": "예제5: 재해석2\n- 아래의 코드도 재해석하자.\n\nfig, axs = plt.subplots(2,2)\n\n\n\n\n\nfig, axs = plt.subplots(2,2)\naxs[0,0].plot([1,2,3,4],[1,2,4,3],'.')\naxs[0,1].plot([1,2,3,4],[1,2,4,3],'--r')\naxs[1,0].plot([1,2,3,4],[1,2,4,3],'o--')\naxs[1,1].plot([1,2,3,4],[1,2,4,3],'o--',color='lime')\n\n\n\n\n- fig, axs = plt.subplots(2,2)의 축약버전을 이해하면된다.\n(ver1)\n\nfig, axs = plt.subplots(2,2)\n\n\n\n\n(ver2)\nver1은 사실 아래의 축약!\nfig = plt.figure()\nfig.add_axes([?,?,?,?]) \nfig.add_axes([?,?,?,?])\nfig.add_axes([?,?,?,?])\nfig.add_axes([?,?,?,?])\nax1,ax2,ax3,ax4 = fig.axes\naxs = np.array(((ax1,ax2),(ax3,ax4)))\n(ver3)\nver1은 아래와 같이 표현할 수도 있다.\n\nfig = plt.figure()\naxs = fig.subplots(2,2)"
  },
  {
    "objectID": "posts/2022-12-19-final.html",
    "href": "posts/2022-12-19-final.html",
    "title": "final",
    "section": "",
    "text": "기말고사\n\n주의: 엑셀 등을 이용하여 자료를 전처리할 경우 부분점수 없이 0점 처리함\n\nimport pandas as pd \nimport json \nimport requests \nimport folium \nimport plotly.express as px\n\n\n1. 시군구별 에너지사용량 시각화 (30점)\n아래의 주소들에서 2018-2021의 시군구별 에너지 사용량에 대한 자료를 정리하고 물음에 답하라.\n# 2018\nhttps://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Seoul2018.csv\n...\nhttps://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Jeju-do2018.csv\n\n# 2019\nhttps://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Seoul2019.csv\n...\nhttps://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Jeju-do2019.csv\n\n# 2020\nhttps://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Seoul2020.csv\n...\nhttps://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Jeju-do2020.csv\n\n# 2021\nhttps://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Seoul2021.csv\n...\nhttps://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Jeju-do2021.csv\n\nhint1: 코드1, 코드2를 적절하게 응용하면 쉽게 데이터를 합칠 수 있음\n## 코드1 \n_district = [global_dict['features'][i]['properties']['name_eng'] for i in range(17)]\n_year = ['2018','2019','2020','2021']\nfor d in _district:\n    for y in _year: \n        print(d+y)\n        \n## 코드2\n_url = 'https://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/{}.csv' \npd.concat([pd.read_csv(_url.format(k)) for k in ['Seoul2018','Jeju-do2018']])\nhint2: 데이터프레임을 읽었을 때 ['에너지사용량(TOE)/지역난방']의 자료형이 통일되어 있지 않음을 유의하여 처리할 것.\n\npd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Gangwon-do2021.csv')['에너지사용량(TOE)/지역난방'].dtype\n\ndtype('int64')\n\n\n\npd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/main/posts/Energy/Seoul2021.csv')['에너지사용량(TOE)/지역난방'].dtype\n\ndtype('O')\n\n\nhint3: 아래의 코드를 이용하여 geojson 파일을 확보하고 문제를 풀 것\n\nglobal_dict = json.loads(requests.get('https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-provinces-2018-geo.json').text)\nlocal_dict = json.loads(requests.get('https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-municipalities-2018-geo.json').text)\n\nhint4: 필요하다면 아래의 코드를 활용할 것 (활용하지 않아도 무방함)\n\n_df = pd.DataFrame({'A':['서초구','강남구','송파구'],'B':['33,231','22,321',45123]})\n_df                   \n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      서초구\n      33,231\n    \n    \n      1\n      강남구\n      22,321\n    \n    \n      2\n      송파구\n      45123\n    \n  \n\n\n\n\n(할당)\n\n_df.assign(C=2018,D='Seoul')\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      서초구\n      33,231\n      2018\n      Seoul\n    \n    \n      1\n      강남구\n      22.321\n      2018\n      Seoul\n    \n    \n      2\n      송파구\n      45123\n      2018\n      Seoul\n    \n  \n\n\n\n\n(인덱스)\n\n_df.assign(C=2018,D='Seoul').set_index(['A','D'])\n\n\n\n\n\n  \n    \n      \n      \n      B\n      C\n    \n    \n      A\n      D\n      \n      \n    \n  \n  \n    \n      서초구\n      Seoul\n      33,231\n      2018\n    \n    \n      강남구\n      Seoul\n      22.321\n      2018\n    \n    \n      송파구\n      Seoul\n      45123\n      2018\n    \n  \n\n\n\n\n(applymap)\n\n_df.assign(C=2018,D='Seoul').set_index(['A','D']).applymap(lambda x: int(str(x).replace(',','')))\n\n\n\n\n\n  \n    \n      \n      \n      B\n      C\n    \n    \n      A\n      D\n      \n      \n    \n  \n  \n    \n      서초구\n      Seoul\n      33231\n      2018\n    \n    \n      강남구\n      Seoul\n      22321\n      2018\n    \n    \n      송파구\n      Seoul\n      45123\n      2018\n    \n  \n\n\n\n\n(1) 아래의 지역에 대한 4년간 전기 에너지 사용량의 총합을 구하고 folium을 이용하여 시각화 하라.\n\n[global_dict['features'][i]['properties']['name_eng'] for i in range(17)]\n\n['Seoul',\n 'Busan',\n 'Daegu',\n 'Incheon',\n 'Gwangju',\n 'Daejeon',\n 'Ulsan',\n 'Sejongsi',\n 'Gyeonggi-do',\n 'Gangwon-do',\n 'Chungcheongbuk-do',\n 'Chungcheongnam-do',\n 'Jeollabuk-do',\n 'Jeollanam-do',\n 'Gyeongsangbuk-do',\n 'Gyeongsangnam-do',\n 'Jeju-do']\n\n\n\n# 시각화예시\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nlocation = [36,128], zoom_start=7 로 설정\n\n\n(2) 서울의 4년간 전기에너지 사용량의 총합을 구하고 folium을 이용하여 구별로 시각화 하라.\nhint 아래의 리스트에서\n[local_dict['features'][i]['properties']['code'] for i in range(250)]\n11로 시작하는 원소들이 서울지역이다.\n\n# 시각화예시\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nlocation = [37.55,127], zoom_start=11 로 설정\n\n\n(3) 서울의 전기에너지 사용비율을 (연도별,구별)로 구하고 이를 plotly의 choropleth_mapbox를 이용하여 시각화 하라. (연도에 따라 choropleth map이 바뀌도록 시각화 할 것)\nhint1: 2020년의 관악구의 전기에너지 사용비율은 아래와 같이 계산한다.\n\\(\\frac{\\text{2020관악구의 ``에너지사용량(TOE)/전기''}}{\\text{2020관악구의 ``에너지사용량(TOE)/전기''}+\\text{2020관악구의 ``에너지사용량(TOE)/도시가스''}+\\text{2020년 관악구의 ``에너지사용량(TOE)/지역난방''}}\\)\n\n# 시각화예시\n\n\n                                                \n\n\nhint2: 아래의 코드 참고할 것.\nfig = px.choropleth_mapbox(data_frame=???,\n                           geojson=???, \n                           color=???,\n                           locations=???, \n                           featureidkey=???, \n                           center={\"lat\": 37.55, \"lon\": 126.95}, \n                           mapbox_style=\"carto-positron\", \n                           animation_frame=???, # 2028,2019,2020,2021와 같이 년도가 명시된 column의 이름을 쓸 것\n                           range_color=[0.31,0.56],\n                           height=800,\n                           zoom=10)\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html",
    "href": "posts/2022-10-17-7wk-1.html",
    "title": "07wk-1",
    "section": "",
    "text": "판다스– 인덱싱(2), 판다스–새로운열의할당(1), 아이스크림을 많이 먹으면 걸리는 병(1)"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#데이터",
    "href": "posts/2022-10-17-7wk-1.html#데이터",
    "title": "07wk-1",
    "section": "데이터",
    "text": "데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      ...\n      num_user_for_reviews\n      language\n      country\n      content_rating\n      budget\n      title_year\n      actor_2_facebook_likes\n      imdb_score\n      aspect_ratio\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      ...\n      3054.0\n      English\n      USA\n      PG-13\n      237000000.0\n      2009.0\n      936.0\n      7.9\n      1.78\n      33000\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      ...\n      1238.0\n      English\n      USA\n      PG-13\n      300000000.0\n      2007.0\n      5000.0\n      7.1\n      2.35\n      0\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n      148.0\n      0.0\n      161.0\n      Rory Kinnear\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      ...\n      994.0\n      English\n      UK\n      PG-13\n      245000000.0\n      2015.0\n      393.0\n      6.8\n      2.35\n      85000\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n      164.0\n      22000.0\n      23000.0\n      Christian Bale\n      27000.0\n      448130642.0\n      Action|Thriller\n      ...\n      2701.0\n      English\n      USA\n      PG-13\n      250000000.0\n      2012.0\n      23000.0\n      8.5\n      2.35\n      164000\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      NaN\n      131.0\n      NaN\n      Rob Walker\n      131.0\n      NaN\n      Documentary\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      12.0\n      7.1\n      NaN\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n      87.0\n      2.0\n      318.0\n      Daphne Zuniga\n      637.0\n      NaN\n      Comedy|Drama\n      ...\n      6.0\n      English\n      Canada\n      NaN\n      NaN\n      2013.0\n      470.0\n      7.7\n      NaN\n      84\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      43.0\n      NaN\n      319.0\n      Valorie Curry\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      ...\n      359.0\n      English\n      USA\n      TV-14\n      NaN\n      NaN\n      593.0\n      7.5\n      16.00\n      32000\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n      76.0\n      0.0\n      0.0\n      Maxwell Moody\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      ...\n      3.0\n      English\n      USA\n      NaN\n      1400.0\n      2013.0\n      0.0\n      6.3\n      NaN\n      16\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n      100.0\n      0.0\n      489.0\n      Daniel Henney\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      ...\n      9.0\n      English\n      USA\n      PG-13\n      NaN\n      2012.0\n      719.0\n      6.3\n      2.35\n      660\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n      90.0\n      16.0\n      16.0\n      Brian Herzlinger\n      86.0\n      85222.0\n      Documentary\n      ...\n      84.0\n      English\n      USA\n      PG\n      1100.0\n      2004.0\n      23.0\n      6.6\n      1.85\n      456\n    \n  \n\n4916 rows × 28 columns\n\n\n\n- 열의 이름을 출력하여 보자."
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#기본인덱싱-df-인덱싱공부-1단계-내용",
    "href": "posts/2022-10-17-7wk-1.html#기본인덱싱-df-인덱싱공부-1단계-내용",
    "title": "07wk-1",
    "section": "기본인덱싱 (df 인덱싱공부 1단계 내용)",
    "text": "기본인덱싱 (df 인덱싱공부 1단계 내용)\n- color ~ num_voted_user 를 뽑고 + aspect_ratio 도 추가적으로 뽑고싶다. -> loc으로는 못하겠어요..\n\ndf.loc[:,['color':'num_voted_users','aspect_ratio']]\n\nSyntaxError: invalid syntax (1210972629.py, line 1)\n\n\n- (팁) 복잡한 조건은 iloc으로 쓰는게 편할때가 있다. \\(\\to\\) 그런데 df.columns 변수들이 몇번인지 알아보기 힘듬 \\(\\to\\) 아래와 같이 하면 열의 이름을 인덱스와 함께 출력할 수 있음\n\npd.Series(df.columns)\n\n0                         color\n1                 director_name\n2        num_critic_for_reviews\n3                      duration\n4       director_facebook_likes\n5        actor_3_facebook_likes\n6                  actor_2_name\n7        actor_1_facebook_likes\n8                         gross\n9                        genres\n10                 actor_1_name\n11                  movie_title\n12              num_voted_users\n13    cast_total_facebook_likes\n14                 actor_3_name\n15         facenumber_in_poster\n16                plot_keywords\n17              movie_imdb_link\n18         num_user_for_reviews\n19                     language\n20                      country\n21               content_rating\n22                       budget\n23                   title_year\n24       actor_2_facebook_likes\n25                   imdb_score\n26                 aspect_ratio\n27         movie_facebook_likes\ndtype: object\n\n\n\nlist(range(13))+[26]\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26]\n\n\n\ndf.iloc[:,list(range(13))+[26]] \n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      actor_1_name\n      movie_title\n      num_voted_users\n      aspect_ratio\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      CCH Pounder\n      Avatar\n      886204\n      1.78\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      Johnny Depp\n      Pirates of the Caribbean: At World's End\n      471220\n      2.35\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n      148.0\n      0.0\n      161.0\n      Rory Kinnear\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      Christoph Waltz\n      Spectre\n      275868\n      2.35\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n      164.0\n      22000.0\n      23000.0\n      Christian Bale\n      27000.0\n      448130642.0\n      Action|Thriller\n      Tom Hardy\n      The Dark Knight Rises\n      1144337\n      2.35\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      NaN\n      131.0\n      NaN\n      Rob Walker\n      131.0\n      NaN\n      Documentary\n      Doug Walker\n      Star Wars: Episode VII - The Force Awakens\n      8\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n      87.0\n      2.0\n      318.0\n      Daphne Zuniga\n      637.0\n      NaN\n      Comedy|Drama\n      Eric Mabius\n      Signed Sealed Delivered\n      629\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      43.0\n      NaN\n      319.0\n      Valorie Curry\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      Natalie Zea\n      The Following\n      73839\n      16.00\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n      76.0\n      0.0\n      0.0\n      Maxwell Moody\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      Eva Boehnke\n      A Plague So Pleasant\n      38\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n      100.0\n      0.0\n      489.0\n      Daniel Henney\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      Alan Ruck\n      Shanghai Calling\n      1255\n      2.35\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n      90.0\n      16.0\n      16.0\n      Brian Herzlinger\n      86.0\n      85222.0\n      Documentary\n      John August\n      My Date with Drew\n      4285\n      1.85\n    \n  \n\n4916 rows × 14 columns"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#actor라는-단어가-포함된-column-선택",
    "href": "posts/2022-10-17-7wk-1.html#actor라는-단어가-포함된-column-선택",
    "title": "07wk-1",
    "section": "actor라는 단어가 포함된 column 선택",
    "text": "actor라는 단어가 포함된 column 선택\n- 다시 열의 이름들을 확인\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n- 방법1\n\ndf.iloc[:,list(map(lambda x : 'actor' in x, df.columns) )]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법2\n\ndf.loc[:,list(map(lambda x : 'actor' in x, df.columns) )]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법3\n\ndf.iloc[:,map(lambda x : 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n- 방법4\n\ndf.loc[:,map(lambda x : 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#s로-끝나는-column-선택",
    "href": "posts/2022-10-17-7wk-1.html#s로-끝나는-column-선택",
    "title": "07wk-1",
    "section": "s로 끝나는 column 선택",
    "text": "s로 끝나는 column 선택\n- 방법1\n\ndf.iloc[:,map(lambda x: 's' == x[-1],df.columns )]\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns\n\n\n\n- 방법2\n\ndf.loc[:,map(lambda x: 's' == x[-1],df.columns )]\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#c-혹은-d로-시작하는-column-선택",
    "href": "posts/2022-10-17-7wk-1.html#c-혹은-d로-시작하는-column-선택",
    "title": "07wk-1",
    "section": "c 혹은 d로 시작하는 column 선택",
    "text": "c 혹은 d로 시작하는 column 선택\n- 방법1\n\ndf.iloc[:,map(lambda x: 'c' == x[0] or 'd' == x[0] ,df.columns )]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns\n\n\n\n- 방법2\n\ndf.loc[:,map(lambda x: 'c' == x[0] or 'd' == x[0] ,df.columns )]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#방법1-concat",
    "href": "posts/2022-10-17-7wk-1.html#방법1-concat",
    "title": "07wk-1",
    "section": "방법1: concat",
    "text": "방법1: concat\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n_df = pd.DataFrame({'c':[3,4,5]}) \n_df\n\n\n\n\n\n  \n    \n      \n      c\n    \n  \n  \n    \n      0\n      3\n    \n    \n      1\n      4\n    \n    \n      2\n      5\n    \n  \n\n\n\n\n\npd.concat([df,_df],axis=1)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#방법2-4가지-컨셉에-따른-할당",
    "href": "posts/2022-10-17-7wk-1.html#방법2-4가지-컨셉에-따른-할당",
    "title": "07wk-1",
    "section": "방법2: 4가지 컨셉에 따른 할당",
    "text": "방법2: 4가지 컨셉에 따른 할당\n\n# 컨셉1: 불가능\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.c = pd.Series([1,2,3]) \ndf\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n\n# 컨셉2: 가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf['c']=[3,4,5]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf[['c','d']]=np.array([[3,4,5],[4,5,6]]).T # 굳이.. \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf['c'],df['d']=[3,4,5],[4,5,6]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n\n# 컨셉3: 불가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.iloc[:,2] = [3,4,5] \ndf\n\nIndexError: iloc cannot enlarge its target object\n\n\n\n\n# 컨셉4: 가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'] = [3,4,5] \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,['c','d']] = np.array([[3,4,5],[4,5,6]]).T # 이거 솔직히 되는지 몰랐어요.. \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'],df.loc[:,'d'] = [3,4,5],[4,5,6] \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#방법3-.assign으로-할당-star-제-최애",
    "href": "posts/2022-10-17-7wk-1.html#방법3-.assign으로-할당-star-제-최애",
    "title": "07wk-1",
    "section": "방법3: .assign으로 할당 (\\(\\star\\)) – 제 최애",
    "text": "방법3: .assign으로 할당 (\\(\\star\\)) – 제 최애\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5],d=[4,5,6])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5]).assign(d=[4,5,6])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#방법4-.eval을-이용한-할당",
    "href": "posts/2022-10-17-7wk-1.html#방법4-.eval을-이용한-할당",
    "title": "07wk-1",
    "section": "방법4: .eval을 이용한 할당",
    "text": "방법4: .eval을 이용한 할당\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]').eval('d=[4,5,6]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#연습해보기",
    "href": "posts/2022-10-17-7wk-1.html#연습해보기",
    "title": "07wk-1",
    "section": "연습해보기",
    "text": "연습해보기\n\n# 데이터프레임 생성\n\ndf=pd.DataFrame({'x':np.random.randn(1000),'y':np.random.randn(1000)})\ndf\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      1.085469\n      -1.427839\n    \n    \n      1\n      -1.473272\n      -1.527442\n    \n    \n      2\n      -1.007274\n      -1.312202\n    \n    \n      3\n      1.220634\n      -0.474995\n    \n    \n      4\n      -0.101496\n      1.636326\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      995\n      -0.668557\n      -0.435391\n    \n    \n      996\n      0.455894\n      0.796826\n    \n    \n      997\n      -1.004412\n      1.843344\n    \n    \n      998\n      -2.115145\n      -1.971965\n    \n    \n      999\n      0.861141\n      -0.193742\n    \n  \n\n1000 rows × 2 columns\n\n\n\n\n\n# 새로운열 r을 생성하고 \\(r=\\sqrt{x^2 + y^2}\\)를 계산\n- 방법1: 브로드캐스팅\n\ndf.assign(r=np.sqrt(df.x**2 + df.y**2))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      1.085469\n      -1.427839\n      1.793590\n    \n    \n      1\n      -1.473272\n      -1.527442\n      2.122171\n    \n    \n      2\n      -1.007274\n      -1.312202\n      1.654229\n    \n    \n      3\n      1.220634\n      -0.474995\n      1.309796\n    \n    \n      4\n      -0.101496\n      1.636326\n      1.639470\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      -0.668557\n      -0.435391\n      0.797831\n    \n    \n      996\n      0.455894\n      0.796826\n      0.918026\n    \n    \n      997\n      -1.004412\n      1.843344\n      2.099229\n    \n    \n      998\n      -2.115145\n      -1.971965\n      2.891796\n    \n    \n      999\n      0.861141\n      -0.193742\n      0.882667\n    \n  \n\n1000 rows × 3 columns\n\n\n\n- 방법2: lambda + map을 이용한 개별원소 계산\n\ndf.assign(r=list(map(lambda x,y: np.sqrt(x**2+y**2), df.x,df.y)))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      1.085469\n      -1.427839\n      1.793590\n    \n    \n      1\n      -1.473272\n      -1.527442\n      2.122171\n    \n    \n      2\n      -1.007274\n      -1.312202\n      1.654229\n    \n    \n      3\n      1.220634\n      -0.474995\n      1.309796\n    \n    \n      4\n      -0.101496\n      1.636326\n      1.639470\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      -0.668557\n      -0.435391\n      0.797831\n    \n    \n      996\n      0.455894\n      0.796826\n      0.918026\n    \n    \n      997\n      -1.004412\n      1.843344\n      2.099229\n    \n    \n      998\n      -2.115145\n      -1.971965\n      2.891796\n    \n    \n      999\n      0.861141\n      -0.193742\n      0.882667\n    \n  \n\n1000 rows × 3 columns\n\n\n\n- 방법3: eval\n\ndf.eval('r=sqrt(x**2+y**2)')\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      1.085469\n      -1.427839\n      1.793590\n    \n    \n      1\n      -1.473272\n      -1.527442\n      2.122171\n    \n    \n      2\n      -1.007274\n      -1.312202\n      1.654229\n    \n    \n      3\n      1.220634\n      -0.474995\n      1.309796\n    \n    \n      4\n      -0.101496\n      1.636326\n      1.639470\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      -0.668557\n      -0.435391\n      0.797831\n    \n    \n      996\n      0.455894\n      0.796826\n      0.918026\n    \n    \n      997\n      -1.004412\n      1.843344\n      2.099229\n    \n    \n      998\n      -2.115145\n      -1.971965\n      2.891796\n    \n    \n      999\n      0.861141\n      -0.193742\n      0.882667\n    \n  \n\n1000 rows × 3 columns"
  },
  {
    "objectID": "posts/2022-10-17-7wk-1.html#toy-exam",
    "href": "posts/2022-10-17-7wk-1.html#toy-exam",
    "title": "07wk-1",
    "section": "Toy exam",
    "text": "Toy exam\n- 교재의 예제상황은 예를들면 아래와 같다.\n(숨은진짜상황1)\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1) \ntemp= np.array([-10.2, -5.2, 0.1, 10.1, 12.2, 14.7, \n                25.4, 26.8, 28.9, 35.1, 32.2, 34.6])\neps= np.random.normal(size=12,scale=5)\nicecream= 20 + temp * 2 + eps\n\n\nplt.plot(temp,icecream,'.')\n\n\n\n\n\n온도와 아이스크림 판매량의 산점도\n\n(숨은진짜상황2)\n\\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\epsilon\\] - 좌변은 소아마비임을 나타내는 어떠한 반응수치라고 생각하자.\n\nnp.random.seed(2) \neps = np.random.normal(size=12,scale=5) \ndisease = 30+ temp* 0.5 + eps\n\n\nplt.plot(temp,disease,'.')\n\n\n\n\n\n온도와 소아마비의 산점도\n\n(우리가 데이터로부터 관측한 상황)\n- 아이스크림과 질병의 산점도를 그려보자.\n\nplt.plot(icecream,disease,'.')\n\n\n\n\n\n양의 상관관계에 있다.\n\n- 아이스크림 중 어떠한 물질이 소아마비를 일으키는것이 분명하므로 (인과성이 분명해보이니까) 아래와 같은 모형을 세우자. <– 여기서부터 틀렸음\n\\[{\\tt disease}_i =\\beta_0 +\\beta_1 {\\tt icecream}_i +\\epsilon_i,\\quad \\textbf{for} ~~ i=1,2,\\dots, 12\\]\n- 적절한 \\(\\beta_0\\)와 \\(\\beta_1\\)을 추정하면 우리는 아이스크림과 소아마비의 관계를 알 수 있다. <– 틀린주장\n\n틀린 모형\n도데체 우리가 뭘 잘못했는가?\n\n- 두 변수 사이에 상관관계가 있어도 실제 원인은 다른 변수에 숨겨져 있는 경우가 많다.\n(ex1)\n\n온도 \\(\\to\\) 익사\n온도 \\(\\to\\) 아이스크림\n아이스크림과 익사자도 양의 상관관계에 있을것이다.\n아이스크림을 먹이면 물에 빠져 죽는다 \\(\\to\\) 틀린주장\n사실 기온이 숨겨진 원인이다. 기온이 증가하면 아이스크림 판매량도 증가하고 폭염때문에 익사사고율도 높아지는 구조이다.\n\n(ex2)\n\n인구수 \\(\\to\\) 교회\n인구수 \\(\\to\\) 범죄건수\n지역별 교회와 범죄건수를 살펴보면 상관관계가 높게 나올것임\n교회를 지으면 범죄건수도 증가한다? \\(\\to\\) 틀린주장\n사실 인구가 숨겨진 요인임\n\n- ex2, ex1에 대하여 바른 분석을 하려면?\n\nex2: 인구가 비슷한 도시끼리 묶어서 비교해보면 교회와 범죄의 건수는 양의 상관관계에 있지 않을것임\nex1: 온도가 비슷한 그룹끼리 묶어보자.\n\n- 올바른 분석: 온도가 비슷한 그룹끼리 묶어서 그려보자. \\(\\to\\) 상관계수가 줄어들 것이다.\n\nplt.plot(icecream[:6],disease[:6],'.')\n\n\n\n\n\nplt.plot(icecream[6:],disease[6:],'.')\n\n\n\n\n\n진짜로 선형관계가 약해졌다.."
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html",
    "href": "posts/2022-11-28-13wk-1.html",
    "title": "13wk-1",
    "section": "",
    "text": "Choropleth– json 파일 뜯어보기, folium.Choropleth를 이용한 시각화 I, folium.Choropleth를 이용한 시각화 II"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#folium.polygon",
    "href": "posts/2022-11-28-13wk-1.html#folium.polygon",
    "title": "13wk-1",
    "section": "folium.Polygon",
    "text": "folium.Polygon\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Marker(\n    location = [35.8471, 127.1291]\n).add_to(m)\nfolium.Marker(\n    location = [35.8468, 127.1289]\n).add_to(m)\nfolium.Marker(\n    location = [35.84635, 127.1291]\n).add_to(m)\nfolium.Marker(\n    location = [35.84635, 127.1297]\n).add_to(m)\nfolium.Marker(\n    location = [35.8468, 127.12995]\n).add_to(m)\nfolium.Marker(\n    location = [35.8474, 127.1300]\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Polygon(\n    locations = [[35.8471, 127.1291],\n                 [35.8468, 127.1289],\n                 [35.84635, 127.1291],\n                 [35.84635, 127.1297],\n                 [35.8468, 127.12995],\n                 [35.8474, 127.1300]],\n    fill=True\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\nm = folium.Map(\n    scrollWheelZoom=False,\n    location = [35.8468,127.1294], # 분수대\n    zoom_start=18,\n)\nfolium.Polygon(\n    locations = [[[35.8471, 127.1291],\n                 [35.8468, 127.1289],\n                 [35.84635, 127.1291],\n                 [35.84635, 127.1297],\n                 [35.8468, 127.12995],\n                 [35.8474, 127.1300]],\n                 \n                 [[ 35.8471 , 127.1302],\n                 [ 35.8468 , 127.1300],\n                 [ 35.84635, 127.1302],\n                 [ 35.84635, 127.1308],\n                 [ 35.8468 , 127.13105],\n                 [ 35.8474 , 127.1311]]],\n    fill=True\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#dict-view-vs-copy",
    "href": "posts/2022-11-28-13wk-1.html#dict-view-vs-copy",
    "title": "13wk-1",
    "section": "dict: view vs copy",
    "text": "dict: view vs copy\n- 원하지 않는 코드\n\ndct1= {'a':1, 'b':2, 'c':3}\ndct1\n\n{'a': 1, 'b': 2, 'c': 3}\n\n\n\ndct2 = dct1 \ndct1,dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 3})\n\n\n\ndct2['c']=9999\ndct1,dct2\n\n({'a': 1, 'b': 2, 'c': 9999}, {'a': 1, 'b': 2, 'c': 9999})\n\n\n- 원하는 코드\n\ndct1= {'a':1, 'b':2, 'c':3}\ndct1\n\n{'a': 1, 'b': 2, 'c': 3}\n\n\n\ndct2 = dct1.copy()\ndct1,dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 3})\n\n\n\ndct2['c']=9999\ndct1,dct2\n\n({'a': 1, 'b': 2, 'c': 3}, {'a': 1, 'b': 2, 'c': 9999})"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#json-파일-다운로드",
    "href": "posts/2022-11-28-13wk-1.html#json-파일-다운로드",
    "title": "13wk-1",
    "section": "json 파일 다운로드",
    "text": "json 파일 다운로드\n\nglobal_dict = json.loads(requests.get('https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-provinces-2018-geo.json').text)\nlocal_dict = json.loads(requests.get('https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-municipalities-2018-geo.json').text)"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#json-파일의-구조",
    "href": "posts/2022-11-28-13wk-1.html#json-파일의-구조",
    "title": "13wk-1",
    "section": "json 파일의 구조",
    "text": "json 파일의 구조\n- global_dict의 구조를 살펴보면 아래와 같음\n\n\n\nlevel_0\nlevel_1\nlevel_2\nlevel3\nlevel4\n\n\n\n\ntype\n‘FeatureCollection’\n\n\n\n\n\nfeatures\n[0]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘Polygon’\n\n\n\n\n\ncoordinates\n(1,??,2) list\n\n\n\n\nproperties\nname\n‘서울특별시’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Seoul’\n\n\n\n\n\ncode\n‘11’\n\n\n\n…\n…\n…\n…\n\n\n\n[16]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(6,1,??,2) list\n\n\n\n\nproperties\nname\n‘’제주특별자치도’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Jeju-do’\n\n\n\n\n\ncode\n‘39’\n\n\nname\n‘sido’\n\n\n\n\n\ncrs\ntype\n‘name’\n\n\n\n\n\nproperties\nname\n‘urn:ogc:def:crs:OGC:1.3:CRS84’\n\n\n\n\n- local_dict의 구조를 살펴보면 아래와 같음\n\n\n\nlevel_0\nlevel_1\nlevel_2\nlevel3\nlevel4\n\n\n\n\ntype\n‘FeatureCollection’\n\n\n\n\n\nfeatures\n[0]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(1,1,??,2) list\n\n\n\n\nproperties\nname\n‘종로구’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Jongno-gu’\n\n\n\n\n\ncode\n‘11010’\n\n\n\n…\n…\n…\n…\n\n\n\n[249]\ntype\n‘Feature’\n\n\n\n\n\ngeometry\ntype\n‘MultiPolygon’\n\n\n\n\n\ncoordinates\n(10,1,??,2) list\n\n\n\n\nproperties\nname\n‘서귀포시’\n\n\n\n\n\nbase_year\n‘2018’\n\n\n\n\n\nname_eng\n‘Seogwipo-si’\n\n\n\n\n\ncode\n‘39020’\n\n\nname\n‘sido’\n\n\n\n\n\ncrs\ntype\n‘name’\n\n\n\n\n\nproperties\nname\n‘urn:ogc:def:crs:OGC:1.3:CRS84’"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#예제1-global-scale",
    "href": "posts/2022-11-28-13wk-1.html#예제1-global-scale",
    "title": "13wk-1",
    "section": "예제1: global scale",
    "text": "예제1: global scale\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start=7,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=global_dict\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#예제2-local-scale",
    "href": "posts/2022-11-28-13wk-1.html#예제2-local-scale",
    "title": "13wk-1",
    "section": "예제2: local scale",
    "text": "예제2: local scale\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start=7,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#예제3-덕진구-완신구-시각화",
    "href": "posts/2022-11-28-13wk-1.html#예제3-덕진구-완신구-시각화",
    "title": "13wk-1",
    "section": "예제3: 덕진구, 완신구 시각화",
    "text": "예제3: 덕진구, 완신구 시각화\n\nlocal_dict2 = local_dict.copy() \n\n\n_features = [local_dict['features'][i] for i in range(250) if local_dict['features'][i]['properties']['name'] == '전주시덕진구' or local_dict['features'][i]['properties']['name'] == '전주시완산구']\nlocal_dict2['features'] = _features\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#예제1-덕진구-vs-완산구",
    "href": "posts/2022-11-28-13wk-1.html#예제1-덕진구-vs-완산구",
    "title": "13wk-1",
    "section": "예제1: 덕진구 vs 완산구",
    "text": "예제1: 덕진구 vs 완산구\n\n선실습\n\ndf = pd.DataFrame({'key':['전주시덕진구', '전주시완산구'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      전주시완산구\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n후설명\n이해를 위해 필요한 약간의 직관\n\n예비생각1: 코로플레스맵을 그리기 위해서는 항상 2개의 데이터를 연결해야하는 구조이다. 하나는 json에서 나온 dict (local_dict2), 다른하나는 이다.\n예비생각2: 두개의 데이터를 연결하기 위해서는 공유가능한 연결의 매개체가 필요하다. (cbind: row-index를 공유, rbind: colnames공유, merge: 양쪽 데이터프레임에서 같은 이름을 가진 특정 col이 있었음)\n예비생각3: 코로플레스맵의 연결매개체는 ‘완산구’, ’덕진구’와 같은 지역명이다.\n\nfolium.Choropleth() 에 사용될 변수들 상상해보기\n\n재료: 두개의 데이터 (json과 df)를 명시해야 한다.\n연결매개체: 두개의 데이터프레임을 연결하는 변수이름을 명시해야 한다.\n색깔표시: (지역명,value)와 같은 쌍을 전달해야 한다."
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#key_on-에-대한-이해",
    "href": "posts/2022-11-28-13wk-1.html#key_on-에-대한-이해",
    "title": "13wk-1",
    "section": "key_on 에 대한 이해",
    "text": "key_on 에 대한 이해\n\n사용예시1: 한글이름으로 key_on\n\ndf = pd.DataFrame({'key':['전주시덕진구', 'Jeonjusiwansangu'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      Jeonjusiwansangu\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n사용예시2: 영어이름으로 key_on\n\ndf = pd.DataFrame({'key':['전주시덕진구', 'Jeonjusiwansangu'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      key\n      value\n    \n  \n  \n    \n      0\n      전주시덕진구\n      20\n    \n    \n      1\n      Jeonjusiwansangu\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['key','value'],\n    key_on='properties.name_eng',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n사용예시3: 코드로 key_on\n\nlocal_dict2['features'][0]['properties'], local_dict2['features'][1]['properties']\n\n({'name': '전주시완산구',\n  'base_year': '2018',\n  'name_eng': 'Jeonjusiwansangu',\n  'code': '35011'},\n {'name': '전주시덕진구',\n  'base_year': '2018',\n  'name_eng': 'Jeonjusideokjingu',\n  'code': '35012'})\n\n\n\ndf = pd.DataFrame({'code':['35012', '35011'], 'value':[20,30]})\ndf\n\n\n\n\n\n  \n    \n      \n      code\n      value\n    \n  \n  \n    \n      0\n      35012\n      20\n    \n    \n      1\n      35011\n      30\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [35.84195368311022, 127.1155556693179],\n    zoom_start=11,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict2,\n    data=df,\n    columns=['code','value'],\n    key_on='properties.code',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#예제2-대한민국-인구수-시각화-global-scale",
    "href": "posts/2022-11-28-13wk-1.html#예제2-대한민국-인구수-시각화-global-scale",
    "title": "13wk-1",
    "section": "예제2: 대한민국 인구수 시각화 (global scale)",
    "text": "예제2: 대한민국 인구수 시각화 (global scale)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-prov.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      행정구역(시군구)별\n      총인구수 (명)\n    \n  \n  \n    \n      0\n      서울특별시\n      9532428\n    \n    \n      1\n      부산광역시\n      3356311\n    \n    \n      2\n      대구광역시\n      2390721\n    \n    \n      3\n      인천광역시\n      2945009\n    \n    \n      4\n      광주광역시\n      1442454\n    \n    \n      5\n      대전광역시\n      1454228\n    \n    \n      6\n      울산광역시\n      1122566\n    \n    \n      7\n      세종특별자치시\n      368276\n    \n    \n      8\n      경기도\n      13549577\n    \n    \n      9\n      강원도\n      1537717\n    \n    \n      10\n      충청북도\n      1596948\n    \n    \n      11\n      충청남도\n      2118977\n    \n    \n      12\n      전라북도\n      1789770\n    \n    \n      13\n      전라남도\n      1834653\n    \n    \n      14\n      경상북도\n      2627925\n    \n    \n      15\n      경상남도\n      3318161\n    \n    \n      16\n      제주특별자치도\n      676569\n    \n  \n\n\n\n\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start=7,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=global_dict,\n    data=df,\n    columns=['행정구역(시군구)별','총인구수 (명)'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "posts/2022-11-28-13wk-1.html#예제3-대한민국-인구수-시각화-local-scale",
    "href": "posts/2022-11-28-13wk-1.html#예제3-대한민국-인구수-시각화-local-scale",
    "title": "13wk-1",
    "section": "예제3: 대한민국 인구수 시각화 (local scale)",
    "text": "예제3: 대한민국 인구수 시각화 (local scale)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-muni.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      행정구역(시군구)별\n      총인구수 (명)\n    \n  \n  \n    \n      0\n      종로구\n      145346\n    \n    \n      1\n      중구\n      122781\n    \n    \n      2\n      용산구\n      223713\n    \n    \n      3\n      성동구\n      287174\n    \n    \n      4\n      광진구\n      340814\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      269\n      함양군\n      38475\n    \n    \n      270\n      거창군\n      61242\n    \n    \n      271\n      합천군\n      43029\n    \n    \n      272\n      제주시\n      493225\n    \n    \n      273\n      서귀포시\n      183344\n    \n  \n\n274 rows × 2 columns\n\n\n\n\nm = folium.Map(\n    location = [36,128],\n    zoom_start=7,\n    scrollWheelZoom = False\n)\nfolium.Choropleth(\n    geo_data=local_dict,\n    data=df,\n    columns=['행정구역(시군구)별','총인구수 (명)'],\n    key_on='properties.name',\n).add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -> Trust Notebook"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "데이터시각화(2022)",
    "section": "",
    "text": "final\n\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA2: 깊은복사와 얕은복사\n\n\n\n\n\n\n\n\n\n\n\n\nDec 14, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13wk-2\n\n\n\n\n\n\n\n지리정보시각화\n\n\nplotly\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13wk-1\n\n\n\n\n\n\n\n지리정보시각화\n\n\nfolium\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12wk-2\n\n\n\n\n\n\n\n지리정보시각화\n\n\nplotly\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12wk-1\n\n\n\n\n\n\n\n지리정보시각화\n\n\nfolium\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11wk-2\n\n\n\n\n\n\n\n자료분석\n\n\npandas backend\n\n\nplotly\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11wk-1\n\n\n\n\n\n\n\npandas backend\n\n\nplotly\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10wk-2\n\n\n\n\n\n\n\n통계와 시각화\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nNov 9, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10wk-1\n\n\n\n\n\n\n\npandas\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\n최규빈\n\n\n\n\n\n\n  \n\n\n\n\n09wk-2\n\n\n\n\n\n\n\n훌륭한 시각화\n\n\n\n\n\n\n\n\n\n\n\nNov 2, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmidterm\n\n\n\n\n\n\n\n\n\n\n\n\nOct 30, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n08wk-1,2\n\n\n\n\n\n\n\npandas\n\n\n자료분석\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07wk-2\n\n\n\n\n\n\n\n통계와 시각화\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07wk-1\n\n\n\n\n\n\n\npandas\n\n\n통계와 시각화\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n06wk-1,2\n\n\n\n\n\n\n\npandas\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2022\n\n\n최규빈\n\n\n\n\n\n\n  \n\n\n\n\n05wk-2\n\n\n\n\n\n\n\n훌륭한 시각화\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05wk-1\n\n\n\n\n\n\n\nseaborn\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04wk-2\n\n\n\n\n\n\n\nseaborn\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04wk-1\n\n\n\n\n\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n03wk-2\n\n\n\n\n\n\n\nmatplotlib\n\n\n통계와 시각화\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2022\n\n\n최규빈\n\n\n\n\n\n\n  \n\n\n\n\n03wk-1\n\n\n\n\n\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n02wk-2\n\n\n\n\n\n\n\n통계와 시각화\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01wk-1\n\n\n\n\n\n\n\nmatplotlib\n\n\nseaborn\n\n\nplotnine\n\n\nplotly\n\n\n\n\n\n\n\n\n\n\n\nSep 10, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA1: tips for matploblib\n\n\n\n\n\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\n최규빈\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "데이터시각화\nguebin@jbnu.ac.kr\n자연과학대학 본관 205호"
  }
]